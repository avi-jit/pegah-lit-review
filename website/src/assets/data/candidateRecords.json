{"papers":[{"url":"https://www.semanticscholar.org/paper/493a6e7aef4ead8fafa8913ce404a870d862c08b","title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","venue":"ArXiv","year":2022,"referenceCount":159,"citationCount":0,"influentialCitationCount":0,"publicationDate":"19/12/2022","authors":"Sagi Shaier,L. Hunter,Katharina Kann","id":"493a6e7aef4ead8fafa8913ce404a870d862c08b","summary":"This work surveys the motivation for enhancing DSs with knowledge, used datasets, and methods for knowledge search, knowledge encoding, and knowledge incorporation, and proposes how to improve existing systems based on theories from linguistics and cognitive science.","score":6},{"url":"https://www.semanticscholar.org/paper/17a8b5e6fef1f69979d57021a8f30a5159e152c7","title":"Commonsense Reasoning for Conversational AI: A Survey of the State of the Art","venue":"ArXiv","year":2023,"referenceCount":90,"citationCount":0,"influentialCitationCount":0,"publicationDate":"15/02/2023","authors":"Christopher Richardson,Larry Heck","id":"17a8b5e6fef1f69979d57021a8f30a5159e152c7","summary":"A survey of recent conversational AI research focused on commonsense reasoning, including preliminary observations of the limited commonsense capabilities of two state-of-the-art open dialogue models, BlenderBot3 and LaMDA, and its negative effect on natural interactions.","score":6},{"url":"https://www.semanticscholar.org/paper/8f926c0c3f1557a9241b7e75609082a1f207a75e","title":"InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":124,"citationCount":10,"influentialCitationCount":0,"publicationDate":"25/05/2022","authors":"Prakhar Gupta,Cathy Jiao,Yi-Ting Yeh,Shikib Mehri,M. Eskénazi,Jeffrey P. Bigham","id":"8f926c0c3f1557a9241b7e75609082a1f207a75e","summary":"This work introduces InstructDial, an instruction tuning framework for dialogue, which consists of a repository of 48 diverse dialogue tasks in a unified text-to-text format created from 59 openly available dialogue datasets, and introduces novel meta-tasks to ensure that models adhere to instructions.","score":6},{"url":"https://www.semanticscholar.org/paper/c8559021289f08eaf8cf2294e406bc1c6b506d19","title":"Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey","venue":"Artificial Intelligence Review","year":2021,"referenceCount":480,"citationCount":64,"influentialCitationCount":4,"publicationDate":"10/05/2021","authors":"Jinjie Ni,Tom Young,Vlad Pandelea,Fuzhao Xue,V. Adiga,E. Cambria","id":"c8559021289f08eaf8cf2294e406bc1c6b506d19","summary":"This survey is the most comprehensive and up-to-date one at present in the area of dialogue systems and dialogue-related tasks, extensively covering the popular frameworks, topics, and datasets.","score":5},{"url":"https://www.semanticscholar.org/paper/a6880a4c3f4b2f0a1d492d689569683ffbc03076","title":"DFM: Dialogue Foundation Model for Universal Large-Scale Dialogue-Oriented Task Learning","venue":"","year":2022,"referenceCount":92,"citationCount":1,"influentialCitationCount":0,"publicationDate":"25/05/2022","authors":"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Xinhsuai Dong,Fujiang Ge,Qingliang Miao,Jian-Guang Lou,Kai Yu","id":"a6880a4c3f4b2f0a1d492d689569683ffbc03076","summary":"Experiments show that, compared with models of the same size, DFM can achieve state-of-the-art or competitive performance on very rich cross-domain downstream dialogue tasks, and demonstrates that DFM largely ex-tends the ability of uniﬁed dialogue pre-trained model.","score":5},{"url":"https://www.semanticscholar.org/paper/7e582b03b597d8865f6641c511c1a63b6255b821","title":"DialogZoo: Large-Scale Dialog-Oriented Task Learning","venue":"ArXiv","year":2022,"referenceCount":86,"citationCount":3,"influentialCitationCount":0,"publicationDate":2022,"authors":"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Jian-Guang Lou,Kai Yu","id":"7e582b03b597d8865f6641c511c1a63b6255b821","summary":"The experimental results show that the building a uniﬁed foundation model which can solve massive diverse dialogue tasks and improves the ability of dialogue generation and knowledge distillation, but also the representation ability of models.","score":5},{"url":"https://www.semanticscholar.org/paper/343eef7387dbc7d0ffa463cfe1cfab237f82aa66","title":"Gunrock 2.0: A User Adaptive Social Conversational System","venue":"ArXiv","year":2020,"referenceCount":42,"citationCount":16,"influentialCitationCount":0,"publicationDate":"17/11/2020","authors":"Kai-Hui Liang,Author Chau,Yu Li,Xueyuan Lu,Dian Yu,Mingyang Zhou,Ishan Jain,Sam Davidson,Josh Arnold,Minh Le Nguyen,Zhou Yu","id":"343eef7387dbc7d0ffa463cfe1cfab237f82aa66","summary":"Gunrock 2.0 is built on top of Gunrock with an emphasis on user adaptation and combines various neural natural language understanding modules, including named entity detection, linking, and dialog act prediction, to improve user understanding.","score":4},{"url":"https://www.semanticscholar.org/paper/9997901cac96451686b817961c1408ac4123102c","title":"HappyBot: Generating Empathetic Dialogue Responses by Improving User Experience Look-ahead","venue":"ArXiv","year":2019,"referenceCount":33,"citationCount":38,"influentialCitationCount":0,"publicationDate":"20/06/2019","authors":"Jamin Shin,Peng Xu,Andrea Madotto,Pascale Fung","id":"9997901cac96451686b817961c1408ac4123102c","summary":"A Sentiment Predictor is trained to estimate the user sentiment look-ahead towards the generated system responses, which is then used as the reward function for generating more empathetic responses.","score":4},{"url":"https://www.semanticscholar.org/paper/af4cb5bef1db79b837ca5eabc47a3a3a582b0c17","title":"C L ] 7 S ep 2 02 1 Empathetic Dialogue Generation with Pre-trained RoBERTa-GPT 2 and External Knowledge","venue":"","year":2021,"referenceCount":47,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"Ye Liu,Wolfgang Maier,W. Minker,Stefan Ultes","id":"af4cb5bef1db79b837ca5eabc47a3a3a582b0c17","summary":"To enable the empathetic ability of RoBERTaGPT2 model, this work proposes a commonsense knowledge and emotional concepts extractor, in which the commonsensible andotional concepts of dialogue context are extracted for the GPT-2 decoder.","score":4},{"url":"https://www.semanticscholar.org/paper/062466fb189fd3d4ab2f56a05937a8ae6df7bd06","title":"A Comprehensive Assessment of Dialog Evaluation Metrics","venue":"EANCS","year":2021,"referenceCount":68,"citationCount":44,"influentialCitationCount":10,"publicationDate":"07/06/2021","authors":"Yi-Ting Yeh,M. Eskénazi,Shikib Mehri","id":"062466fb189fd3d4ab2f56a05937a8ae6df7bd06","summary":"This comprehensive assessment provides a comprehensive assessment of recently proposed dialog evaluation metrics on a number of datasets and suggests how to best assess evaluation metrics and indicates promising directions for future work.","score":4},{"url":"https://www.semanticscholar.org/paper/5cf42d26583d2b083262451e9005e6ed273badca","title":"Automatic Evaluation and Moderation of Open-domain Dialogue Systems","venue":"ArXiv","year":2021,"referenceCount":55,"citationCount":11,"influentialCitationCount":0,"publicationDate":"03/11/2021","authors":"Chen Zhang,João Sedoc,L. F. D’Haro,Rafael E. Banchs,Alexander I. Rudnicky","id":"5cf42d26583d2b083262451e9005e6ed273badca","summary":"This paper describes the datasets and baselines provided to participants, as well as submission evaluation results for each of the two proposed subtasks, and describes the automatic evaluation mechanisms that show high correlations with human judgements across multiple dialogue evaluation aspects.","score":4},{"url":"https://www.semanticscholar.org/paper/5d0419f282aa8ad7c98c1f28876323645a7407d6","title":"Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":36,"citationCount":3,"influentialCitationCount":0,"publicationDate":2022,"authors":"Ling-Yu Zhu,Zhengkun Zhang,Jun Wang,Hongbin Wang,Haiying Wu,Zhenglu Yang","id":"5d0419f282aa8ad7c98c1f28876323645a7407d6","summary":"","score":4},{"url":"https://www.semanticscholar.org/paper/0ba23c847d2ca087887b60ea92ce56c71f0425b2","title":"MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":49,"citationCount":4,"influentialCitationCount":0,"publicationDate":"14/12/2021","authors":"Chen Zhang,L. F. D’Haro,Thomas Friedrichs,Haizhou Li","id":"0ba23c847d2ca087887b60ea92ce56c71f0425b2","summary":"The proposed MDD-Eval framework first train a teacher evaluator with human-annotated data to acquire a rating skill to tell good dialogue responses from bad ones in a particular domain and then, adopt a self-training strategy to train a new evaluators with teacher-annotation multi-domain data, that helps the newevaluator to generalize across multiple domains.","score":4},{"url":"https://www.semanticscholar.org/paper/59707fbd3308257628470d94e56c8165bf4e1cff","title":"FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":59,"citationCount":5,"influentialCitationCount":0,"publicationDate":"12/05/2022","authors":"Alon Albalak,Yi-Lin Tuan,Pegah Jandaghi,Connor Pryor,Luke Yoffe,Deepak Ramachandran,L. Getoor,J. Pujara,William Yang Wang","id":"59707fbd3308257628470d94e56c8165bf4e1cff","summary":"Conversational task transfer is explored by introducing FETA: a benchmark for FEw-sample TAsk transfer in open-domain dialogue and can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning.","score":4},{"url":"https://www.semanticscholar.org/paper/f1217313b3dd1d4dc5afc09edfcbccae9b5647fe","title":"Grounding in social media: An approach to building a chit-chat dialogue model","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":26,"citationCount":0,"influentialCitationCount":0,"publicationDate":"12/06/2022","authors":"Ritvik Choudhary,Daisuke Kawahara","id":"f1217313b3dd1d4dc5afc09edfcbccae9b5647fe","summary":"This method aims to improve the raw conversation ability of the system by mimicking the human response behavior through casual interactions found on social media, and queries a large set of filtered comment data from Reddit to act as additional context for the seq2seq generator.","score":4},{"url":"https://www.semanticscholar.org/paper/4bc51cb3ba793de7c06bb77770f2f9a91ff809f7","title":"MVP: Multi-task Supervised Pre-training for Natural Language Generation","venue":"ArXiv","year":2022,"referenceCount":187,"citationCount":4,"influentialCitationCount":0,"publicationDate":"24/06/2022","authors":"Tianyi Tang,Junyi Li,Wayne Xin Zhao,Ji-rong Wen","id":"4bc51cb3ba793de7c06bb77770f2f9a91ff809f7","summary":"This work collects a large-scale natural language generation corpus, MVPCorpus, from 77 datasets over 11 diverse NLG tasks, and unifies these examples into a general text-to-text format to pre-train the text generation model MVP in a supervised manner.","score":4},{"url":"https://www.semanticscholar.org/paper/27a51fa45ab9512b43d697a017a52ec3b4f7fd32","title":"SelF-Eval: Self-supervised Fine-grained Dialogue Evaluation","venue":"International Conference on Computational Linguistics","year":2022,"referenceCount":47,"citationCount":0,"influentialCitationCount":0,"publicationDate":"17/08/2022","authors":"Longxuan Ma,Ziyu Zhuang,Weinan Zhang,Mingda Li,Ting Liu","id":"27a51fa45ab9512b43d697a017a52ec3b4f7fd32","summary":"A novel automatic data construction method that can automatically assign fine-grained scores for arbitrarily dialogue data and train SelF-Eval with a multi-level contrastive learning schema which helps to distinguish different score levels.","score":4},{"url":"https://www.semanticscholar.org/paper/a6f171598db5a21ece1ac38010c48df19b2b23ca","title":"FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":55,"citationCount":2,"influentialCitationCount":2,"publicationDate":"25/10/2022","authors":"Chen Zhang,L. F. D’Haro,Qiquan Zhang,Thomas Friedrichs,Haizhou Li","id":"a6f171598db5a21ece1ac38010c48df19b2b23ca","summary":"A multi-dimensional dialogue-level metric, which consists of three sub-metrics with each targeting a specific dimension, which is trained with novel self-supervised objectives and exhibit strong correlations with human judgment for their respective dimensions.","score":4},{"url":"https://www.semanticscholar.org/paper/e8059434aa997cf486e6ae83cfbf355d4829a95c","title":"PoE: a Panel of Experts for Generalized Automatic Dialogue Assessment","venue":"IEEE/ACM Transactions on Audio Speech and Language Processing","year":2022,"referenceCount":81,"citationCount":0,"influentialCitationCount":0,"publicationDate":"18/12/2022","authors":"Chen Zhang,L. F. D’Haro,Qiquan Zhang,Thomas Friedrichs,Haizhou Li","id":"e8059434aa997cf486e6ae83cfbf355d4829a95c","summary":"A Panel of Experts (PoE) network is proposed, a multitask network that consists of a shared transformer encoder and a collection of lightweight adapters that exhibits better zero-shot generalization than existing state-of-the-art ADEMs and the ability to easily adapt to new domains with few-shot transfer learning.","score":4},{"url":"https://www.semanticscholar.org/paper/fa50f2bc03d6d53fe50f37a1978107b13af24ea7","title":"SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization","venue":"ArXiv","year":2022,"referenceCount":59,"citationCount":3,"influentialCitationCount":0,"publicationDate":"20/12/2022","authors":"Hyunwoo Kim,Jack Hessel,Liwei Jiang,Ximing Lu,Youngjae Yu,Pei Zhou,Ronan Le Bras,Malihe Alikhani,Gunhee Kim,Maarten Sap,Yejin Choi","id":"fa50f2bc03d6d53fe50f37a1978107b13af24ea7","summary":"C OSMO is a generalizable conversation agent outperforming previous best-performing agents on both in- and out-of-domain datasets, and human evaluation shows that dialogues in S ODA are more consistent, speciﬁc, and (surprisingly) natural than prior human-authored datasets.","score":4},{"url":"https://www.semanticscholar.org/paper/1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a","title":"Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation","venue":"ArXiv","year":2020,"referenceCount":47,"citationCount":17,"influentialCitationCount":1,"publicationDate":"10/09/2020","authors":"Junlong Li,Zhuosheng Zhang,Hai Zhao,Xi Zhou,Xiang Zhou","id":"1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a","summary":"A Dialogue-Adaptive Pre-training Objective (DAPO) based on some important qualities for assessing dialogues which are usually ignored by general LM pre-training objectives is designed and Experimental results show that models with DAPO surpass those with general LMPre- training objectives and other strong baselines on downstream DrNLP tasks.","score":4},{"url":"https://www.semanticscholar.org/paper/0934d7cac5a86b02fc49852334051bde540b34bd","title":"DialogSum: A Real-Life Scenario Dialogue Summarization Dataset","venue":"Findings","year":2021,"referenceCount":37,"citationCount":58,"influentialCitationCount":18,"publicationDate":2021,"authors":"Yulong Chen,Yang Liu,Liang Chen,Yue Zhang","id":"0934d7cac5a86b02fc49852334051bde540b34bd","summary":"Experimental results show unique challenges in dialogue summarization, such as spoken terms, special discourse structures, coreferences and ellipsis, pragmatics and social common sense, which require specific representation learning technologies to better deal with.","score":4},{"url":"https://www.semanticscholar.org/paper/281b4a7e7fb057d8266ec0610888905c46fd715d","title":"Advances in Multi-turn Dialogue Comprehension: A Survey","venue":"ArXiv","year":2021,"referenceCount":106,"citationCount":10,"influentialCitationCount":1,"publicationDate":"04/03/2021","authors":"Zhuosheng Zhang,Hai Zhao","id":"281b4a7e7fb057d8266ec0610888905c46fd715d","summary":"The characteristics and challenges of dialogue comprehension in contrast to plaintext reading comprehension are summarized and three typical patterns of dialogue modeling that are widely-used in dialogue comprehension tasks such as response selection and conversation questionanswering are discussed.","score":4},{"url":"https://www.semanticscholar.org/paper/dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2","title":"Probing Commonsense Explanation in Dialogue Response Generation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":45,"citationCount":8,"influentialCitationCount":1,"publicationDate":"19/04/2021","authors":"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Justin Cho,J. Pujara,Xiang Ren","id":"dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2","summary":"This study formalizes the problem by framing commonsense as a latent variable in the RG task and using explanations for responses as textual form of commonsense, and collecting 6k annotated explanations justifying responses from four dialogue datasets and asking humans to verify them.","score":4},{"url":"https://www.semanticscholar.org/paper/a210df43018c682f6f57120cdb66b93a42c26699","title":"Probing Causal Common Sense in Dialogue Response Generation","venue":"ArXiv","year":2021,"referenceCount":46,"citationCount":3,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Hyundong Justin Cho,J. Pujara,Xiang Ren","id":"a210df43018c682f6f57120cdb66b93a42c26699","summary":"The study if response generation models can emulate human reasoning process and use common sense to help produce better-quality responses finds that RG models have a hard time determining the logical validity of explanations but can identify grammatical naturalness of the explanation easily.","score":4},{"url":"https://www.semanticscholar.org/paper/2a3dd5cf961747adcb05f4f2834ff7a22261e861","title":"Commonsense-Focused Dialogues for Response Generation: An Empirical Study","venue":"SIGDIAL Conferences","year":2021,"referenceCount":45,"citationCount":20,"influentialCitationCount":2,"publicationDate":"14/09/2021","authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"2a3dd5cf961747adcb05f4f2834ff7a22261e861","summary":"This paper auto-extract commonsensical dialogues from existing dialogue datasets by leveraging ConceptNet, a commonsense knowledge graph, and proposes an approach for automatic evaluation of commonsense that relies on features derived from ConceptNet and pre-trained language and dialog models, and shows reasonable correlation with human evaluation of responses’ commonsense quality.","score":4},{"url":"https://www.semanticscholar.org/paper/ce74df5126faad7d74f578f1e1953278611e235d","title":"Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation","venue":"ArXiv","year":2021,"referenceCount":60,"citationCount":7,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"ce74df5126faad7d74f578f1e1953278611e235d","summary":"This paper presents a self-talk approach that first generates the implicit commonsense knowledge and then generates response by referencing the externalized knowledge, all using one generative model.","score":4},{"url":"https://www.semanticscholar.org/paper/0f17d7619e5de7bf41079d65783d4fb135825377","title":"CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":34,"citationCount":7,"influentialCitationCount":1,"publicationDate":"25/03/2022","authors":"Deepanway Ghosal,Siqi Shen,Navonil Majumder,Rada Mihalcea,Soujanya Poria","id":"0f17d7619e5de7bf41079d65783d4fb135825377","summary":"This paper curates CICERO, a dataset of dyadic conversations with five types of utterance-level reasoning-based inferences, and uses it to solve relevant generative and discriminative tasks: generation of cause and subsequent event; generation of prerequisite, motivation, and listener’s emotional reaction; and selection of plausible alternatives.","score":4},{"url":"https://www.semanticscholar.org/paper/fa71d25c07d6d3c890ef4b7547d5a4d117d0b96d","title":"Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches and Future Directions","venue":"ArXiv","year":2022,"referenceCount":159,"citationCount":0,"influentialCitationCount":0,"publicationDate":"18/10/2022","authors":"Qi Jia,Siyu Ren,Yizhu Liu,Kenny Q. Zhu","id":"fa71d25c07d6d3c890ef4b7547d5a4d117d0b96d","summary":"This survey provides a comprehensive investigation on existing work for abstractive dialogue summarization from scenarios, approaches to evaluations and presents a taxonomy of existing techniques in three directions, namely, injecting dialogue features, designing auxiliary training tasks and using additional data.","score":4},{"url":"https://www.semanticscholar.org/paper/bc9d103493d93a9ad8e6b60af4d9a900e4470146","title":"CausalDialogue: Modeling Utterance-level Causality in Conversations","venue":"ArXiv","year":2022,"referenceCount":50,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/12/2022","authors":"Yi-Lin Tuan,Alon Albalak,Wenda Xu,Michael Stephen Saxon,Connor Pryor,L. Getoor,William Yang Wang","id":"bc9d103493d93a9ad8e6b60af4d9a900e4470146","summary":"This research examines user utterances as causes and generated responses as effects and proposes a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models.","score":4},{"url":"https://www.semanticscholar.org/paper/b13c3e87a80f491899068524e7e860872b521a27","title":"DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization","venue":"ArXiv","year":2022,"referenceCount":56,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/12/2022","authors":"Yu Li,Baolin Peng,Pengcheng He,Michel Galley,Zhou Yu,Jianfeng Gao","id":"b13c3e87a80f491899068524e7e860872b521a27","summary":"DIONYSUS (dynamic input optimization in pre-training for dialogue summarization), a pre-trained encoder-decoder model for summarizing dialogues in any new domain outperforms existing methods on six datasets, as demonstrated by its ROUGE scores in zero-shot and few-shot settings.","score":4},{"url":"https://www.semanticscholar.org/paper/b0b96270a9bbeb9f3ec040e70114d565fbcaaed9","title":"Learning from Dialogue after Deployment: Feed Yourself, Chatbot!","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":52,"citationCount":124,"influentialCitationCount":9,"publicationDate":"16/01/2019","authors":"Braden Hancock,Antoine Bordes,Pierre-Emmanuel Mazaré,J. Weston","id":"b0b96270a9bbeb9f3ec040e70114d565fbcaaed9","summary":"On the PersonaChat chit-chat dataset with over 131k training examples, it is found that learning from dialogue with a self-feeding chatbot significantly improves performance, regardless of the amount of traditional supervision.","score":3},{"url":"https://www.semanticscholar.org/paper/6b94dcac41325a03956402ff7862fa80936f9ddb","title":"A Survey of Natural Language Generation Techniques with a Focus on Dialogue Systems - Past, Present and Future Directions","venue":"ArXiv","year":2019,"referenceCount":143,"citationCount":32,"influentialCitationCount":0,"publicationDate":"02/06/2019","authors":"Sashank Santhanam,Samira Shaikh","id":"6b94dcac41325a03956402ff7862fa80936f9ddb","summary":"This work provides a comprehensive review towards building open domain dialogue systems, an important application of natural language generation, and finds that, predominantly, the approaches for building dialogue systems use seq2seq or language models architecture.","score":3},{"url":"https://www.semanticscholar.org/paper/b47698a589e35ec3f7a0bb30618939fbed0b9e41","title":"MoEL: Mixture of Empathetic Listeners","venue":"Conference on Empirical Methods in Natural Language Processing","year":2019,"referenceCount":65,"citationCount":108,"influentialCitationCount":32,"publicationDate":"21/08/2019","authors":"Zhaojiang Lin,Andrea Madotto,Jamin Shin,Peng Xu,Pascale Fung","id":"b47698a589e35ec3f7a0bb30618939fbed0b9e41","summary":"A novel end-to-end approach for modeling empathy in dialogue systems: Mixture of Empathetic Listeners (MoEL), which outperforms multitask training baseline in terms of empathy, relevance, and fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/2899ad28e9616779a251a78917e313b5e5011d78","title":"MIME: MIMicking Emotions for Empathetic Response Generation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":48,"citationCount":65,"influentialCitationCount":20,"publicationDate":"04/10/2020","authors":"Navonil Majumder,Pengfei Hong,Shanshan Peng,Jiankun Lu,Deepanway Ghosal,Alexander Gelbukh,Rada Mihalcea,Soujanya Poria","id":"2899ad28e9616779a251a78917e313b5e5011d78","summary":"This work argues that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content, and introduces stochasticity into the emotion mixture that yields emotionally more varied emPathetic responses than the previous work.","score":3},{"url":"https://www.semanticscholar.org/paper/89e65078d37d076627818d9dba2c8ca9bf8f66bc","title":"Challenges in Building Intelligent Open-domain Dialog Systems","venue":"ACM Trans. Inf. Syst.","year":2019,"referenceCount":204,"citationCount":171,"influentialCitationCount":11,"publicationDate":"13/05/2019","authors":"Minlie Huang,Xiaoyan Zhu,Jianfeng Gao","id":"89e65078d37d076627818d9dba2c8ca9bf8f66bc","summary":"This article reviews the recent work on neural approaches that are devoted to addressing three challenges in developing intelligent open-domain dialog systems: semantics, consistency, and interactiveness.","score":3},{"url":"https://www.semanticscholar.org/paper/270b3f5201e835dd9a6a80fb8d749dba08dc88dd","title":"Generating Empathetic Responses by Looking Ahead the User’s Sentiment","venue":"IEEE International Conference on Acoustics, Speech, and Signal Processing","year":2019,"referenceCount":29,"citationCount":22,"influentialCitationCount":2,"publicationDate":"20/06/2019","authors":"Jamin Shin,Peng Xu,Andrea Madotto,Pascale Fung","id":"270b3f5201e835dd9a6a80fb8d749dba08dc88dd","summary":"This paper implements and evaluates three different possible implementations of sentiment look-ahead and empirically shows that the proposed approach can generate significantly more empathetic, relevant, and fluent responses than other competitive baselines such as multitask learning.","score":3},{"url":"https://www.semanticscholar.org/paper/6ebfbc954b9975d2f2651f380b9bdf46ae963178","title":"PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":37,"citationCount":153,"influentialCitationCount":21,"publicationDate":"17/10/2019","authors":"Siqi Bao,H. He,Fan Wang,Hua Wu","id":"6ebfbc954b9975d2f2651f380b9bdf46ae963178","summary":"This work proposes a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering, and introduces discrete latent variables to tackle the inherent one-to-many mapping problem in response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/11abce981e90585c142078b5c64b2cb8331b8794","title":"The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":56,"citationCount":51,"influentialCitationCount":7,"publicationDate":"09/11/2019","authors":"Kurt Shuster,Da Ju,Stephen Roller,Emily Dinan,Y-Lan Boureau,J. Weston","id":"11abce981e90585c142078b5c64b2cb8331b8794","summary":"D dodecaDialogue is introduced, a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the fine-tune and task transfer settings.","score":3},{"url":"https://www.semanticscholar.org/paper/3d8c305787ed208ea6ea0ccf958b740bcfccaece","title":"EmpDG: Multi-resolution Interactive Empathetic Dialogue Generation","venue":"International Conference on Computational Linguistics","year":2019,"referenceCount":62,"citationCount":65,"influentialCitationCount":17,"publicationDate":"20/11/2019","authors":"Qintong Li,Hongshen Chen,Z. Ren,Zhumin Chen,Zhaopeng Tu,Jun Ma","id":"3d8c305787ed208ea6ea0ccf958b740bcfccaece","summary":"A multi-resolution adversarial model – EmpDG is proposed, to generate more empathetic responses and an interactive adversarial learning framework which exploits the user feedback, to identify whether the generated responses evoke emotion perceptivity in dialogues.","score":3},{"url":"https://www.semanticscholar.org/paper/15704cdfe55ddd375e7fec9e71cba9956a73972e","title":"EmpTransfo: A Multi-head Transformer Architecture for Creating Empathetic Dialog Systems","venue":"The Florida AI Research Society","year":2020,"referenceCount":25,"citationCount":27,"influentialCitationCount":1,"publicationDate":"05/03/2020","authors":"Rohola Zandie,M. Mahoor","id":"15704cdfe55ddd375e7fec9e71cba9956a73972e","summary":"It is shown that utilizing the history of emotions and other metadata can improve the quality of generated conversations by the dialog system, and the proposed approach outperforms other models in terms of Hit@1 and PPL (Perplexity).","score":3},{"url":"https://www.semanticscholar.org/paper/404859dc02da6c9dcb924535894dad0dc56696f2","title":"An Empirical Investigation of Pre-Trained Transformer Language Models for Open-Domain Dialogue Generation","venue":"ArXiv","year":2020,"referenceCount":69,"citationCount":12,"influentialCitationCount":1,"publicationDate":"09/03/2020","authors":"Piji Li","id":"404859dc02da6c9dcb924535894dad0dc56696f2","summary":"An empirical investigation of pre-trained Transformer-based auto-regressive language models for the task of open-domain dialogue generation with detailed numbers of automatic evaluation metrics on relevance and diversity of the generated results for the languages models as well as the baseline approaches are reported.","score":3},{"url":"https://www.semanticscholar.org/paper/71017cc6d270d28d9edcd47550450dc05edd65f4","title":"Can You Put it All Together: Evaluating Conversational Agents’ Ability to Blend Skills","venue":"Annual Meeting of the Association for Computational Linguistics","year":2020,"referenceCount":19,"citationCount":136,"influentialCitationCount":13,"publicationDate":"17/04/2020","authors":"Eric Michael Smith,Mary Williamson,Kurt Shuster,J. Weston,Y-Lan Boureau","id":"71017cc6d270d28d9edcd47550450dc05edd65f4","summary":"This work investigates several ways to combine models trained towards isolated capabilities, ranging from simple model aggregation schemes that require minimal additional training, to various forms of multi-task training that encompass several skills at all training stages.","score":3},{"url":"https://www.semanticscholar.org/paper/18c54279a916293153db45e6db8422eaa52539cd","title":"Open-Domain Conversational Agents: Current Progress, Open Problems, and Future Directions","venue":"ArXiv","year":2020,"referenceCount":163,"citationCount":25,"influentialCitationCount":3,"publicationDate":"22/06/2020","authors":"Stephen Roller,Y.-Lan Boureau,J. Weston,Antoine Bordes,Emily Dinan,Angela Fan,David Gunning,Da Ju,Margaret Li,Spencer Poff,Pratik Ringshia,Kurt Shuster,Eric Michael Smith,Arthur D. Szlam,Jack Urbanek,Mary Williamson","id":"18c54279a916293153db45e6db8422eaa52539cd","summary":"The properties of continual learning, providing engaging content, and being well-behaved are discussed -- and how to measure success in providing them and their recommendations to the community are discussed.","score":3},{"url":"https://www.semanticscholar.org/paper/310ce0b1b4049206a260a711cc27cae5fad3700a","title":"Persona aware Response Generation with Emotions","venue":"IEEE International Joint Conference on Neural Network","year":2020,"referenceCount":47,"citationCount":3,"influentialCitationCount":0,"publicationDate":"01/07/2020","authors":"Mauajama Firdaus,Naveen Thangavelu,Asif Ekbal,P. Bhattacharyya","id":"310ce0b1b4049206a260a711cc27cae5fad3700a","summary":"This work proposes a persona aware attention framework employing an encoder-decoder approach in which the system can generate specific and consistent responses in accordance to the provided personality information and the conversational history.","score":3},{"url":"https://www.semanticscholar.org/paper/9fb623c516994ba4ec1365db16afced31ac23520","title":"What If Bots Feel Moods?","venue":"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval","year":2020,"referenceCount":46,"citationCount":10,"influentialCitationCount":1,"publicationDate":"25/07/2020","authors":"L. Qiu,Yingwai Shiu,Pingping Lin,Ruihua Song,Yue Liu,Dongyan Zhao,Rui Yan","id":"9fb623c516994ba4ec1365db16afced31ac23520","summary":"An emotion-aware transition network is proposed to model the dynamic emotional flow and enhance context-response matching in retrieval-based dialogue systems with learnt intrinsic emotion features through a multi-task learning framework and is applied to a real IoT application.","score":3},{"url":"https://www.semanticscholar.org/paper/d8a0f9bb452bdd4408343d80336055d320cb6b1e","title":"Which Kind Is Better in Open-domain Multi-turn Dialog, Hierarchical or Non-hierarchical Models? An Empirical Study","venue":"ArXiv","year":2020,"referenceCount":32,"citationCount":0,"influentialCitationCount":0,"publicationDate":"07/08/2020","authors":"Tian Lan,Xian-Ling Mao,Wei Wei,Heyan Huang","id":"d8a0f9bb452bdd4408343d80336055d320cb6b1e","summary":"Nearly all hierarchical models are worse than non-hierarchical models in open-domain multi-turn dialog generation, except for the HRAN model, and the word-level attention mechanism is so powerful for hierarchical models is because it can leverage context information more effectively, especially the fine-grained information.","score":3},{"url":"https://www.semanticscholar.org/paper/63913530782522e0d7ca5deceb40c08d606cafab","title":"Deploying Lifelong Open-Domain Dialogue Learning","venue":"ArXiv","year":2020,"referenceCount":38,"citationCount":17,"influentialCitationCount":1,"publicationDate":"18/08/2020","authors":"Kurt Shuster,Jack Urbanek,Emily Dinan,Arthur D. Szlam,J. Weston","id":"63913530782522e0d7ca5deceb40c08d606cafab","summary":"This work builds and deploy a role-playing game, whereby human players converse with learning agents situated in an open-domain fantasy world and shows that by training models on the conversations they have with humans in the game the models progressively improve, as measured by automatic metrics and online engagement scores.","score":3},{"url":"https://www.semanticscholar.org/paper/c6d38e105562ae0a5d9b21fb4333212f36a3e041","title":"A Survey of Evaluation Metrics Used for NLG Systems","venue":"ACM Computing Surveys","year":2020,"referenceCount":209,"citationCount":69,"influentialCitationCount":6,"publicationDate":"27/08/2020","authors":"Ananya B. Sai,Akash Kumar Mohankumar,Mitesh M. Khapra","id":"c6d38e105562ae0a5d9b21fb4333212f36a3e041","summary":"This survey of automatic evaluation metrics for evaluating Natural Language Generation (NLG) systems highlights the challenges, proposes a coherent taxonomy for organising existing evaluation metrics, and briefly describes different existing metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/7d5b2388945b5ba53512ab775d80f4659092307f","title":"Towards Empathetic Dialogue Generation over Multi-type Knowledge.","venue":"","year":2020,"referenceCount":55,"citationCount":15,"influentialCitationCount":7,"publicationDate":"21/09/2020","authors":"Qintong Li,Piji Li,Zhumin Chen,Z. Ren","id":"7d5b2388945b5ba53512ab775d80f4659092307f","summary":"This work proposes to leverage multi-type knowledge, i.e, the commonsense knowledge and emotional lexicon, to explicitly understand and express emotions in empathetic dialogue generation, and introduces a multi- type knowledge-aware context encoder to learn emotional context representations and distill emotional signals.","score":3},{"url":"https://www.semanticscholar.org/paper/9c72b6a869cbec916d5e6b05c4ea36056c93c52c","title":"Spot the Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":40,"citationCount":20,"influentialCitationCount":2,"publicationDate":"05/10/2020","authors":"Jan Deriu,Don Tuggener,Pius von Däniken,Jon Ander Campos,Álvaro Rodrigo,Thiziri Belkacem,Aitor Soroa Etxabe,Eneko Agirre,Mark Cieliebak","id":"9c72b6a869cbec916d5e6b05c4ea36056c93c52c","summary":"A cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots, and incorporates a metric that measures which chatbot can uphold human-like behavior the longest, i.e., \\emph{Survival Analysis}.","score":3},{"url":"https://www.semanticscholar.org/paper/4236663e6416423fca02d5b058302adcb78f51f3","title":"COSMIC: COmmonSense knowledge for eMotion Identification in Conversations","venue":"Findings","year":2020,"referenceCount":45,"citationCount":103,"influentialCitationCount":28,"publicationDate":"06/10/2020","authors":"Deepanway Ghosal,Navonil Majumder,Alexander Gelbukh,Rada Mihalcea,Soujanya Poria","id":"4236663e6416423fca02d5b058302adcb78f51f3","summary":"This paper proposes COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation.","score":3},{"url":"https://www.semanticscholar.org/paper/ef3a96d8f42e8caa1994caba2e53ca98121b4d1f","title":"Plug-and-Play Conversational Models","venue":"Findings","year":2020,"referenceCount":65,"citationCount":37,"influentialCitationCount":6,"publicationDate":"09/10/2020","authors":"Andrea Madotto,Etsuko Ishii,Zhaojiang Lin,Sumanth Dathathri,Pascale Fung","id":"ef3a96d8f42e8caa1994caba2e53ca98121b4d1f","summary":"This paper proposes and evaluates plug-and-play methods for controllable response generation, and demonstrates a high degree of control over the generated conversational responses with regard to multiple desired attributes, while being fluent.","score":3},{"url":"https://www.semanticscholar.org/paper/314358d6e9969cb89da0ad0b6aa4f406294d3ff4","title":"Generalized Conditioned Dialogue Generation Based on Pre-trained Language Model","venue":"ArXiv","year":2020,"referenceCount":38,"citationCount":3,"influentialCitationCount":1,"publicationDate":"21/10/2020","authors":"Yan Zeng,J. Nie","id":"314358d6e9969cb89da0ad0b6aa4f406294d3ff4","summary":"This work proposes to complement the labeled dialogue data with labeled non-dialogue text data, and fine-tune BERT based on them, and utilizes BERT for both encoder and decoder via different input representations and self-attention masks in order to distinguish the source and target side.","score":3},{"url":"https://www.semanticscholar.org/paper/0f8cb4a6c794ee18d5f9177782cf07d000adffca","title":"An Evaluation Protocol for Generative Conversational Systems","venue":"ArXiv","year":2020,"referenceCount":52,"citationCount":4,"influentialCitationCount":1,"publicationDate":"24/10/2020","authors":"Seolhwa Lee,Heuiseok Lim,João Sedoc","id":"0f8cb4a6c794ee18d5f9177782cf07d000adffca","summary":"The findings show that DialoGPT and Blender are superior systems using Bradley-Terry model and TrueSkill ranking methods and demonstrate the feasibility of the protocol for the evaluation of conversational models using head-to-head pairwise comparison.","score":3},{"url":"https://www.semanticscholar.org/paper/240f3eb516051b1e9f5baced99855e8495a1298a","title":"A Taxonomy of Empathetic Response Intents in Human Social Conversations","venue":"International Conference on Computational Linguistics","year":2020,"referenceCount":60,"citationCount":39,"influentialCitationCount":5,"publicationDate":"01/12/2020","authors":"A. Welivita,P. Pu","id":"240f3eb516051b1e9f5baced99855e8495a1298a","summary":"A large-scale taxonomy for empathetic response intents is produced and novel and important empathy patterns in human-human open-domain conversations are revealed and can serve as heuristics for hybrid approaches.","score":3},{"url":"https://www.semanticscholar.org/paper/0e635104e5378bc226b0e07e429fcef44f959fc8","title":"Robust Dialogue Utterance Rewriting as Sequence Tagging","venue":"ArXiv","year":2020,"referenceCount":29,"citationCount":6,"influentialCitationCount":2,"publicationDate":"29/12/2020","authors":"Jie Hao,Linfeng Song,Liwei Wang,Kun Xu,Zhaopeng Tu,Dong Yu","id":"0e635104e5378bc226b0e07e429fcef44f959fc8","summary":"A novel sequence-taggingbased model is proposed so that the search space is significantly reduced, yet the core of this task is still well covered, and the model’s outputs may lack fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/6c48cedd98da74f4e1b29dc89aafd3c374e069fa","title":"Context-Controlled Topic-Aware Neural Response Generation for Open-Domain Dialog Systems","venue":"Information Processing & Management","year":2021,"referenceCount":53,"citationCount":19,"influentialCitationCount":0,"publicationDate":2021,"authors":"Yanxiang Ling,Fei Cai,Xuejun Hu,Jun Liu,Wanyu Chen,Honghui Chen","id":"6c48cedd98da74f4e1b29dc89aafd3c374e069fa","summary":"A Context-Controlled Topic-Aware neural response generation model, i.e., CCTA, which makes dialog context interact with the process of topic representing and transiting to achieve balanced improvements on response informativeness and contextual coherence and finds that topic transition modeling can work as an auxiliary learning task to boost the response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/b7a64a22f69a17ea0b007f7748580f7641b55cb6","title":"Dialogue in the Wild: Learning from a Deployed Role-Playing Game with Humans and Bots","venue":"Findings","year":2021,"referenceCount":36,"citationCount":8,"influentialCitationCount":0,"publicationDate":2021,"authors":"Kurt Shuster,Jack Urbanek,Emily Dinan,Arthur D. Szlam,J. Weston","id":"b7a64a22f69a17ea0b007f7748580f7641b55cb6","summary":"This work builds and deploy a role-playing game, whereby human players converse with learning agents situated in an open-domain fantasy world and shows that by training models on the conversations they have with humans in the game the models progressively improve, as measured by automatic metrics and online engagement scores.","score":3},{"url":"https://www.semanticscholar.org/paper/9588603547d14c81beca87f6de399334b8d3645d","title":"Enhancing the Open-Domain Dialogue Evaluation in Latent Space","venue":"Findings","year":2021,"referenceCount":51,"citationCount":7,"influentialCitationCount":0,"publicationDate":2021,"authors":"Zhangming Chan,Lemao Liu,Juntao Li,Haisong Zhang,Dongyan Zhao,Shuming Shi,Rui Yan","id":"9588603547d14c81beca87f6de399334b8d3645d","summary":"Experimental results on two real-world dialogue datasets confirm the superiority of the self-supervised method for open-domain dialogue evaluation, where both Pearson and Spearman correlations with human judgments outperform all baselines.","score":3},{"url":"https://www.semanticscholar.org/paper/1466200bb780899d5899ea7862a418039cf48131","title":"Projection of Turn Completion in Incremental Spoken Dialogue Systems","venue":"SIGDIAL Conferences","year":2021,"referenceCount":53,"citationCount":1,"influentialCitationCount":0,"publicationDate":2021,"authors":"Erik Ekstedt,Gabriel Skantze","id":"1466200bb780899d5899ea7862a418039cf48131","summary":"This work implements a mechanism to achieve fast response times by projecting what the interlocutor will say and estimating upcoming turn completions in an incremental spoken dialog system, by using a language model that generates possible futures to project upcoming completion points.","score":3},{"url":"https://www.semanticscholar.org/paper/89ba86c751e6fe6759c4f8cb07b6784adb117aeb","title":"SEPRG: Sentiment aware Emotion controlled Personalized Response Generation","venue":"International Conference on Natural Language Generation","year":2021,"referenceCount":51,"citationCount":1,"influentialCitationCount":0,"publicationDate":2021,"authors":"Mauajama Firdaus,U. Jain,Asif Ekbal,P. Bhattacharyya","id":"89ba86c751e6fe6759c4f8cb07b6784adb117aeb","summary":"Experimental results on the PersonaChat dataset show that the proposed framework significantly outperforms the existing baselines, thereby generating personalized emotional responses in accordance with the sentiment that provides better emotional connection and user satisfaction as desired in a social chatbot.","score":3},{"url":"https://www.semanticscholar.org/paper/56dc1ce4df5ce80a48743be8ebd38025bdba24bf","title":"RAST: Domain-Robust Dialogue Rewriting as Sequence Tagging","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":39,"citationCount":6,"influentialCitationCount":0,"publicationDate":2021,"authors":"Jie Hao,Linfeng Song,Liwei Wang,Kun Xu,Zhaopeng Tu,Dong Yu","id":"56dc1ce4df5ce80a48743be8ebd38025bdba24bf","summary":"A novel sequence-tagging-based model is proposed so that the search space is significantly reduced, yet the core of this task is still well covered, and the model’s outputs may lack fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/ca7570353bab859f515e9599bc38defc6ec40e98","title":"Less is more : An Empirical Analysis of Model Compression for Dialogue","venue":"","year":2021,"referenceCount":55,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"","id":"ca7570353bab859f515e9599bc38defc6ec40e98","summary":"This work performs an empirical evaluation of three model compression techniques on conversational agents specif-ically pre-trained on large language transformer networks using OpenAI GPT-2 transformer network to evaluate and compare the performance of open-domain dialogue models before and after undergoing compression.","score":3},{"url":"https://www.semanticscholar.org/paper/f6d0321e0a0447da0af4f4d8cafaff0704005116","title":"Anna: A Dapper Open-Domain Dialogue Agent Based on a Joint Attention Network","venue":"Journal of Natural Language Processing","year":2021,"referenceCount":38,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"Itsugun Cho,Hiroaki Saito","id":"f6d0321e0a0447da0af4f4d8cafaff0704005116","summary":"A high-quality open-domain dialogue generation model called Anna that is composed of a hierarchical self-attention network with multiple convolution filters and a topic-augmented network that outperforms baseline models in terms of response quality, parameter size and decoding speed.","score":3},{"url":"https://www.semanticscholar.org/paper/70af4173983eccc0beac29ed4602bf9db5568b92","title":"PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning","venue":"Findings","year":2020,"referenceCount":59,"citationCount":84,"influentialCitationCount":13,"publicationDate":"30/06/2020","authors":"Siqi Bao,H. He,Fan Wang,Hua Wu,Haifeng Wang,Wenquan Wu,Zhen Guo,Zhibin Liu,Xinchao Xu","id":"70af4173983eccc0beac29ed4602bf9db5568b92","summary":"To build a high-quality open-domain chatbot, this work introduces the effective training process of PLATO-2 via curriculum learning, achieving new state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/fa544c82344a556b69316f05f2ea6f51fa202139","title":"The Adapter-Bot: All-In-One Controllable Conversational Model","venue":"AAAI Conference on Artificial Intelligence","year":2020,"referenceCount":75,"citationCount":40,"influentialCitationCount":2,"publicationDate":"28/08/2020","authors":"Andrea Madotto,Zhaojiang Lin,Yejin Bang,Pascale Fung","id":"fa544c82344a556b69316f05f2ea6f51fa202139","summary":"The Adapter-Bot is presented, a generative chat-bot that uses a fixed backbone conversational model such as DialGPT and triggers on-demand dialogue skills via different adapters that can be trained independently, thus allowing a continual integration of skills without retraining the entire model.","score":3},{"url":"https://www.semanticscholar.org/paper/983921bd0ccaee71df7580ce13dd0d53dba5f368","title":"Empathetic BERT2BERT Conversational Model: Learning Arabic Language Generation with Little Data","venue":"Workshop on Arabic Natural Language Processing","year":2021,"referenceCount":34,"citationCount":7,"influentialCitationCount":1,"publicationDate":"07/03/2021","authors":"Tarek Naous,Wissam Antoun,Reem A. Mahmoud,Hazem M. Hajj","id":"983921bd0ccaee71df7580ce13dd0d53dba5f368","summary":"A transformer-based encoder-decoder initialized with AraBERT parameters is proposed, validating its high capability in exhibiting empathy while generating relevant and fluent responses in open-domain settings.","score":3},{"url":"https://www.semanticscholar.org/paper/5b41b3c31edb20f7b08ebb8fa49b9d0887f01a3c","title":"Enhancing Cognitive Models of Emotions with Representation Learning","venue":"Workshop on Cognitive Modeling and Computational Linguistics","year":2021,"referenceCount":27,"citationCount":1,"influentialCitationCount":0,"publicationDate":"20/04/2021","authors":"Yuting Guo,Jinho D. Choi","id":"5b41b3c31edb20f7b08ebb8fa49b9d0887f01a3c","summary":"A novel deep learning-based framework to generate embedding representations of fine-grained emotions that can be used to computationally describe psychological models of emotions that enables to interpret dynamically learned representations optimized for an emotion classification task.","score":3},{"url":"https://www.semanticscholar.org/paper/f4bef31094420c572e6c4159c45234c741d9e5bf","title":"Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":23,"citationCount":14,"influentialCitationCount":0,"publicationDate":"25/05/2021","authors":"Tatsuya Ide,Daisuke Kawahara","id":"f4bef31094420c572e6c4159c45234c741d9e5bf","summary":"This model based on BART, a pre-trained transformer encoder-decoder model, is trained to generate responses and recognize emotions simultaneously, and weight the losses for the tasks to control the update of parameters.","score":3},{"url":"https://www.semanticscholar.org/paper/a7a00e14c60fd13bf08dc435e9b0fdd96d050b99","title":"Generating Negative Samples by Manipulating Golden Responses for Unsupervised Learning of a Response Evaluation Model","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":28,"citationCount":2,"influentialCitationCount":0,"publicationDate":"01/06/2021","authors":"chaeHun Park,Eugene Jang,Wonsuk Yang,Jong C. Park","id":"a7a00e14c60fd13bf08dc435e9b0fdd96d050b99","summary":"It is found that using the negative samples generated by the unsupervised learning of a golden response to create a new negative response that is designed to be inappropriate within the context while maintaining high similarity with the original golden response can increase the model's correlation with human evaluations.","score":3},{"url":"https://www.semanticscholar.org/paper/87102d1054611d8cf8bc4e743516ef3a613766ac","title":"A Simple and Efficient Multi-Task Learning Approach for Conditioned Dialogue Generation","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":39,"citationCount":8,"influentialCitationCount":1,"publicationDate":"01/06/2021","authors":"Yan Zeng,J. Nie","id":"87102d1054611d8cf8bc4e743516ef3a613766ac","summary":"This work proposes a multi-task learning approach to leverage both labeled dialogue and text data, which outperforms the state-of-the-art models by leveraging the labeled texts, and it obtains larger improvement in performance comparing to the previous methods to leverage text data.","score":3},{"url":"https://www.semanticscholar.org/paper/c8419114a8972e4945052e9699b69dfa858ab17c","title":"Towards Quantifiable Dialogue Coherence Evaluation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":29,"citationCount":4,"influentialCitationCount":0,"publicationDate":"01/06/2021","authors":"Zheng Ye,Liucun Lu,Lishan Huang,Liang Lin,Xiaodan Liang","id":"c8419114a8972e4945052e9699b69dfa858ab17c","summary":"Experimental results show that the model trained by QuantiDCE presents stronger correlations with human judgements than the other state-of-the-art metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/753baa88a7f49f6605ae30f77a54dbb9e074c8b4","title":"DynaEval: Unifying Turn and Dialogue Level Evaluation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":61,"citationCount":24,"influentialCitationCount":5,"publicationDate":"02/06/2021","authors":"Chen Zhang,Yiming Chen,L. F. D’Haro,Yan Zhang,Thomas Friedrichs,Grandee Lee,Haizhou Li","id":"753baa88a7f49f6605ae30f77a54dbb9e074c8b4","summary":"DynaEval, a unified automatic evaluation framework which is not only capable of performing turn-level evaluation, but also holistically considers the quality of the entire dialogue, is proposed.","score":3},{"url":"https://www.semanticscholar.org/paper/d08a6a41e2b16928a1dc93b259bffbe37dae021d","title":"Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation","venue":"Findings","year":2021,"referenceCount":93,"citationCount":12,"influentialCitationCount":2,"publicationDate":"10/06/2021","authors":"Prakhar Gupta,Yulia Tsvetkov,Jeffrey P. Bigham","id":"d08a6a41e2b16928a1dc93b259bffbe37dae021d","summary":"This work proposes mask-and-fill and keyword-guided approaches that generate negative examples for training more robust dialogue systems and proposes approaches for automatically creating adversarial negative training data to help ranking and evaluation models learn features beyond content similarity.","score":3},{"url":"https://www.semanticscholar.org/paper/8f31038de5cadc3171735c0410511c044d216463","title":"Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":18,"citationCount":4,"influentialCitationCount":1,"publicationDate":"19/07/2021","authors":"Nyoungwoo Lee,Suwon Shin,J. Choo,Ho‐Jin Choi,S. Myaeng","id":"8f31038de5cadc3171735c0410511c044d216463","summary":"Automatic metrics and human evaluation results show that the proposed 45k multi-modal dialogue dataset can be effectively used as training data for multi- modal dialogue systems which require an understanding of images and text in a context-aware manner.","score":3},{"url":"https://www.semanticscholar.org/paper/9f54b02d32835a6dc977a335444df707494763ec","title":"Proto: A Neural Cocktail for Generating Appealing Conversations","venue":"ArXiv","year":2021,"referenceCount":38,"citationCount":6,"influentialCitationCount":0,"publicationDate":"06/09/2021","authors":"Sougata Saha,Souvik Das,Elizabeth Soper,Erin Pacquetet,R. Srihari","id":"9f54b02d32835a6dc977a335444df707494763ec","summary":"This paper dissect and analyze the different components and conversation strategies implemented by the socialbot, which enables it to generate colloquial, empathetic, engaging, self-rectifying, factually correct, and on-topic response, which has helped it achieve consistent scores throughout the competition.","score":3},{"url":"https://www.semanticscholar.org/paper/91aca4acc06348c67df00180191d02297c563d9f","title":"Empathetic Dialogue Generation with Pre-trained RoBERTa-GPT2 and External Knowledge","venue":"International Workshop on Spoken Dialogue Systems Technology","year":2021,"referenceCount":43,"citationCount":4,"influentialCitationCount":2,"publicationDate":"07/09/2021","authors":"Ye Liu,Wolfgang Maier,W. Minker,Stefan Ultes","id":"91aca4acc06348c67df00180191d02297c563d9f","summary":"To enable the empathetic ability of RoBERTaGPT2 model, this work proposes a commonsense knowledge and emotional concepts extractor, in which the commonsensible andotional concepts of dialogue context are extracted for the GPT-2 decoder.","score":3},{"url":"https://www.semanticscholar.org/paper/690edf89431f26d355fc4a991a489d9d080e1ebe","title":"Alquist 4.0: Towards Social Intelligence Using Generative Models and Dialogue Personalization","venue":"ArXiv","year":2021,"referenceCount":30,"citationCount":8,"influentialCitationCount":0,"publicationDate":"16/09/2021","authors":"Jakub Konrád,Jan Pichl,Petro Marek,Petr Lorenc,Van Duy Ta,Ondrej Kobza,L. Hýlová,J. Sedivý","id":"690edf89431f26d355fc4a991a489d9d080e1ebe","summary":"The principles and inner workings of individual components of the open-domain dialogue system Alquist developed within the Alexa Prize Socialbot Grand Challenge 4 are presented and the experiments conducted to evaluate them are presented.","score":3},{"url":"https://www.semanticscholar.org/paper/30873c32db5a219a58be928d5692cce48be1d3a0","title":"Few-Shot Bot: Prompt-Based Learning for Dialogue Systems","venue":"ArXiv","year":2021,"referenceCount":116,"citationCount":24,"influentialCitationCount":5,"publicationDate":"15/10/2021","authors":"Andrea Madotto,Zhaojiang Lin,Genta Indra Winata,Pascale Fung","id":"30873c32db5a219a58be928d5692cce48be1d3a0","summary":"An end-to-end chatbot named the Few-Shot Bot is created, which automatically selects the most appropriate conversational skill, queries different knowledge bases or the internet, and uses the retrieved knowledge to generate a human-like response, all using only few dialogue examples per skill.","score":3},{"url":"https://www.semanticscholar.org/paper/84363d3326105df2d297898e411be02b62e7df63","title":"Modeling Performance in Open-Domain Dialogue with PARADISE","venue":"ArXiv","year":2021,"referenceCount":65,"citationCount":2,"influentialCitationCount":0,"publicationDate":"21/10/2021","authors":"M. Walker,Colin Harmon,James Graupera,Davan Harrison,S. Whittaker","id":"84363d3326105df2d297898e411be02b62e7df63","summary":"A PARADISE model is developed for predicting the performance of Athena, a dialogue system that has participated in thousands of conversations with real users, while competing as a finalist in the Alexa Prize.","score":3},{"url":"https://www.semanticscholar.org/paper/54e00dfd4821b0b21bb4e8392336a8c8ac062d43","title":"Conversational Agents: Goals, Technologies, Vision and Challenges","venue":"Italian National Conference on Sensors","year":2021,"referenceCount":254,"citationCount":10,"influentialCitationCount":1,"publicationDate":"01/12/2021","authors":"Merav Allouch,A. Azaria,Rina Azoulay-Schwartz","id":"54e00dfd4821b0b21bb4e8392336a8c8ac062d43","summary":"The main areas in which CAs are successful are described along with the main technologies that enable the creation of CAs and the primary tools and datasets that may be useful for the development and evaluation ofCAs of different categories are described.","score":3},{"url":"https://www.semanticscholar.org/paper/cddd04ca1810214a4bd17a39650043fd663eb373","title":"Neural Network With Hierarchical Attention Mechanism for Contextual Topic Dialogue Generation","venue":"IEEE Access","year":2022,"referenceCount":39,"citationCount":1,"influentialCitationCount":0,"publicationDate":2022,"authors":"Xiao Sun,Bingbing Ding","id":"cddd04ca1810214a4bd17a39650043fd663eb373","summary":"This work improves upon existing models and attention mechanisms and proposes a new hierarchical model to better solve the problem of dialogue context (the HAT model), which enables the model to obtain more contextual information when processing and improves the ability of the model in terms of contextual relevance to produce high-quality responses.","score":3},{"url":"https://www.semanticscholar.org/paper/eb1ac44bbc0fe07c5f31f459c7199211239e90b8","title":"Open-domain Dialogue Generation: What We Can Do, Cannot Do, And Should Do Next","venue":"NLP4CONVAI","year":2022,"referenceCount":146,"citationCount":5,"influentialCitationCount":0,"publicationDate":2022,"authors":"Katharina Kann,Abteen Ebrahimi,Joewie J. Koh,Shiran Dudy,A. Roncone","id":"eb1ac44bbc0fe07c5f31f459c7199211239e90b8","summary":"The goal of this work is to provide an overview of recent advances in the field of open-domain dialogue, to summarize issues related to ethics, bias, and fairness that the field has identified as well as typical errors of dialogue systems and to outline important future challenges.","score":3},{"url":"https://www.semanticscholar.org/paper/d2bc6012afd5ea0eaf3b4f5484c179f465cbb66c","title":"SHONGLAP: A Large Bengali Open-Domain Dialogue Corpus","venue":"International Conference on Language Resources and Evaluation","year":2022,"referenceCount":49,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Syed Mostofa Monsur,Sakib Chowdhury,Shahrar Fatemi,Shafayat Ahmed","id":"d2bc6012afd5ea0eaf3b4f5484c179f465cbb66c","summary":"Experimental results show that the SHONGLAP corpus improves performance of large language models (BanglaBERT) in case of downstream classification tasks during fine-tuning and can serve as a strong baseline for future works.","score":3},{"url":"https://www.semanticscholar.org/paper/fa26b1182d1a76ad550694b57ba1d6afe73e238d","title":"Automatic Generation of Large-scale Multi-turn Dialogues from Reddit","venue":"International Conference on Computational Linguistics","year":2022,"referenceCount":19,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Daniil Huryn,William M. Hutsell,Jinho D. Choi","id":"fa26b1182d1a76ad550694b57ba1d6afe73e238d","summary":"Novel methods to automatically convert posts and their comments from discussion forums such as Reddit into multi-turn dialogues are presented, which are generalizable to any forums and allow for a massive amount of dialogues for diverse topics that can be used to pretrain language models.","score":3},{"url":"https://www.semanticscholar.org/paper/01caaf3a67ad31c93048a29fff90e62ad3dac167","title":"Knowledge Bridging for Empathetic Dialogue Generation","venue":"AAAI Conference on Artificial Intelligence","year":2020,"referenceCount":49,"citationCount":18,"influentialCitationCount":7,"publicationDate":"21/09/2020","authors":"Qintong Li,Pijian Li,Z. Ren,Pengjie Ren,Zhumin Chen","id":"01caaf3a67ad31c93048a29fff90e62ad3dac167","summary":"This work proposes to leverage external knowledge, including commonsense knowledge and emotional lexical knowledge, to explicitly understand and express emotions in empathetic dialogue generation to address the problems of lack of external knowledge and limited dialogue history.","score":3},{"url":"https://www.semanticscholar.org/paper/88064de690af282dbdf222774f03ff070b9df22b","title":"Beyond Goldfish Memory: Long-Term Open-Domain Conversation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":39,"citationCount":72,"influentialCitationCount":19,"publicationDate":"15/07/2021","authors":"Jing Xu,Arthur D. Szlam,J. Weston","id":"88064de690af282dbdf222774f03ff070b9df22b","summary":null,"score":3},{"url":"https://www.semanticscholar.org/paper/3af37400f1f9a4f4f211c4a472e18963edc2b34f","title":"ValueNet: A New Dataset for Human Value Driven Dialogue System","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":47,"citationCount":7,"influentialCitationCount":0,"publicationDate":"12/12/2021","authors":"Liang Qiu,Yizhou Zhao,Jinchao Li,Pan Lu,Baolin Peng,Jianfeng Gao,Song-Chun Zhu","id":"3af37400f1f9a4f4f211c4a472e18963edc2b34f","summary":"This work presents a new large-scale human value dataset called ValueNet, which contains human attitudes on 21,374 text scenarios and is the first one trying to incorporate a value model into emotionally intelligent dialogue systems.","score":3},{"url":"https://www.semanticscholar.org/paper/c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7","title":"Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":54,"citationCount":6,"influentialCitationCount":5,"publicationDate":"16/12/2021","authors":"Yoonna Jang,J. Lim,Yuna Hur,Dongsuk Oh,Suhyune Son,Yeonsoo Lee,Donghoon Shin,Seungryong Kim,Heuiseok Lim","id":"c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7","summary":"This work introduces a call For Customized conversation (FoCus) dataset where the customized answers are built with the user's persona and Wikipedia knowledge and shows that the utterances of the data are constructed with the proper knowledge and persona through grounding quality assessment.","score":3},{"url":"https://www.semanticscholar.org/paper/e0af8f2dd390fabcdf2c373640833efc62faa530","title":"FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":48,"citationCount":2,"influentialCitationCount":0,"publicationDate":"14/02/2022","authors":"Jianqiao Zhao,Yanyang Li,Wanyu Du,Yangfeng Ji,Dong Yu,M. Lyu,Liwei Wang","id":"e0af8f2dd390fabcdf2c373640833efc62faa530","summary":"This work develops the first consensus-based dialogue evaluation framework, FlowEval, which provides a reference-free approach for dialog evaluation by finding pseudo-references and proposes segment act, an extension of dialog act from utterance level to segment level, and crowdsource a large-scale dataset for it.","score":3},{"url":"https://www.semanticscholar.org/paper/c8fba3d80a3b6add6fb386f458850d02b77f34bb","title":"Generating Relevant and Informative Questions for Open-Domain Conversations","venue":"ACM Transactions on Information Systems","year":2022,"referenceCount":80,"citationCount":0,"influentialCitationCount":0,"publicationDate":"14/02/2022","authors":"Yanxiang Ling,Fei Cai,Jun Liu,Honghui Chen,M. de Rijke","id":"c8fba3d80a3b6add6fb386f458850d02b77f34bb","summary":"A context-enhanced neural question generation model that leverages the conversational context to predict question content and pattern, then performs question decoding, and is the first to extend the application of QG to the multi-turn open-domain conversational scenario.","score":3},{"url":"https://www.semanticscholar.org/paper/d73d3a82da0bc93be238c286abfd06722247d298","title":"Rethinking and Refining the Distinct Metric","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":51,"citationCount":2,"influentialCitationCount":1,"publicationDate":"28/02/2022","authors":"Siyang Liu,Sahand Sabour,Yinhe Zheng,Pei Ke,Xiaoyan Zhu,Minlie Huang","id":"d73d3a82da0bc93be238c286abfd06722247d298","summary":"This work refine the calculation of distinct scores by scaling the number of distinct tokens based on their expectations, and shows that the proposed metric, Expectation-Adjusted Distinct (EAD), correlates better with human judgment in evaluating response diversity.","score":3},{"url":"https://www.semanticscholar.org/paper/1e704b99a04aad6d6d7e665616b7d4ed2513da02","title":"Probing the Robustness of Trained Metrics for Conversational Dialogue Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":19,"citationCount":2,"influentialCitationCount":0,"publicationDate":"28/02/2022","authors":"Jan Deriu,Don Tuggener,Pius von Daniken,Mark Cieliebak","id":"1e704b99a04aad6d6d7e665616b7d4ed2513da02","summary":"An adversarial method to stress-test trained metrics for the evaluation of conversational dialogue systems using Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics is introduced.","score":3},{"url":"https://www.semanticscholar.org/paper/4ebff21b83277a523d9ce84c5cc745074b1f642e","title":"MISC: A Mixed Strategy-Aware Model integrating COMET for Emotional Support Conversation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":58,"citationCount":10,"influentialCitationCount":4,"publicationDate":"25/03/2022","authors":"Quan Tu,Yanran Li,Jianwei Cui,Bin Wang,Jiaxin Wen,Rui Yan","id":"4ebff21b83277a523d9ce84c5cc745074b1f642e","summary":"A novel model is proposed, which firstly infers the user’s fine-grained emotional status, and then responds skillfully using a mixture of strategy, which reveals the benefits of fine- grained emotion understanding as well as mixed-up strategy modeling.","score":3},{"url":"https://www.semanticscholar.org/paper/aab1dead436211a7d9eb7a717ee63a5d23cf23f0","title":"Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional Characters with only a Few Utterances","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":58,"citationCount":5,"influentialCitationCount":1,"publicationDate":"22/04/2022","authors":"Seungju Han,Beomsu Kim,Jin Yong Yoo,Seokjun Seo,Sangbum Kim,Enkhbayar Erdenee,Buru Chang","id":"aab1dead436211a7d9eb7a717ee63a5d23cf23f0","summary":"A new method named Pseudo Dialog Prompting (PDP) is proposed that generates responses by leveraging the power of large-scale language models with prompts containing the target character’s utterances to better reflect the style of fictional characters.","score":3},{"url":"https://www.semanticscholar.org/paper/32f87b51e3ba42894821716b8145bde41fc65983","title":"Semantic Diversity in Dialogue with Natural Language Inference","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":36,"citationCount":2,"influentialCitationCount":0,"publicationDate":"03/05/2022","authors":"Katherine Stasaski,Marti A. Hearst","id":"32f87b51e3ba42894821716b8145bde41fc65983","summary":"It is shown that the contradiction relation is more useful than the neutral relation for measuring this diversity and that incorporating the NLI model’s confidence achieves state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/77ced33cba86b4d01fbfe6622c8f564c89d6a1b3","title":"A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration","venue":"ArXiv","year":2022,"referenceCount":39,"citationCount":3,"influentialCitationCount":0,"publicationDate":"05/05/2022","authors":"Shaojie Jiang,Ruqing Zhang,Svitlana Vakulenko,M. de Rijke","id":"77ced33cba86b4d01fbfe6622c8f564c89d6a1b3","summary":"Comprehensive experiments on language modeling and open-domain dialogue generation tasks show that the proposed contrastive token objective yields less repetitive texts, with a higher generation quality than unlikelihood training, achieving the new state-of-the-art performance.","score":3},{"url":"https://www.semanticscholar.org/paper/086f3f9f023f0127f4be03a21189a1e90ffbb01f","title":"Empathetic Conversational Systems: A Review of Current Advances, Gaps, and Opportunities","venue":"IEEE Transactions on Affective Computing","year":2022,"referenceCount":132,"citationCount":1,"influentialCitationCount":0,"publicationDate":"09/05/2022","authors":"Aravind Sesagiri Raamkumar,Yinping Yang","id":"086f3f9f023f0127f4be03a21189a1e90ffbb01f","summary":"It is recommended that future studies should address key gaps in areas of detecting and authenticating emotions at the entity level, handling multimodal inputs, displaying more nuanced empathetic behaviors, and encompassing additional dialogue system features.","score":3},{"url":"https://www.semanticscholar.org/paper/d69ec0bbc9fc4fe898ac8cb73f629d253358bf66","title":"Stop Filtering: Multi-View Attribute-Enhanced Dialogue Learning","venue":"ArXiv","year":2022,"referenceCount":67,"citationCount":1,"influentialCitationCount":0,"publicationDate":"23/05/2022","authors":"Yiwei Li,Bin Sun,Shaoxiong Feng,Kan Li","id":"d69ec0bbc9fc4fe898ac8cb73f629d253358bf66","summary":"A multi-view attribute-enhanced dialogue learning framework that strengthens the attribute-related features more robustly and comprehensively and can improve the performance of models by enhancing dialogue attributes and fusing view-speciﬁc knowledge.","score":3},{"url":"https://www.semanticscholar.org/paper/d6a60f41e6e53469042259ce3c281907907c0993","title":"Building a Dialogue Corpus Annotated with Expressed and Experienced Emotions","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":26,"citationCount":1,"influentialCitationCount":0,"publicationDate":"24/05/2022","authors":"Tatsuya Ide,Daisuke Kawahara","id":"d6a60f41e6e53469042259ce3c281907907c0993","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/36c50e6638dddc8324eef9bfa064bfcab80cbef4","title":"ProsocialDialog: A Prosocial Backbone for Conversational Agents","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":56,"citationCount":13,"influentialCitationCount":4,"publicationDate":"25/05/2022","authors":"Hyunwoo Kim,Youngjae Yu,Liwei Jiang,Ximing Lu,Daniel Khashabi,Gunhee Kim,Yejin Choi,Maarten Sap","id":"36c50e6638dddc8324eef9bfa064bfcab80cbef4","summary":"This work introduces ProsocialDialog, the first large-scale multi-turn dialogue dataset to teach conversational agents to respond to problematic content following social norms, and introduces a dialogue safety detection module, Canary, capable of generating RoTs given conversational context, and a socially-informed dialogue agent, Prost.","score":3},{"url":"https://www.semanticscholar.org/paper/cb1ecd3a14c5a65c3f887cfd3072bc05f1eea70c","title":"CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI","venue":"ArXiv","year":2022,"referenceCount":85,"citationCount":1,"influentialCitationCount":0,"publicationDate":"29/05/2022","authors":"Yirong Chen,Weiquan Fan,Xiaofen Xing,Jianxin Pang,Minlie Huang,W. Han,Qianfeng Tie,Xiangmin Xu","id":"cb1ecd3a14c5a65c3f887cfd3072bc05f1eea70c","summary":"The proposed CPED, a large-scale Chinese personalized and emotional dialogue dataset, which consists of multi-source knowledge related to empathy and personal char- acteristic is proposed, to be widely adopted by the NLP community as a new open benchmark for conversational AI research.","score":3},{"url":"https://www.semanticscholar.org/paper/e86869d44e78d4cffd1bf1b62f2f8e56a519e23c","title":"E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation","venue":"ArXiv","year":2022,"referenceCount":83,"citationCount":8,"influentialCitationCount":0,"publicationDate":"30/05/2022","authors":"Qihuang Zhong,Liang Ding,Juhua Liu,Bo Du,Dacheng Tao","id":"e86869d44e78d4cffd1bf1b62f2f8e56a519e23c","summary":"This work proposes an encoding-enhancedseq2seq pretraining strategy, namely E2S2, which improves the seq2seq models via integrating more efﬁcient self-supervised information into the encoders, and proves that the encoder takes an important but under-exploitation role than the decoder regarding the downstream performance and neuron activation.","score":3},{"url":"https://www.semanticscholar.org/paper/45645b392ce5cd914007b5ae2c572c0cd591e835","title":"Emotion Recognition in Conversation using Probabilistic Soft Logic","venue":"ArXiv","year":2022,"referenceCount":41,"citationCount":0,"influentialCitationCount":0,"publicationDate":"14/07/2022","authors":"Eriq Augustine,Pegah Jandaghi,Alon Albalak,Connor Pryor,Charles Dickens,William Wang,L. Getoor","id":"45645b392ce5cd914007b5ae2c572c0cd591e835","summary":"This work explores an approach to ERC that exploits the use of neural embeddings along with complex structures in dialogues, and implements it in a framework called Probabilistic Soft Logic (PSL), a declarative templating language that uses logical rules that when combined with data, combine to form a particular class of graphical model.","score":3},{"url":"https://www.semanticscholar.org/paper/5c474c68dea579784eb61f84c6250d3d22dfc485","title":"Towards a sentiment-aware conversational agent","venue":"International Conference on Intelligent Virtual Agents","year":2022,"referenceCount":39,"citationCount":0,"influentialCitationCount":0,"publicationDate":"24/07/2022","authors":"Isabel Dias,Ricardo Rei,Patrícia Pereira,Luísa Coheur","id":"5c474c68dea579784eb61f84c6250d3d22dfc485","summary":"Results show that explicitly guiding the text generation model with a pre-defined set of sentiment sentences leads to clear improvements, regarding the expressed sentiment and the quality of the generated text.","score":3},{"url":"https://www.semanticscholar.org/paper/1c25b49fb6a2789597320a9e3591a6e51f1ed6ed","title":"Neural Generation Meets Real People: Building a Social, Informative Open-Domain Dialogue Agent","venue":"SIGDIAL Conferences","year":2022,"referenceCount":71,"citationCount":1,"influentialCitationCount":0,"publicationDate":"25/07/2022","authors":"Ethan A. Chi,Ashwin Paranjape,A. See,Caleb Chiam,Kathleen Kenealy,Swee Kiat Lim,Amelia Hardy,Chetanya Rastogi,Hao Li,Alexander Iyabor,Yutong He,Hari Sowrirajan,Peng Qi,Kaushik Ram Sadagopan,Nguyet Minh Phu,Dilara Soylu,Jillian Tang,A. Narayan,Giovanni Campagna,Christopher D. Manning","id":"1c25b49fb6a2789597320a9e3591a6e51f1ed6ed","summary":"Aiming to be both informative and conversational, the Chirpy Cardinal bot chats with users in an authentic, emotionally intelligent way by integrating controlled neural generation with scaffolded, hand-written dialogue, producing an engaging and socially fluent experience.","score":3},{"url":"https://www.semanticscholar.org/paper/b0e7055fcbb33e0cf1a93a27b483db66a57ffd5b","title":"A Systematic Evaluation of Response Selection for Open Domain Dialogue","venue":"SIGDIAL Conferences","year":2022,"referenceCount":41,"citationCount":1,"influentialCitationCount":1,"publicationDate":"08/08/2022","authors":"Behnam Hedayatnia,Di Jin,Yang Liu,Dilek Z. Hakkani-Tür","id":"b0e7055fcbb33e0cf1a93a27b483db66a57ffd5b","summary":"This work curated a dataset where responses from multiple response generators produced for the same dialog context are manually annotated as appropriate (positive) and inappropriate (negative) and argues that such training data better matches the actual use case examples, enabling the models to learn to rank responses effectively.","score":3},{"url":"https://www.semanticscholar.org/paper/9a1e0b8cc7a94dbe3929bb350bd04f5017a88515","title":"Building the Intent Landscape of Real-World Conversational Corpora with Extractive Question-Answering Transformers","venue":"ArXiv","year":2022,"referenceCount":44,"citationCount":0,"influentialCitationCount":0,"publicationDate":"26/08/2022","authors":"Jean-Philippe Corbeil,Mia Taige Li,H. Ghavidel","id":"9a1e0b8cc7a94dbe3929bb350bd04f5017a88515","summary":"This work proposes an unsupervised pipeline that extracts the intents and the taxonomy of intents from real-world dialogues and demonstrates the generalization ability of an ELECTRA large model tuned on the SQuAD2 dataset to understand dialogues.","score":3},{"url":"https://www.semanticscholar.org/paper/cd6652fe413d57d05b44e0f3aa036c54f0eef464","title":"Towards Boosting the Open-Domain Chatbot with Human Feedback","venue":"ArXiv","year":2022,"referenceCount":31,"citationCount":2,"influentialCitationCount":0,"publicationDate":"30/08/2022","authors":"Hua Lu,Siqi Bao,H. He,Fan Wang,Hua Wu,Haifeng Wang","id":"cd6652fe413d57d05b44e0f3aa036c54f0eef464","summary":"A novel andcient approach Diamante to boost the open-domain chatbot, where two kinds of human feedback are collected and leveraged and the implicit preference in the data collection process and the generation-evaluation joint training is introduced.","score":3},{"url":"https://www.semanticscholar.org/paper/051808bd0abd0350b6d642cf4f0cb63533b3f06d","title":"Prediction, selection, and generation: a knowledge-driven conversation system","venue":"Neural computing & applications (Print)","year":2022,"referenceCount":51,"citationCount":0,"influentialCitationCount":0,"publicationDate":"18/09/2022","authors":"Cheng Luo,Dayiheng Liu,Chanjuan Li,Li Lu,Jiancheng Lv","id":"051808bd0abd0350b6d642cf4f0cb63533b3f06d","summary":"This paper proposes a knowledge-driven conversation system that outperforms a strong baseline and achieves state-of-the-art results, and proposes the Bert2Transformer model as the dialogue generator, which can generate rich and fluent utterances based on contextual and relevant knowledge.","score":3},{"url":"https://www.semanticscholar.org/paper/52788fec0b67236d110eaa2d6ce637febb9ef4aa","title":"An Explainable Artificial Intelligence Approach for Detecting Empathy in Textual Communication","venue":"Applied Sciences","year":2022,"referenceCount":67,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/09/2022","authors":"Edwin Carlos Montiel-Vázquez,J. R. Ramírez Uresti,O. Loyola-González","id":"52788fec0b67236d110eaa2d6ce637febb9ef4aa","summary":"It is shown that an explicative pattern-based approach (PBC4cip) is, to date, the best approach for detecting empathy in texts by measuring performance in both nominal and ordinal metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/89924944fe899fc26e8dfa447900ca849f47b76a","title":"DialogCC: Large-Scale Multi-Modal Dialogue Dataset","venue":"ArXiv","year":2022,"referenceCount":46,"citationCount":0,"influentialCitationCount":0,"publicationDate":"08/12/2022","authors":"Young-Jun Lee,ByungSoo Ko,Han-Gyu Kim,Ho-Jin Choi","id":"89924944fe899fc26e8dfa447900ca849f47b76a","summary":"It is demonstrated that training a multi-modal dialogue model with the proposed DialogCC dataset can improve generalization performance and existing models trained with the dataset achieve state-of-the-art performance on image and text retrieval tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/7b55d03d4e9252f8f56c3b1c650ec051b6bd0972","title":"Open-Domain Response Generation in Low-Resource Settings using Self-Supervised Pre-training of Warm-Started Transformers","venue":"ACM Transactions on Asian and Low-Resource Language Information Processing","year":2023,"referenceCount":40,"citationCount":0,"influentialCitationCount":0,"publicationDate":"05/01/2023","authors":"Tarek Naous,Zahraa Bassyouni,Bassel Mousi,Hazem M. Hajj,Wassim El Hajj,K. Shaban","id":"7b55d03d4e9252f8f56c3b1c650ec051b6bd0972","summary":"A framework for training open-domain response generation models in low-resource settings capable of generating fluent responses in multiple dialects with an average human-evaluated fluency score above 4 and fine-tuned on a very small labeled dataset for open- domain response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/12d13eb67b05a74d49fda150d62deb0fc4462dc2","title":"Improving Open-Domain Dialogue Evaluation with a Causal Inference Model","venue":"ArXiv","year":2023,"referenceCount":56,"citationCount":0,"influentialCitationCount":0,"publicationDate":"31/01/2023","authors":"Cat P. Le,Luke Dai,Michael Johnston,Yang Liu,M. Walker,R. Ghanadan","id":"12d13eb67b05a74d49fda150d62deb0fc4462dc2","summary":"This work explores the creation of automated methods for predicting both expert and user ratings of open-domain dialogues and shows that the CF-LSTM achieves the best performance for predicting dialogue ratings and classiﬁcation.","score":3},{"url":"https://www.semanticscholar.org/paper/5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691","title":"PLACES: Prompting Language Models for Social Conversation Synthesis","venue":"ArXiv","year":2023,"referenceCount":62,"citationCount":1,"influentialCitationCount":0,"publicationDate":"07/02/2023","authors":"Maximillian Chen,A. Papangelis,Chenyang Tao,Seokhwan Kim,Andrew Rosenbaum,Yang Liu,Zhou Yu,Dilek Z. Hakkani-Tür","id":"5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691","summary":"This work uses a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting, and demonstrates that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi- party tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/dfcdf6c4e1d43097d911e0da304b2540f857cfb8","title":"DialogSum Challenge: Summarizing Real-Life Scenario Dialogues","venue":"International Conference on Natural Language Generation","year":2021,"referenceCount":22,"citationCount":14,"influentialCitationCount":2,"publicationDate":2021,"authors":"Yulong Chen,Yang Liu,Yue Zhang","id":"dfcdf6c4e1d43097d911e0da304b2540f857cfb8","summary":"This work carefully annotates a large-scale dialogue summarization dataset based on multiple public dialogue corpus, opening the door to all kinds of summarization models.","score":3},{"url":"https://www.semanticscholar.org/paper/2cc805b3b4a0a6a619a44bb7dd6d91d15f117016","title":"Think Before You Speak: Learning to Generate Implicit Knowledge for Response Generation by Self-Talk","venue":"NLP4CONVAI","year":2021,"referenceCount":17,"citationCount":5,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Behnam Hedayatnia,Karthik Gopalakrishnan,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"2cc805b3b4a0a6a619a44bb7dd6d91d15f117016","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/e764dee4e50db01d77976e8f313fc092fc0eba85","title":"GRICE: A Grammar-based Dataset for Recovering Implicature and Conversational rEasoning","venue":"Findings","year":2021,"referenceCount":70,"citationCount":1,"influentialCitationCount":0,"publicationDate":2021,"authors":"Zilong Zheng,Shuwen Qiu,Lifeng Fan,Yixin Zhu,Song-Chun Zhu","id":"e764dee4e50db01d77976e8f313fc092fc0eba85","summary":"A grammar-based dialogue dataset, GRICE, designed to bring implicature into pragmatic reasoning in the context of conversations, and shows an overall performance boost in conversational reasoning.","score":3},{"url":"https://www.semanticscholar.org/paper/614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac","title":"A Survey on Response Selection for Retrieval-based Dialogues","venue":"International Joint Conference on Artificial Intelligence","year":2021,"referenceCount":68,"citationCount":11,"influentialCitationCount":0,"publicationDate":"01/08/2021","authors":"Chongyang Tao,Jiazhan Feng,Rui Yan,Wei Wu,Daxin Jiang","id":"614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac","summary":"A comprehensive survey of recent advances in response selection for retrieval-based dialogues and summarizes some recent advances on the research of response selection, including incorporation with extra knowledge and exploration on more effective model learning.","score":3},{"url":"https://www.semanticscholar.org/paper/2820c2f6147ca8dbc19181fa712b2662dd0c3ae0","title":"Guiding Topic Flows in the Generative Chatbot by Enhancing the ConceptNet with the Conversation Corpora","venue":"ArXiv","year":2021,"referenceCount":40,"citationCount":0,"influentialCitationCount":0,"publicationDate":"12/09/2021","authors":"Pengda Si,Yao Qiu,Jinchao Zhang,Yujiu Yang","id":"2820c2f6147ca8dbc19181fa712b2662dd0c3ae0","summary":"This work proposes the method to supply more 017 concept relations extracted from the conversa- 018 tional corpora and build an enhanced concept 019 graph for the chatbot construction, which significantly outperforms strong baseline systems and achieves new SOTA results.","score":3},{"url":"https://www.semanticscholar.org/paper/6f1c10534f6407ef3b090032b4dc2f9073569526","title":"Think Before You Speak: Explicitly Generating Implicit Commonsense Knowledge for Response Generation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":69,"citationCount":6,"influentialCitationCount":0,"publicationDate":"16/10/2021","authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"6f1c10534f6407ef3b090032b4dc2f9073569526","summary":"Think-Before-Speaking is presented, a generative approach to first externalize implicit commonsense knowledge (think) and use this knowledge to generate responses (speak), arguing that externalizing implicit knowledge allows more efficient learning, produces more informative responses, and enables more explainable models.","score":3},{"url":"https://www.semanticscholar.org/paper/2ae757afd718d5219cdee3a6c4cee0d226378efd","title":"Representation Learning for Conversational Data using Discourse Mutual Information Maximization","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":50,"citationCount":1,"influentialCitationCount":0,"publicationDate":"04/12/2021","authors":"Bishal Santra,Sumegh Roychowdhury,Aishik Mandal,Vasu Gurram,Atharva Naik,Manish Gupta,Pawan Goyal","id":"2ae757afd718d5219cdee3a6c4cee0d226378efd","summary":"This work proposes a structure-aware Mutual Information based loss-function DMI (Discourse Mutual Information) for training dialog-representation models, that additionally captures the inherent uncertainty in response prediction.","score":3},{"url":"https://www.semanticscholar.org/paper/3c9ba25baca64151af4e9d50c7947de28eb2a599","title":"Survey of Hallucination in Natural Language Generation","venue":"ACM Computing Surveys","year":2022,"referenceCount":250,"citationCount":75,"influentialCitationCount":4,"publicationDate":"08/02/2022","authors":"Ziwei Ji,Nayeon Lee,Rita Frieske,Tiezheng Yu,D. Su,Yan Xu,Etsuko Ishii,Yejin Bang,Wenliang Dai,Andrea Madotto,Pascale Fung","id":"3c9ba25baca64151af4e9d50c7947de28eb2a599","summary":"A broad overview of the research progress and challenges in the hallucination problem in NLG is provided, including task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation.","score":3},{"url":"https://www.semanticscholar.org/paper/d179082956ab75d08311ddc1bbb20783031d15b1","title":"Leveraging speaker-aware structure and factual knowledge for faithful dialogue summarization","venue":"Knowledge-Based Systems","year":2022,"referenceCount":75,"citationCount":2,"influentialCitationCount":0,"publicationDate":"01/03/2022","authors":"Lulu Zhao,Weiran Xu,Chunyun Zhang,Jun Guo","id":"d179082956ab75d08311ddc1bbb20783031d15b1","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/3c05f71157c713fe45704bdd130f01620b7ab771","title":"Towards Robust Online Dialogue Response Generation","venue":"ArXiv","year":2022,"referenceCount":53,"citationCount":0,"influentialCitationCount":0,"publicationDate":"07/03/2022","authors":"Leyang Cui,Fandong Meng,Yanjun Liu,Jie Zhou,Yue Zhang","id":"3c05f71157c713fe45704bdd130f01620b7ab771","summary":"A hierarchical sampling-based method consist- of both utterance-level sampling and semi- 017 utterance -level sampling, to alleviate the dis- 018 crepancy, which implicitly increases the dia- 019 logue coherence.","score":3},{"url":"https://www.semanticscholar.org/paper/d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3","title":"Multiview Contextual Commonsense Inference: A New Dataset and Task","venue":"ArXiv","year":2022,"referenceCount":25,"citationCount":1,"influentialCitationCount":0,"publicationDate":"06/10/2022","authors":"Siqi Shen,Deepanway Ghosal,Navonil Majumder,Henry Lim,Rada Mihalcea,Soujanya Poria","id":"d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3","summary":"This work creates CICEROv2, a dataset consisting of 8,351 instances from 2,379 dialogues, containing multiple human-written answers for each contextual commonsense inference question, representing a type of explanation on cause, subsequent event, motivation, and emotional reaction.","score":3},{"url":"https://www.semanticscholar.org/paper/d1feb79f63ea52839f4a784fbd7d60bb73dd98dd","title":"ComFact: A Benchmark for Linking Contextual Commonsense Knowledge","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":67,"citationCount":2,"influentialCitationCount":0,"publicationDate":"23/10/2022","authors":"Silin Gao,Jena D. Hwang,Saya Kanno,Hiromi Wakaki,Yuki Mitsufuji,Antoine Bosselut","id":"d1feb79f63ea52839f4a784fbd7d60bb73dd98dd","summary":"This work proposes the new task of commonsense fact linking, where models are given contexts and trained to identify situationally-relevant commonsense knowledge from KGs, and shows that heuristic fact linking approaches are imprecise knowledge extractors.","score":3},{"url":"https://www.semanticscholar.org/paper/8089bfe8aa59151147b78d9c9968026119cd5420","title":"Dialogue-adaptive language model pre-training from quality estimation☆","venue":"Neurocomputing","year":2020,"referenceCount":53,"citationCount":0,"influentialCitationCount":0,"publicationDate":"10/09/2020","authors":"Junlong Li,Zhuosheng Zhang,Hai Zhao","id":"8089bfe8aa59151147b78d9c9968026119cd5420","summary":"Experimental results on widely used open-domain response selection and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of estimating quality evaluation factors into pre-training.","score":3},{"url":"https://www.semanticscholar.org/paper/c44176020bc7034f5ea788cb8de7fcdda5f6a91d","title":"Social Influence Dialogue Systems: A Scoping Survey of the Efforts Towards Influence Capabilities of Dialogue Systems","venue":"ArXiv","year":2022,"referenceCount":93,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Kushal Chawla,Weiyan Shi,Jingwen Zhang,Gale M. Lucas,Zhou Yu,J. Gratch","id":"c44176020bc7034f5ea788cb8de7fcdda5f6a91d","summary":"This work formally deﬁne and introduces the category of social inﬂuence dialogue systems that in-situ users’ cognitive and emotional responses are changed, leading to changes in thoughts, opinions, and behaviors through natural conversations.","score":3},{"url":"https://www.semanticscholar.org/paper/a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88","title":"Social Influence Dialogue Systems: A Survey of Datasets and Models For Social Influence Tasks","venue":"","year":2022,"referenceCount":98,"citationCount":0,"influentialCitationCount":0,"publicationDate":"11/10/2022","authors":"Kushal Chawla,Weiyan Shi,Jingwen Zhang,Gale M. Lucas,Zhou Yu,J. Gratch","id":"a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88","summary":"This work formally deﬁne and introduces the category of social inﬂuence dialogue systems that in-situ users’ cognitive and emotional responses are changed, leading to changes in thoughts, opinions, and behaviors through natural conversations.","score":3},{"url":"https://www.semanticscholar.org/paper/b0df9c1a785618c1cfa9090cbca4c6110be092fe","title":"Emotion-Aware and Human-Like Autonomous Agents","venue":"","year":2019,"referenceCount":227,"citationCount":1,"influentialCitationCount":0,"publicationDate":"20/12/2019","authors":"Nabiha Asghar","id":"b0df9c1a785618c1cfa9090cbca4c6110be092fe","summary":"This thesis addresses two challenges: replicating the human ability to correctly perceive and adopt emotions, and communicate effectively through language, and devise an active learning technique that elicits user feedback during a conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/35763b04ca7ec8d1cbdacb3be5635015d2f7ad9b","title":"A Survey of Document Grounded Dialogue Systems (DGDS)","venue":"ArXiv","year":2020,"referenceCount":143,"citationCount":9,"influentialCitationCount":2,"publicationDate":2020,"authors":"Longxuan Ma,Weinan Zhang,Mingda Li,Ting Liu","id":"35763b04ca7ec8d1cbdacb3be5635015d2f7ad9b","summary":"The classification, architecture, datasets, models, and future development trends of the DGDS are analyzed, hoping to help researchers in this field.","score":2},{"url":"https://www.semanticscholar.org/paper/dca519be8c02a29566985e9cadc138d7d64626ce","title":"A Survey of Document Grounded Dialogue Systems (DGDS)","venue":"","year":2020,"referenceCount":145,"citationCount":0,"influentialCitationCount":0,"publicationDate":2020,"authors":"Apple Siri,MicrosoftâĂŹs,Cortana,Amazon Alexa","id":"dca519be8c02a29566985e9cadc138d7d64626ce","summary":"This paper presents a meta-modelling system that automates the very labor-intensive and therefore time-heavy and expensive and therefore expensive and expensive process of social computing and information Retrieval.","score":2},{"url":"https://www.semanticscholar.org/paper/d08463bd665589d04619f04dbde84183ffcf2e63","title":"Towards a Human-like Open-Domain Chatbot","venue":"ArXiv","year":2020,"referenceCount":63,"citationCount":553,"influentialCitationCount":86,"publicationDate":"27/01/2020","authors":"Daniel De Freitas,Minh-Thang Luong,David R. So,Jamie Hall,Noah Fiedel,Romal Thoppilan,Zi Yang,Apoorv Kulshreshtha,Gaurav Nemade,Yifeng Lu,Quoc V. Le","id":"d08463bd665589d04619f04dbde84183ffcf2e63","summary":"Meena, a multi-turn open-domain chatbot trained end-to-end on data mined and filtered from public domain social media conversations, is presented and a human evaluation metric called Sensibleness and Specificity Average (SSA) is proposed, which captures key elements of a human-like multi- turn conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/77b101d2c0f3d2842edb4acdbca0c4e859cda4d5","title":"A survey on empathetic dialogue systems","venue":"Information Fusion","year":2020,"referenceCount":152,"citationCount":104,"influentialCitationCount":1,"publicationDate":"01/12/2020","authors":"Yukun Ma,Khanh Linh Nguyen,Frank Z. Xing,E. Cambria","id":"77b101d2c0f3d2842edb4acdbca0c4e859cda4d5","summary":"This review article focuses on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge, and identifies three key features that underpin such systems: emotion-awareness, personality-awareness and knowledge-accessibility.","score":2},{"url":"https://www.semanticscholar.org/paper/df39e25d31e76427e5a6e91246951b1049b639ab","title":"Proxy Indicators for the Quality of Open-domain Dialogues","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":32,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"R. Nedelchev,Jens Lehmann,Ricardo Usbeck","id":"df39e25d31e76427e5a6e91246951b1049b639ab","summary":"This work investigates using a deep-learning model trained on the General Language Understanding Evaluation (GLUE) benchmark to serve as a quality indication of open-domain dialogues to reduce the need for additional training data or responses that serve as quality references.","score":2},{"url":"https://www.semanticscholar.org/paper/fac8d660e9c0cef1da5d35aea35c572ed776e887","title":"Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":40,"citationCount":10,"influentialCitationCount":2,"publicationDate":"31/12/2020","authors":"Weiyan Shi,Yu Li,Saurav Sahay,Zhou Yu","id":"fac8d660e9c0cef1da5d35aea35c572ed776e887","summary":"This model outperforms previous state-of-the-art dialogue models on both automatic metrics and human evaluation results on a donation persuasion task, and generates more diverse, consistent and persuasive conversations according to the user feedback.","score":2},{"url":"https://www.semanticscholar.org/paper/56586eb758d7fabdbbd5ee4c5ed7e30c6d457d30","title":"Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":86,"citationCount":9,"influentialCitationCount":0,"publicationDate":"20/02/2021","authors":"Haoming Jiang,Bo Dai,Mengjiao Yang,Wei Wei,T. Zhao","id":"56586eb758d7fabdbbd5ee4c5ed7e30c6d457d30","summary":"ENIGMA only requires a handful of pre-collected experience data, and therefore does not involve human interaction with the target policy during the evaluation, making automatic evaluations feasible, and significantly outperforms existing methods in terms of correlation with human evaluation scores.","score":2},{"url":"https://www.semanticscholar.org/paper/205a405e5d2823c9bfdf77a3452b2ac8481a1525","title":"Can Contextualizing User Embeddings Improve Sarcasm and Hate Speech Detection?","venue":"NLPCSS","year":2022,"referenceCount":60,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Kim Breitwieser","id":"205a405e5d2823c9bfdf77a3452b2ac8481a1525","summary":"It is shown that task-related topics can have a noticeable effect on model performance, especially when dealing with intended expressions like sarcasm, but less so for hate speech, which is usually labelled as such on the receiving end.","score":2},{"url":"https://www.semanticscholar.org/paper/23bb7ac9d1164b0b429e59eb012584c1c1c64e73","title":"Structural Characterization for Dialogue Disentanglement","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":62,"citationCount":5,"influentialCitationCount":1,"publicationDate":"15/10/2021","authors":"Xinbei Ma,Zhuosheng Zhang,Hai Zhao","id":"23bb7ac9d1164b0b429e59eb012584c1c1c64e73","summary":"This work specially takes structure factors into account and design a novel model for dialogue disentangling that achieves new state-of-the-art on the Ubuntu IRC benchmark dataset and contributes to dialogue-related comprehension.","score":2},{"url":"https://www.semanticscholar.org/paper/8ac5f84cd417b04dd178e963d7aa03f3be27d74b","title":"Dialogue System Augmented with Commonsense Knowledge","venue":"Vilnius University Open Series","year":2022,"referenceCount":31,"citationCount":0,"influentialCitationCount":0,"publicationDate":"13/05/2022","authors":"I. Lasy,Virginijus Marcinkevicius","id":"8ac5f84cd417b04dd178e963d7aa03f3be27d74b","summary":"This work proposes usage of structured knowledge base ConceptNet for knowledge-grounded dialogue generation and novel knowledge extraction algorithm is proposed which is then used to incorporate knowledge into existing dialogue datasets.","score":2},{"url":"https://www.semanticscholar.org/paper/82eea58ca6e16e7b2df9a6f76b796da5a7cfcbc5","title":"Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":78,"citationCount":0,"influentialCitationCount":0,"publicationDate":"31/10/2022","authors":"Nyoungwoo Lee,chaeHun Park,Ho-Jin Choi,J. Choo","id":"82eea58ca6e16e7b2df9a6f76b796da5a7cfcbc5","summary":"Experimental results on dialogue selection tasks show that the proposed method outperforms other methods of synthesizing adversarial negative responses and suggest that the method can be an effective alternative to human annotators in generating adversarial responses.","score":2},{"url":"https://www.semanticscholar.org/paper/658a912984d6a4899d1369ca674b06c7aafd45d0","title":"DIRECT: Toward Dialogue-Based Reading Comprehension Tutoring","venue":"IEEE Access","year":2023,"referenceCount":44,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Jin-Xia Huang,Yohan Lee,Oh-Woog Kwon","id":"658a912984d6a4899d1369ca674b06c7aafd45d0","summary":"A dialogue-based intelligent tutoring system (ITS) that imitates human expert tutors that asks questions, assesses student answers, provides hints, and even chats to encourage student engagement is developed.","score":2},{"url":"https://www.semanticscholar.org/paper/891082eb8ec9796d9e6041a93c2dfcf1654daf76","title":"1 c-TextGen : Conditional Text Generation for Harmonious Human-Machine Interaction","venue":"","year":2019,"referenceCount":90,"citationCount":0,"influentialCitationCount":0,"publicationDate":2019,"authors":"Bin Guo,Hao Wang,Yasan Ding,Shaoyang Hao,Yueqi Sun","id":"891082eb8ec9796d9e6041a93c2dfcf1654daf76","summary":"The paper is presented at the 2016 ACM meeting in Washington, DC, where it was presented as well as at the ACM workshop in New York, USA, where the paper was presented in person for the first time.","score":2},{"url":"https://www.semanticscholar.org/paper/f2d257625e8029f6f4998deb6279f97e07e2893c","title":"MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations","venue":"Annual Meeting of the Association for Computational Linguistics","year":2018,"referenceCount":34,"citationCount":378,"influentialCitationCount":115,"publicationDate":"05/10/2018","authors":"Soujanya Poria,Devamanyu Hazarika,Navonil Majumder,Gautam Naik,E. Cambria,Rada Mihalcea","id":"f2d257625e8029f6f4998deb6279f97e07e2893c","summary":"The Multimodal EmotionLines Dataset (MELD), an extension and enhancement of Emotion lines, contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends and shows the importance of contextual and multimodal information for emotion recognition in conversations.","score":2},{"url":"https://www.semanticscholar.org/paper/592d500e44f99e39f35d5d96f8787b94f51aa914","title":"Approximating Interactive Human Evaluation with Self-Play for Open-Domain Dialog Systems","venue":"Neural Information Processing Systems","year":2019,"referenceCount":44,"citationCount":63,"influentialCitationCount":7,"publicationDate":"01/06/2019","authors":"Asma Ghandeharioun,J. Shen,Natasha Jaques,Craig Ferguson,Noah J. Jones,À. Lapedriza,Rosalind W. Picard","id":"592d500e44f99e39f35d5d96f8787b94f51aa914","summary":"It is shown that this metric is capable of capturing the human-rated quality of a dialog model better than any automated metric known to-date, achieving a significant Pearson correlation (r>.7, p<.05).","score":2},{"url":"https://www.semanticscholar.org/paper/c131665638feb8c11f936989ffc6187317593b41","title":"Emotionally-Aware Chatbots: A Survey","venue":"ArXiv","year":2019,"referenceCount":70,"citationCount":28,"influentialCitationCount":0,"publicationDate":"24/06/2019","authors":"Endang Wahyu Pamungkas","id":"c131665638feb8c11f936989ffc6187317593b41","summary":"In this paper, a systematic review of approaches in building an emotionally-aware chatbot (EAC) is provided and it is found that in the early development, EAC exploits a simple rule-based approach while now most of EAC use neural- based approach.","score":2},{"url":"https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920","title":"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction","venue":"ArXiv","year":2019,"referenceCount":182,"citationCount":5,"influentialCitationCount":0,"publicationDate":"08/09/2019","authors":"Bin Guo,Hao Wang,Yasan Ding,Shaoyang Hao,Yueqi Sun,Zhiwen Yu","id":"e324d92c005ccdec0ce04dfb9941dd99ded21920","summary":"This work aims to give a comprehensive review of the new research trends of c-TextGen, and gives a brief literature review of text generation technology, based on which it formalizes the concept model of c.TextGen.","score":2},{"url":"https://www.semanticscholar.org/paper/e4b14cc43f2bceaafd056b2c43a93f2cc81086b7","title":"Follow Alice into the Rabbit Hole: Giving Dialogue Agents Understanding of Human Level Attributes","venue":"ArXiv","year":2019,"referenceCount":43,"citationCount":2,"influentialCitationCount":0,"publicationDate":"18/10/2019","authors":"Aaron W. Li,Veronica Jiang,Steven Y. Feng,Julia Sprague,W. Zhou,J. Hoey","id":"e4b14cc43f2bceaafd056b2c43a93f2cc81086b7","summary":"This work proposes Human Level Attributes based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters and introduces a three-component system, ALOHA, that combines character space mapping, character community detection, and language style retrieval to build a character (or personality) specific language model.","score":2},{"url":"https://www.semanticscholar.org/paper/f83d2439ce294eebee6b8303ab717fb2c0be6386","title":"Emotional Neural Language Generation Grounded in Situational Contexts","venue":"CCNLG","year":2019,"referenceCount":37,"citationCount":11,"influentialCitationCount":1,"publicationDate":"25/11/2019","authors":"Sashank Santhanam,Samira Shaikh","id":"f83d2439ce294eebee6b8303ab717fb2c0be6386","summary":"This work develops a language modeling approach that generates affective content when the dialogue is situated in a given context and outperforms the state-of-the-art method on the perplexity metric and achieves a higher BLEU metric score.","score":2},{"url":"https://www.semanticscholar.org/paper/fc3c05b152e325cd87d0d6275df469c27cc9149e","title":"Challenges in the Evaluation of Conversational Search Systems","venue":"Converse@KDD","year":2020,"referenceCount":74,"citationCount":9,"influentialCitationCount":0,"publicationDate":2020,"authors":"Gustavo Penha,C. Hauff","id":"fc3c05b152e325cd87d0d6275df469c27cc9149e","summary":"It is argued that the currently in-use evaluation schemes have critical limitations and simplify the conversational search tasks to a degree that makes it questionable whether the authors can trust the findings they deliver.","score":2},{"url":"https://www.semanticscholar.org/paper/ab7ea333afb81b937592078fd18544cfdb625255","title":"Seeking an Empathy-abled Conversational Agent","venue":"Romanian Conference on Human-Computer Interaction","year":2020,"referenceCount":14,"citationCount":1,"influentialCitationCount":0,"publicationDate":2020,"authors":"Andreea Grosuleac,Stefania Budulan,Traian Rebedea","id":"ab7ea333afb81b937592078fd18544cfdb625255","summary":"This paper presents an open-domain empathic chatbot, encompassing two of the biggest challenges of dialog systems: understanding emotions and offering appropriate responses, while offering a further refined dialogue persona.","score":2},{"url":"https://www.semanticscholar.org/paper/d8d67b7e943f088351ae5b4a12e35a5448d00846","title":"Challenges in the Evaluation of Conversational Search Systems","venue":"","year":2020,"referenceCount":73,"citationCount":0,"influentialCitationCount":0,"publicationDate":2020,"authors":"S. Kallumadi,U. Porwal,T. Taula","id":"d8d67b7e943f088351ae5b4a12e35a5448d00846","summary":"It is argued that the currently in-use evaluation schemes have critical limitations and simplify the conversational search tasks to a degree that makes it questionable whether the authors can trust the findings they deliver.","score":2},{"url":"https://www.semanticscholar.org/paper/d4e7ae066bc9a5652dc6caf0e75e9f44f1f63f47","title":"Conditional Variational Autoencoders for Emotionally-aware Chatbot Based on Transformer","venue":"","year":2020,"referenceCount":23,"citationCount":0,"influentialCitationCount":0,"publicationDate":2020,"authors":"Yubo Xie","id":"d4e7ae066bc9a5652dc6caf0e75e9f44f1f63f47","summary":"This paper focuses on the need for the variational empathetic chatbot and proposes a model that combines the plain Transformer chatbot model and Conditional Variational Autoencoders (CVAE) to generate high-quality abstractive conversation responses following designated emotions.","score":2},{"url":"https://www.semanticscholar.org/paper/e42fd8c71b6d4acd4da0fece2e9f18cdd781e7ab","title":"Empathy-driven Arabic Conversational Chatbot","venue":"Workshop on Arabic Natural Language Processing","year":2020,"referenceCount":22,"citationCount":12,"influentialCitationCount":2,"publicationDate":2020,"authors":"Tarek Naous,Christian Hokayem,Hazem M. Hajj","id":"e42fd8c71b6d4acd4da0fece2e9f18cdd781e7ab","summary":"This work creates an Arabic conversational dataset that comprises empathetic responses and proposes a special encoder-decoder composed of a Long Short-Term Memory (LSTM) Sequence-to-Sequence (Seq2Seq) with Attention to address the limitation of data scale.","score":2},{"url":"https://www.semanticscholar.org/paper/11ed7f038bd7efd1491f3957959e1e30bc120c38","title":"CAiRE: An Empathetic Neural Chatbot.","venue":"","year":2019,"referenceCount":30,"citationCount":14,"influentialCitationCount":2,"publicationDate":"28/07/2019","authors":"Zhaojiang Lin,Peng Xu,Genta Indra Winata,Farhad Bin Siddique,Zihan Liu,Jamin Shin,Pascale Fung","id":"11ed7f038bd7efd1491f3957959e1e30bc120c38","summary":"This system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection.","score":2},{"url":"https://www.semanticscholar.org/paper/9fc0ddd6811cf682500d12585da78385b01a1e6b","title":"CAiRE: An End-to-End Empathetic Chatbot","venue":"AAAI Conference on Artificial Intelligence","year":2019,"referenceCount":31,"citationCount":76,"influentialCitationCount":9,"publicationDate":"28/07/2019","authors":"Zhaojiang Lin,Peng Xu,Genta Indra Winata,Zihan Liu,Pascale Fung","id":"9fc0ddd6811cf682500d12585da78385b01a1e6b","summary":"This system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection.","score":2},{"url":"https://www.semanticscholar.org/paper/2162c863639414f590f78bb11889dda9e418ee96","title":"ALOHA: Artificial Learning of Human Attributes for Dialogue Agents","venue":"AAAI Conference on Artificial Intelligence","year":2019,"referenceCount":44,"citationCount":17,"influentialCitationCount":4,"publicationDate":"18/10/2019","authors":"Aaron W. Li,Veronica Jiang,Steven Y. Feng,Julia Sprague,Wei Zhou,J. Hoey","id":"2162c863639414f590f78bb11889dda9e418ee96","summary":"This work proposes Human Level Attributes based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters and introduces a three-component system, ALOHA, that combines character space mapping, character community detection, and language style retrieval to build a character (or personality) specific language model.","score":2},{"url":"https://www.semanticscholar.org/paper/14ff8d13e0324982a7718c66657071fcf2e527b3","title":"Generating Emotionally Aligned Responses in Dialogues using Affect Control Theory","venue":"ArXiv","year":2020,"referenceCount":62,"citationCount":5,"influentialCitationCount":0,"publicationDate":"07/03/2020","authors":"Nabiha Asghar,I. Kobyzev,J. Hoey,P. Poupart,Muhammad Bilal Sheikh","id":"14ff8d13e0324982a7718c66657071fcf2e527b3","summary":"This work investigates how ACT can be used to develop affect-aware neural conversational agents, which produce emotionally aligned responses to prompts and take into consideration the affective identities of the interactants.","score":2},{"url":"https://www.semanticscholar.org/paper/37383c30930391c1f67fb5817563c98f1889d3ef","title":"Variational Transformers for Diverse Response Generation","venue":"ArXiv","year":2020,"referenceCount":32,"citationCount":40,"influentialCitationCount":1,"publicationDate":"28/03/2020","authors":"Zhaojiang Lin,Genta Indra Winata,Peng Xu,Zihan Liu,Pascale Fung","id":"37383c30930391c1f67fb5817563c98f1889d3ef","summary":"The Variational Transformer is proposed, a variational self-attentive feed-forward sequence model that combines the parallelizability and global receptive field of the Transformer with the variational nature of the CVAE by incorporating stochastic latent variables into Transformers.","score":2},{"url":"https://www.semanticscholar.org/paper/9910882e86fb264fa96c0e3e92e52b34997e8091","title":"Will I Sound like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":47,"citationCount":29,"influentialCitationCount":1,"publicationDate":"13/04/2020","authors":"Hyunwoo Kim,Byeongchang Kim,Gunhee Kim","id":"9910882e86fb264fa96c0e3e92e52b34997e8091","summary":"Inspired by social cognition and pragmatics, existing dialogue agents are endow with public self-consciousness on the fly through an imaginary listener to enforce dialogue agents to refrain from uttering contradiction and improve consistency of existing dialogue models.","score":2},{"url":"https://www.semanticscholar.org/paper/24181cb896b16d7e423b2c289ee831a10f829ecb","title":"A Wizard-of-Oz Interface and Persona-based Methodology for Collecting Health Counseling Dialog","venue":"CHI Extended Abstracts","year":2020,"referenceCount":51,"citationCount":12,"influentialCitationCount":1,"publicationDate":"25/04/2020","authors":"William R. Kearns,Neha Kaura,Myra Divina,C. Vo,Dong Si,T. Ward,Weichao Yuwen","id":"24181cb896b16d7e423b2c289ee831a10f829ecb","summary":"This work describes an interface designed to augment the ability of clinicians to efficiently engage in high-quality and empathetic health counseling dialog with their patients and presents a WOZ protocol for collecting this dialog using standardized patient actors each playing a role from a pool of caregiver personas.","score":2},{"url":"https://www.semanticscholar.org/paper/82fc3d0b878c0cc01f4b349ba289a78c54622476","title":"Endowing Empathetic Conversational Models with Personas","venue":"","year":2020,"referenceCount":48,"citationCount":4,"influentialCitationCount":1,"publicationDate":"26/04/2020","authors":"Peixiang Zhong,Yan Zhu,Yong Liu,Chen Zhang,Hao Wang,Zaiqing Nie,C. Miao","id":"82fc3d0b878c0cc01f4b349ba289a78c54622476","summary":"Results show that persona improves empathetic responding more when CoBERT is trained on emPathetic conversations than non-empathetic ones, establishing an empirical link between persona and empathy in human conversations.","score":2},{"url":"https://www.semanticscholar.org/paper/5e65e3eb8cb06b07ecfd096fb2ac26ad20083643","title":"Towards Persona-Based Empathetic Conversational Models","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":50,"citationCount":44,"influentialCitationCount":9,"publicationDate":"26/04/2020","authors":"Peixiang Zhong,Yan Zhu,Yong Liu,Chen Zhang,Hao Wang,Zaiqing Nie,C. Miao","id":"5e65e3eb8cb06b07ecfd096fb2ac26ad20083643","summary":"Results show that persona improves empathetic responding more when CoBERT is trained on emPathetic conversations than non-empathetic ones, establishing an empirical link between persona and empathy in human conversations.","score":2},{"url":"https://www.semanticscholar.org/paper/9967faaec2ada5e9c638b6dc9ff577bc28bbd04c","title":"Policy-Driven Neural Response Generation for Knowledge-Grounded Dialog Systems","venue":"International Conference on Natural Language Generation","year":2020,"referenceCount":46,"citationCount":31,"influentialCitationCount":3,"publicationDate":"26/05/2020","authors":"Behnam Hedayatnia,Seokhwan Kim,Yang Liu,Karthik Gopalakrishnan,Mihail Eric,Dilek Z. Hakkani-Tür","id":"9967faaec2ada5e9c638b6dc9ff577bc28bbd04c","summary":"It is demonstrated that a basic dialog policy that operates at the sentence level generates better responses in comparison to turn level generation as well as baseline models with no action plan.","score":2},{"url":"https://www.semanticscholar.org/paper/75f061c958505ef5ecc0442d4bcc8fd4c4ee4688","title":"Controlling Style in Generated Dialogue","venue":"ArXiv","year":2020,"referenceCount":60,"citationCount":33,"influentialCitationCount":3,"publicationDate":"22/09/2020","authors":"Eric Michael Smith,Diana Gonzalez-Rico,Emily Dinan,Y-Lan Boureau","id":"75f061c958505ef5ecc0442d4bcc8fd4c4ee4688","summary":"This work adapts three previously proposed controllable generation architectures to open-domain dialogue generation, controlling the style of the generation to match one among about 200 possible styles, and shows how they can be used to provide insights into existing conversational datasets, and generate a varied set of styled conversation replies.","score":2},{"url":"https://www.semanticscholar.org/paper/943f1c9cae41d7635a40dc9d836edd94418e26c8","title":"INSPIRED: Toward Sociable Recommendation Dialog Systems","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":48,"citationCount":46,"influentialCitationCount":8,"publicationDate":"29/09/2020","authors":"Shirley Anugrah Hayati,Dongyeop Kang,Qingxiaoyang Zhu,Weiyan Shi,Zhou Yu","id":"943f1c9cae41d7635a40dc9d836edd94418e26c8","summary":"This work designs an annotation scheme related to recommendation strategies based on social science theories and annotate these dialogs, and shows that sociable recommendation strategies, such as sharing personal opinions or communicating with encouragement, more frequently lead to successful recommendations.","score":2},{"url":"https://www.semanticscholar.org/paper/4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563","title":"Recipes for Safety in Open-domain Chatbots","venue":"ArXiv","year":2020,"referenceCount":73,"citationCount":91,"influentialCitationCount":16,"publicationDate":"14/10/2020","authors":"J. Xu,Da Ju,Margaret Li,Y-Lan Boureau,J. Weston,Emily Dinan","id":"4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563","summary":"A new human-and-model-in-the-loop framework for both training safer models and for evaluating them, as well as a novel method to distill safety considerations inside generative models without the use of an external classifier at deployment time are introduced.","score":2},{"url":"https://www.semanticscholar.org/paper/4f027ccc32429b798f7ed2d20a69b1a645569087","title":"Open-Domain Dialogue Generation Based on Pre-trained Language Models","venue":"ArXiv","year":2020,"referenceCount":38,"citationCount":2,"influentialCitationCount":0,"publicationDate":"24/10/2020","authors":"Yan Zeng,J. Nie","id":"4f027ccc32429b798f7ed2d20a69b1a645569087","summary":"A comparison of four main frameworks for pre-trained language models shows that the best framework uses bidirectional attention on the source side and does not separate encoder and decoder, and a reduction in discrepancies can lead to improved performance.","score":2},{"url":"https://www.semanticscholar.org/paper/884af0356a4e0d61cd7b4d649e4c037ee84df3bc","title":"Open Questions for Next Generation Chatbots","venue":"IFIP International Information Security Conference","year":2020,"referenceCount":25,"citationCount":0,"influentialCitationCount":0,"publicationDate":"01/11/2020","authors":"Winson Ye,Qun Li","id":"884af0356a4e0d61cd7b4d649e4c037ee84df3bc","summary":"This survey aims to introduce newcomers to the most fundamental research questions for next generation neural dialogue systems and reveals the following 4 key research challenges: 1) knowledge grounding, 2) persona consistency, 3) emotional intelligence, and 4) evaluation.","score":2},{"url":"https://www.semanticscholar.org/paper/bd57fb1156bc7fdc4d1abd59de26c488f26dae2c","title":"Using reinforcement learning with external rewards for open-domain natural language generation","venue":"Journal of Intelligence and Information Systems","year":2020,"referenceCount":53,"citationCount":0,"influentialCitationCount":0,"publicationDate":"06/11/2020","authors":"Vidhushini Srinivasan,Sashank Santhanam,Samira Shaikh","id":"bd57fb1156bc7fdc4d1abd59de26c488f26dae2c","summary":"A new approach towards emotional natural language generation using bidirectional seq2seq model, which is tuned using policy gradient method, and proposes a new internal reward, Emotional Intelligence, computed by minimizing the affective dissonance between the source and generated text.","score":2},{"url":"https://www.semanticscholar.org/paper/470889e2e5493613c641160e9e4b0d5cc2180b7b","title":"OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual Contexts","venue":"ArXiv","year":2020,"referenceCount":108,"citationCount":12,"influentialCitationCount":4,"publicationDate":"30/12/2020","authors":"Yuxian Meng,Shuhe Wang,Qinghong Han,Xiaofei Sun,Fei Wu,Rui Yan,Jiwei Li","id":"470889e2e5493613c641160e9e4b0d5cc2180b7b","summary":"It is observed that visual information significantly improves dialogue generation qualities, verifying the necessity of integrating multi-modal features for dialogue learning.","score":2},{"url":"https://www.semanticscholar.org/paper/59583454cef87dfee40ddb4db1ae67b277a5bacb","title":"Characterizing Social Spambots by their Human Traits","venue":"Findings","year":2021,"referenceCount":54,"citationCount":3,"influentialCitationCount":0,"publicationDate":2021,"authors":"Salvatore Giorgi,Lyle Ungar,H. A. Schwartz","id":"59583454cef87dfee40ddb4db1ae67b277a5bacb","summary":"How well social bots can be identified only using the 17 variables of these human attributes is considered and ended up with a new state of the art in social spambot detection (e.g. F1 = .946).","score":2},{"url":"https://www.semanticscholar.org/paper/7dd25287048fbc8753f412f30d30509e87308071","title":"An Investigation of Suitability of Pre-Trained Language Models for Dialogue Generation – Avoiding Discrepancies","venue":"Findings","year":2021,"referenceCount":31,"citationCount":4,"influentialCitationCount":0,"publicationDate":2021,"authors":"Yan Zeng,Jian-Yun Nie","id":"7dd25287048fbc8753f412f30d30509e87308071","summary":"Comparisons of pre-trained language models using both large and small-scale data reveal that decoder-only architecture is better than stacked encoder-decoder, and both leftto-right and bi-directional attention have their own advantages.","score":2},{"url":"https://www.semanticscholar.org/paper/26a15c0e1becb323f40a616003a15db48ea1581a","title":"MRF-Chat: Improving Dialogue with Markov Random Fields","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":28,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"Ishaan Grover,Matthew Huggins,C. Breazeal,Hae Won Park","id":"26a15c0e1becb323f40a616003a15db48ea1581a","summary":"This work proposes a novel probabilistic approach using Markov Random Fields (MRF) to augment existing deep-learning methods for improved next utterance prediction and shows that this augmentation approach significantly improves the performance of existing state-of-the-art retrieval models for open-domain conversational agents.","score":2},{"url":"https://www.semanticscholar.org/paper/9b539d413393047b28bb7be9b195f142aaf7a80e","title":"Recipes for Building an Open-Domain Chatbot","venue":"Conference of the European Chapter of the Association for Computational Linguistics","year":2020,"referenceCount":80,"citationCount":483,"influentialCitationCount":93,"publicationDate":"28/04/2020","authors":"Stephen Roller,Emily Dinan,Naman Goyal,Da Ju,Mary Williamson,Yinhan Liu,J. Xu,Myle Ott,Kurt Shuster,Eric Michael Smith,Y.-Lan Boureau,J. Weston","id":"9b539d413393047b28bb7be9b195f142aaf7a80e","summary":"Human evaluations show the best models outperform existing approaches in multi-turn dialogue on engagingness and humanness measurements, and the limitations of this work are discussed by analyzing failure cases of the models.","score":2},{"url":"https://www.semanticscholar.org/paper/cf58cbdaf475109da7c528e6d5d390ed97fba6b2","title":"Multi-Modal Open-Domain Dialogue","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":63,"citationCount":12,"influentialCitationCount":5,"publicationDate":"02/10/2020","authors":"Kurt Shuster,Eric Michael Smith,Da Ju,J. Weston","id":"cf58cbdaf475109da7c528e6d5d390ed97fba6b2","summary":"This work studies incorporating different image fusion schemes and domain-adaptive pre-training and fine-tuning strategies, and shows that the best resulting model outperforms strong existing models in multi-modal dialogue while simultaneously performing as well as its predecessor (text-only) BlenderBot in text-based conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/3c64247b4c75c64b4a67d306200bab5b5d3b5bfa","title":"Adding Chit-Chat to Enhance Task-Oriented Dialogues","venue":"North American Chapter of the Association for Computational Linguistics","year":2020,"referenceCount":54,"citationCount":33,"influentialCitationCount":4,"publicationDate":"24/10/2020","authors":"Kai Sun,Seungwhan Moon,Paul A. Crook,Stephen Roller,Becka Silvert,Bing Liu,Zhiguang Wang,Honglei Liu,Eunjoon Cho,Claire Cardie","id":"3c64247b4c75c64b4a67d306200bab5b5d3b5bfa","summary":"Automatic and human evaluations show that the proposed Adding Chit-Chat to ENhance Task-ORiented dialogues (ACCENTOR) models can code-switch between task and chit-chat to be more engaging, interesting, knowledgeable, and humanlike, while maintaining competitive task performance.","score":2},{"url":"https://www.semanticscholar.org/paper/50dde952a48a8c8d64a324d2c16b5e743d47200b","title":"Using reinforcement learning with external rewards for open-domain natural language generation","venue":"Journal of Intelligence and Information Systems","year":2020,"referenceCount":50,"citationCount":6,"influentialCitationCount":0,"publicationDate":"06/11/2020","authors":"Vidhushini Srinivasan,Sashank Santhanam,Samira Shaikh","id":"50dde952a48a8c8d64a324d2c16b5e743d47200b","summary":"A new approach towards emotional natural language generation using bidirectional seq2seq model, which is tuned using policy gradient method, and proposes a new internal reward, Emotional Intelligence, computed by minimizing the affective dissonance between the source and generated text.","score":2},{"url":"https://www.semanticscholar.org/paper/3f8fcf49be5ddd4a950325bc055cc2e159596d6f","title":"Keyword-Guided Neural Conversational Model","venue":"AAAI Conference on Artificial Intelligence","year":2020,"referenceCount":33,"citationCount":14,"influentialCitationCount":2,"publicationDate":"15/12/2020","authors":"Peixiang Zhong,Yong Liu,Hongya Wang,C. Miao","id":"3f8fcf49be5ddd4a950325bc055cc2e159596d6f","summary":"This paper proposes a keyword-guided neural conversational model that can leverage external commonsense knowledge graphs (CKG) for both keyword transition and response retrieval and suggests that commonsense improves the performance of both next-turn keyword prediction and keyword-augmented response retrieval.","score":2},{"url":"https://www.semanticscholar.org/paper/01a9102aa93b152f2d2978c568fb7061eb7152f1","title":"I like fish, especially dolphins: Addressing Contradictions in Dialogue Modeling","venue":"Annual Meeting of the Association for Computational Linguistics","year":2020,"referenceCount":52,"citationCount":46,"influentialCitationCount":13,"publicationDate":"24/12/2020","authors":"Yixin Nie,Mary Williamson,Mohit Bansal,Douwe Kiela,J. Weston","id":"01a9102aa93b152f2d2978c568fb7061eb7152f1","summary":"The DialoguE COntradiction DEtection task (DECODE) and a new conversational dataset containing both human-human and human-bot contradictory dialogues are introduced and it is shown that the best contradiction detection model correlates well with human judgments and is used in both automatically evaluating and improving the consistency of state-of-the-art generative chatbots.","score":2},{"url":"https://www.semanticscholar.org/paper/3d85116a88227cbb12442874bb42818e4c041b77","title":"Evaluating Empathetic Chatbots in Customer Service Settings","venue":"ArXiv","year":2021,"referenceCount":18,"citationCount":1,"influentialCitationCount":0,"publicationDate":"05/01/2021","authors":"Akshay Agarwal,Shashank V. Maiya,Sonu Aggarwal","id":"3d85116a88227cbb12442874bb42818e4c041b77","summary":"It is shown that a blended skills chatbot model that responds to customer queries is more likely to resemble actual human agent response if it is trained to recognize emotion and exhibit appropriate empathy, than a model without such training.","score":2},{"url":"https://www.semanticscholar.org/paper/3c2dc09625e88cb27772cc036bbb260f1815d919","title":"WeChat AI's Submission for DSTC9 Interactive Dialogue Evaluation Track","venue":"ArXiv","year":2021,"referenceCount":28,"citationCount":1,"influentialCitationCount":0,"publicationDate":"20/01/2021","authors":"Zekang Li,Zongjia Li,Jinchao Zhang,Yang Feng,Jie Zhou","id":"3c2dc09625e88cb27772cc036bbb260f1815d919","summary":"An integrated open-domain dialogue system containing preprocess, dialogue model, scoring model, and post-process, which can generate fluent, coherent, consistent, and humanlike responses is designed.","score":2},{"url":"https://www.semanticscholar.org/paper/b00674d4e14ef655a16e74a24dfef32664064587","title":"MultiTalk: A Highly-Branching Dialog Testbed for Diverse Conversations","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":37,"citationCount":4,"influentialCitationCount":0,"publicationDate":"02/02/2021","authors":"Yao Dou,Maxwell Forbes,Ari Holtzman,Yejin Choi","id":"b00674d4e14ef655a16e74a24dfef32664064587","summary":"The culminating task is a challenging theory of mind problem, a controllable generation task which requires reasoning about the expected reaction of the listener and a simple scoring algorithm, based on bipartite graph matching, to optimally incorporate a set of diverse references.","score":2},{"url":"https://www.semanticscholar.org/paper/74f67c3e96a1787955dff6d8eabf147452bd7148","title":"Conditional Text Generation for Harmonious Human-Machine Interaction","venue":"ACM Transactions on Intelligent Systems and Technology","year":2021,"referenceCount":241,"citationCount":16,"influentialCitationCount":0,"publicationDate":"26/02/2021","authors":"Bin Guo,Hao Wang,Yasan Ding,Wei Wu,Shaoyang Hao,Yueqi Sun,Zhiwen Yu","id":"74f67c3e96a1787955dff6d8eabf147452bd7148","summary":"This work summarizes several key techniques and illustrates the technical evolution route in the field of neural text generation, based on the concept model of CTG, and makes an investigation of existing CTG fields and proposes several general learning models for CTG.","score":2},{"url":"https://www.semanticscholar.org/paper/32128a25b1ebf868f9b02590e361a98524bd371b","title":"AdaptSum: Towards Low-Resource Domain Adaptation for Abstractive Summarization","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":66,"citationCount":41,"influentialCitationCount":8,"publicationDate":"21/03/2021","authors":"Tiezheng Yu,Zihan Liu,Pascale Fung","id":"32128a25b1ebf868f9b02590e361a98524bd371b","summary":"A study of domain adaptation for the abstractive summarization task across six diverse target domains in a low-resource setting and finds that continuing pre-training could lead to the pre-trained model's catastrophic forgetting, and a learning method with less forgetting can alleviate this issue.","score":2},{"url":"https://www.semanticscholar.org/paper/3336a84e248cc858b02cb63598c48a26be60b869","title":"Put Chatbot into Its Interlocutor’s Shoes: New Framework to Learn Chatbot Responding with Intention","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":39,"citationCount":2,"influentialCitationCount":0,"publicationDate":"30/03/2021","authors":"Hsuan Su,Jiun-hao Jhan,Fan-Yun Sun,Saurav Sahay,Hung-yi Lee","id":"3336a84e248cc858b02cb63598c48a26be60b869","summary":"An innovative framework to train chatbots to possess human-like intentions and performs trials with human interlocutors to substantiate the guiding chatbot’s effectiveness in influencing the responses of humans to a certain extent is proposed.","score":2},{"url":"https://www.semanticscholar.org/paper/8c0ec929aac2eb67d36f383f3175f22a1b285264","title":"Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task-Oriented Dialogue Systems","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":46,"citationCount":22,"influentialCitationCount":9,"publicationDate":"01/04/2021","authors":"Derek Chen,Howard Chen,Yi Yang,A. Lin,Zhou Yu","id":"8c0ec929aac2eb67d36f383f3175f22a1b285264","summary":"The Action-Based Conversations Dataset (ABCD), a fully-labeled dataset with over 10K human-to-human dialogues containing 55 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success, is introduced.","score":2},{"url":"https://www.semanticscholar.org/paper/318c908f795df590c865cac6659e72f60c4e93c0","title":"Designing Effective Interview Chatbots: Automatic Chatbot Profiling and Design Suggestion Generation for Chatbot Debugging","venue":"International Conference on Human Factors in Computing Systems","year":2021,"referenceCount":58,"citationCount":10,"influentialCitationCount":3,"publicationDate":"10/04/2021","authors":"Xu Han,Michelle X. Zhou,Matthew Turner,Tom Yeh","id":"318c908f795df590c865cac6659e72f60c4e93c0","summary":"iChatProfile is an assistive chatbot design tool that can automatically generate a profile of an interview chatbot with quantified performance metrics and offer design suggestions for improving the chatbot based on such metrics.","score":2},{"url":"https://www.semanticscholar.org/paper/5eba8724559f97b824e832451e4f832e319ce2cf","title":"Estimating Subjective Crowd-Evaluations as an Additional Objective to Improve Natural Language Generation","venue":"HUMEVAL","year":2021,"referenceCount":61,"citationCount":0,"influentialCitationCount":0,"publicationDate":"12/04/2021","authors":"Jakob Nyberg,R. Manuvinakurike,Maike Paetzel-Prüsmann","id":"5eba8724559f97b824e832451e4f832e319ce2cf","summary":"This paper argues for exploring the use of subjective evaluations within the process of training language generation models in a multi-task learning setting and discusses future research directions for incorporating subjective human evaluations into language model training to keep the human user in the loop during the development process.","score":2},{"url":"https://www.semanticscholar.org/paper/7fa273f450251523e6b7fcc2eb3fdbdfd4a30493","title":"CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":172,"citationCount":70,"influentialCitationCount":18,"publicationDate":"18/04/2021","authors":"Qinyuan Ye,Bill Yuchen Lin,Xiang Ren","id":"7fa273f450251523e6b7fcc2eb3fdbdfd4a30493","summary":"This paper presents the NLP Few-shot Gym, a repository of 160 diverse few-shot NLP tasks created from open-access NLP datasets and converted to a unified text-to-text format, and reveals that the few- shot learning ability on unseen tasks can be improved via an upstream learning stage using a set of seen tasks.","score":2},{"url":"https://www.semanticscholar.org/paper/e9e4992bdddc11bde818188c1353fcde650c59b2","title":"Modeling Human Motives and Emotions from Personal Narratives Using External Knowledge And Entity Tracking","venue":"The Web Conference","year":2021,"referenceCount":54,"citationCount":5,"influentialCitationCount":0,"publicationDate":"19/04/2021","authors":"Prashanth Vijayaraghavan,D. Roy","id":"e9e4992bdddc11bde818188c1353fcde650c59b2","summary":"This work proposes a Transformer-based architecture, referred to as Transformer, to model characters’ motives and emotions from personal narratives and shows that the learned mental state embeddings can be applied in downstream tasks such as empathetic response generation.","score":2},{"url":"https://www.semanticscholar.org/paper/e3d8f27f124cdf495834798ffcc5507005ceab6d","title":"Assessing Dialogue Systems with Distribution Distances","venue":"Findings","year":2021,"referenceCount":41,"citationCount":10,"influentialCitationCount":0,"publicationDate":"06/05/2021","authors":"Jiannan Xiang,Yahui Liu,Deng Cai,Huayang Li,Defu Lian,Lemao Liu","id":"e3d8f27f124cdf495834798ffcc5507005ceab6d","summary":"This paper proposes to measure the performance of a dialogue system by computing the distributionwise distance between its generated conversations and real-world conversations, and develops and evaluates two distribution-wise metrics.","score":2},{"url":"https://www.semanticscholar.org/paper/0d2c76843f43d6f7219c7c3ad69a17beac19205b","title":"Conversational Entity Linking: Problem Definition and Datasets","venue":"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval","year":2021,"referenceCount":63,"citationCount":8,"influentialCitationCount":0,"publicationDate":"11/05/2021","authors":"Hideaki Joko,Faegheh Hasibi,K. Balog,A. D. Vries","id":"0d2c76843f43d6f7219c7c3ad69a17beac19205b","summary":"This paper analyzes a large number of dialogues from existing conversational datasets and annotates references to concepts, named entities, and personal entities using crowdsourcing to identify the main characteristics of conversational entity linking.","score":2},{"url":"https://www.semanticscholar.org/paper/edc41f7cb8e0ebd4576e2eab0eb2f89ae54402bb","title":"SentEmojiBot: Empathising Conversations Generation with Emojis","venue":"ArXiv","year":2021,"referenceCount":34,"citationCount":0,"influentialCitationCount":0,"publicationDate":"26/05/2021","authors":"Akhilesh Ravi,A. Yadav,Jainish Chauhan,Jatin Dholakia,Naman Jain,M. Singh","id":"edc41f7cb8e0ebd4576e2eab0eb2f89ae54402bb","summary":"This work proposes, SentEmojiBot, to generate empathetic conversations with a combination of emojis and text, and indicates that BERT-based model outperforms the vanilla transformer model and a user study indicates that the dialogues generated by the model were understandable and adding em emoji improved empathetics traits in conversations.","score":2},{"url":"https://www.semanticscholar.org/paper/fd61ed225ce6fb87d24f4a2b5d90939daabf05ff","title":"Would you like to tell me more? Generating a corpus of psychotherapy dialogues","venue":"NLPMC","year":2021,"referenceCount":25,"citationCount":8,"influentialCitationCount":2,"publicationDate":"01/06/2021","authors":"Seyed Mahed Mousavi,Alessandra Cervone,M. Danieli,G. Riccardi","id":"fd61ed225ce6fb87d24f4a2b5d90939daabf05ff","summary":"","score":2},{"url":"https://www.semanticscholar.org/paper/892c37529053e560db6fb32ee6c4f8730405f374","title":"Gathering Information and Engaging the User ComBot: A Task-Based, Serendipitous Dialog Model for Patient-Doctor Interactions","venue":"NLPMC","year":2021,"referenceCount":24,"citationCount":4,"influentialCitationCount":0,"publicationDate":"01/06/2021","authors":"Anna A. Liednikova,Ph. Jolivet,Alexandre Durand-Salmon,Claire Gardent","id":"892c37529053e560db6fb32ee6c4f8730405f374","summary":"An ensemble model made of three bots: a task-based, a follow-up and a social bot is introduced and it is shown that the combination of the three bots provides a better basis for collecting information than just the information seeking bot and collects information in a more user-friendly, more efficient manner.","score":2},{"url":"https://www.semanticscholar.org/paper/d1290807d6089713a6710285ac115904c39c311d","title":"Assessing Political Prudence of Open-domain Chatbots","venue":"SIGDIAL Conferences","year":2021,"referenceCount":27,"citationCount":6,"influentialCitationCount":1,"publicationDate":"11/06/2021","authors":"Yejin Bang,Nayeon Lee,Etsuko Ishii,Andrea Madotto,Pascale Fung","id":"d1290807d6089713a6710285ac115904c39c311d","summary":"A group of metrics for assessing political prudence of chatbots are proposed and conducted and the testsets and codebase are released to promote research in this area.","score":2},{"url":"https://www.semanticscholar.org/paper/0a12ea86c9193bf2496d65d25d1f234c1fac923b","title":"Zero-Shot Controlled Generation with Encoder-Decoder Transformers","venue":"ArXiv","year":2021,"referenceCount":45,"citationCount":4,"influentialCitationCount":0,"publicationDate":"11/06/2021","authors":"Devamanyu Hazarika,Mahdi Namazifar,Dilek Z. Hakkani-Tür","id":"0a12ea86c9193bf2496d65d25d1f234c1fac923b","summary":"This work proposes novel approaches for controlling encoder-decoder transformerbased NLG models in zero-shot by introducing three control knobs, namely, attention biasing, decoder mixing, and context augmentation, that are applied to these models at generation time and shows that not only are theseNLG models robust to such manipulations, but also their behavior could be controlled without an impact on their generation performance.","score":2}]}