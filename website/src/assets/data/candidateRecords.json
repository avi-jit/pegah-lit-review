{"papers":[{"url":"https://www.semanticscholar.org/paper/493a6e7aef4ead8fafa8913ce404a870d862c08b","title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","venue":"arXiv.org","year":2022,"referenceCount":158,"citationCount":0,"influentialCitationCount":0,"publicationDate":"19/12/2022","authors":"Sagi Shaier,L. Hunter,Katharina Kann","id":"493a6e7aef4ead8fafa8913ce404a870d862c08b","summary":"The first survey of knowledge-enhanced DSs is presented, defining three categories of systems - internal, external, and hybrid - based on the knowledge they use and proposing how to improve existing systems based on theories from linguistics and cognitive science.","score":6},{"url":"https://www.semanticscholar.org/paper/17a8b5e6fef1f69979d57021a8f30a5159e152c7","title":"Commonsense Reasoning for Conversational AI: A Survey of the State of the Art","venue":"arXiv.org","year":2023,"referenceCount":90,"citationCount":3,"influentialCitationCount":0,"publicationDate":"15/02/2023","authors":"Christopher Richardson,Larry Heck","id":"17a8b5e6fef1f69979d57021a8f30a5159e152c7","summary":"A survey of recent conversational AI research focused on commonsense reasoning, including preliminary observations of the limited commonsense capabilities of two state-of-the-art open dialogue models, BlenderBot3 and LaMDA, and its negative effect on natural interactions.","score":6},{"url":"https://www.semanticscholar.org/paper/8f926c0c3f1557a9241b7e75609082a1f207a75e","title":"InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":124,"citationCount":22,"influentialCitationCount":1,"publicationDate":"25/05/2022","authors":"Prakhar Gupta,Cathy Jiao,Yi-Ting Yeh,Shikib Mehri,M. Eskénazi,Jeffrey P. Bigham","id":"8f926c0c3f1557a9241b7e75609082a1f207a75e","summary":"This work introduces InstructDial, an instruction tuning framework for dialogue, which consists of a repository of 48 diverse dialogue tasks in a unified text-to-text format created from 59 openly available dialogue datasets, and introduces novel meta-tasks to ensure that models adhere to instructions.","score":6},{"url":"https://www.semanticscholar.org/paper/7e582b03b597d8865f6641c511c1a63b6255b821","title":"DialogZoo: Large-Scale Dialog-Oriented Task Learning","venue":"arXiv.org","year":2022,"referenceCount":86,"citationCount":4,"influentialCitationCount":0,"publicationDate":2022,"authors":"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Jian-Guang Lou,Kai Yu","id":"7e582b03b597d8865f6641c511c1a63b6255b821","summary":"The experimental results show that the building a uniﬁed foundation model which can solve massive diverse dialogue tasks and improves the ability of dialogue generation and knowledge distillation, but also the representation ability of models.","score":5},{"url":"https://www.semanticscholar.org/paper/c8559021289f08eaf8cf2294e406bc1c6b506d19","title":"Recent advances in deep learning based dialogue systems: a systematic survey","venue":"Artificial Intelligence Review","year":2021,"referenceCount":480,"citationCount":96,"influentialCitationCount":5,"publicationDate":"10/05/2021","authors":"Jinjie Ni,Tom Young,Vlad Pandelea,Fuzhao Xue,V. Adiga,E. Cambria","id":"c8559021289f08eaf8cf2294e406bc1c6b506d19","summary":"This survey is the most comprehensive and up-to-date one at present for deep learning based dialogue systems, extensively covering the popular techniques.","score":5},{"url":"https://www.semanticscholar.org/paper/a6880a4c3f4b2f0a1d492d689569683ffbc03076","title":"DFM: Dialogue Foundation Model for Universal Large-Scale Dialogue-Oriented Task Learning","venue":"","year":2022,"referenceCount":92,"citationCount":1,"influentialCitationCount":0,"publicationDate":"25/05/2022","authors":"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Xinhsuai Dong,Fujiang Ge,Qingliang Miao,Jian-Guang Lou,Kai Yu","id":"a6880a4c3f4b2f0a1d492d689569683ffbc03076","summary":"Experiments show that, compared with models of the same size, DFM can achieve state-of-the-art or competitive performance on very rich cross-domain downstream dialogue tasks, demonstrating that DFM largely extends the ability of unified dialogue pre-trained model.","score":5},{"url":"https://www.semanticscholar.org/paper/9b3ff4c05be2ee57021099ab07fadfb77440be45","title":"IMAD: IMage-Augmented multi-modal Dialogue","venue":"","year":2023,"referenceCount":67,"citationCount":0,"influentialCitationCount":0,"publicationDate":"17/05/2023","authors":"Moskvoretskii Viktor,Frolov Anton,Kuznetsov Denis","id":"9b3ff4c05be2ee57021099ab07fadfb77440be45","summary":"This work proposes a two-stage approach to automatically construct a multi-modal dialogue dataset that can serve as a validated dataset for this task and proposes a baseline model trained on this dataset, which outperforms modeltrained on the same data without images and BlenderBot.","score":5},{"url":"https://www.semanticscholar.org/paper/af4cb5bef1db79b837ca5eabc47a3a3a582b0c17","title":"C L ] 7 S ep 2 02 1 Empathetic Dialogue Generation with Pre-trained RoBERTa-GPT 2 and External Knowledge","venue":"","year":2021,"referenceCount":47,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"Ye Liu,Wolfgang Maier,W. Minker,Stefan Ultes","id":"af4cb5bef1db79b837ca5eabc47a3a3a582b0c17","summary":"To enable the empathetic ability of RoBERTaGPT2 model, this work proposes a commonsense knowledge and emotional concepts extractor, in which the commonsensible andotional concepts of dialogue context are extracted for the GPT-2 decoder.","score":4},{"url":"https://www.semanticscholar.org/paper/5d0419f282aa8ad7c98c1f28876323645a7407d6","title":"Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":36,"citationCount":5,"influentialCitationCount":0,"publicationDate":2022,"authors":"Ling-Yu Zhu,Zhengkun Zhang,Jun Wang,Hongbin Wang,Haiying Wu,Zhenglu Yang","id":"5d0419f282aa8ad7c98c1f28876323645a7407d6","summary":"","score":4},{"url":"https://www.semanticscholar.org/paper/9997901cac96451686b817961c1408ac4123102c","title":"HappyBot: Generating Empathetic Dialogue Responses by Improving User Experience Look-ahead","venue":"arXiv.org","year":2019,"referenceCount":32,"citationCount":41,"influentialCitationCount":0,"publicationDate":"20/06/2019","authors":"Jamin Shin,Peng Xu,Andrea Madotto,Pascale Fung","id":"9997901cac96451686b817961c1408ac4123102c","summary":"A Sentiment Predictor is trained to estimate the user sentiment look-ahead towards the generated system responses, which is then used as the reward function for generating more empathetic responses.","score":4},{"url":"https://www.semanticscholar.org/paper/062466fb189fd3d4ab2f56a05937a8ae6df7bd06","title":"A Comprehensive Assessment of Dialog Evaluation Metrics","venue":"EANCS","year":2021,"referenceCount":68,"citationCount":59,"influentialCitationCount":14,"publicationDate":"07/06/2021","authors":"Yi-Ting Yeh,M. Eskénazi,Shikib Mehri","id":"062466fb189fd3d4ab2f56a05937a8ae6df7bd06","summary":"This comprehensive assessment provides a comprehensive assessment of recently proposed dialog evaluation metrics on a number of datasets and suggests how to best assess evaluation metrics and indicates promising directions for future work.","score":4},{"url":"https://www.semanticscholar.org/paper/5cf42d26583d2b083262451e9005e6ed273badca","title":"Automatic Evaluation and Moderation of Open-domain Dialogue Systems","venue":"arXiv.org","year":2021,"referenceCount":55,"citationCount":14,"influentialCitationCount":1,"publicationDate":"03/11/2021","authors":"Chen Zhang,João Sedoc,L. F. D’Haro,Rafael E. Banchs,Alexander I. Rudnicky","id":"5cf42d26583d2b083262451e9005e6ed273badca","summary":"This paper describes the datasets and baselines provided to participants, as well as submission evaluation results for each of the two proposed subtasks, and describes the automatic evaluation mechanisms that show high correlations with human judgements across multiple dialogue evaluation aspects.","score":4},{"url":"https://www.semanticscholar.org/paper/0ba23c847d2ca087887b60ea92ce56c71f0425b2","title":"MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":49,"citationCount":7,"influentialCitationCount":1,"publicationDate":"14/12/2021","authors":"Chen Zhang,L. F. D’Haro,Thomas Friedrichs,Haizhou Li","id":"0ba23c847d2ca087887b60ea92ce56c71f0425b2","summary":"The proposed MDD-Eval framework first train a teacher evaluator with human-annotated data to acquire a rating skill to tell good dialogue responses from bad ones in a particular domain and then, adopt a self-training strategy to train a new evaluators with teacher-annotation multi-domain data, that helps the newevaluator to generalize across multiple domains.","score":4},{"url":"https://www.semanticscholar.org/paper/59707fbd3308257628470d94e56c8165bf4e1cff","title":"FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":59,"citationCount":8,"influentialCitationCount":1,"publicationDate":"12/05/2022","authors":"Alon Albalak,Yi-Lin Tuan,Pegah Jandaghi,Connor Pryor,Luke Yoffe,Deepak Ramachandran,L. Getoor,J. Pujara,William Yang Wang","id":"59707fbd3308257628470d94e56c8165bf4e1cff","summary":"Conversational task transfer is explored by introducing FETA: a benchmark for FEw-sample TAsk transfer in open-domain dialogue and can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning.","score":4},{"url":"https://www.semanticscholar.org/paper/f1217313b3dd1d4dc5afc09edfcbccae9b5647fe","title":"Grounding in social media: An approach to building a chit-chat dialogue model","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":23,"citationCount":2,"influentialCitationCount":0,"publicationDate":"12/06/2022","authors":"Ritvik Choudhary,Daisuke Kawahara","id":"f1217313b3dd1d4dc5afc09edfcbccae9b5647fe","summary":"This method aims to improve the raw conversation ability of the system by mimicking the human response behavior through casual interactions found on social media, and queries a large set of filtered comment data from Reddit to act as additional context for the seq2seq generator.","score":4},{"url":"https://www.semanticscholar.org/paper/5b0855b9b9361839844ae86277e8189a957d9d23","title":"MVP: Multi-task Supervised Pre-training for Natural Language Generation","venue":"arXiv.org","year":2022,"referenceCount":191,"citationCount":7,"influentialCitationCount":0,"publicationDate":"24/06/2022","authors":"Tianyi Tang,Junyi Li,Wayne Xin Zhao,Ji-rong Wen","id":"5b0855b9b9361839844ae86277e8189a957d9d23","summary":"This work proposes Multi-task superVised Pre-training (MVP) for natural language generation, which achieves state-of-the-art performance on $13$ out of $17$ datasets, outperforming BART by $9.3\\%$ and Flan-T5 by $5.8\\%$.","score":4},{"url":"https://www.semanticscholar.org/paper/27a51fa45ab9512b43d697a017a52ec3b4f7fd32","title":"SelF-Eval: Self-supervised Fine-grained Dialogue Evaluation","venue":"International Conference on Computational Linguistics","year":2022,"referenceCount":47,"citationCount":1,"influentialCitationCount":0,"publicationDate":"17/08/2022","authors":"Longxuan Ma,Ziyu Zhuang,Weinan Zhang,Mingda Li,Ting Liu","id":"27a51fa45ab9512b43d697a017a52ec3b4f7fd32","summary":"A novel automatic data construction method that can automatically assign fine-grained scores for arbitrarily dialogue data and train SelF-Eval with a multi-level contrastive learning schema which helps to distinguish different score levels.","score":4},{"url":"https://www.semanticscholar.org/paper/a6f171598db5a21ece1ac38010c48df19b2b23ca","title":"FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":55,"citationCount":5,"influentialCitationCount":2,"publicationDate":"25/10/2022","authors":"Chen Zhang,L. F. D’Haro,Qiquan Zhang,Thomas Friedrichs,Haizhou Li","id":"a6f171598db5a21ece1ac38010c48df19b2b23ca","summary":"A multi-dimensional dialogue-level metric, which consists of three sub-metrics with each targeting a specific dimension, which is trained with novel self-supervised objectives and exhibit strong correlations with human judgment for their respective dimensions.","score":4},{"url":"https://www.semanticscholar.org/paper/e8059434aa997cf486e6ae83cfbf355d4829a95c","title":"PoE: A Panel of Experts for Generalized Automatic Dialogue Assessment","venue":"IEEE/ACM Transactions on Audio Speech and Language Processing","year":2022,"referenceCount":87,"citationCount":0,"influentialCitationCount":0,"publicationDate":"18/12/2022","authors":"Chen Zhang,L. F. D’Haro,Qiquan Zhang,Thomas Friedrichs,Haizhou Li","id":"e8059434aa997cf486e6ae83cfbf355d4829a95c","summary":"A Panel of Experts (PoE) network is proposed, a multitask network that consists of a shared transformer encoder and a collection of lightweight adapters that exhibits better zero-shot generalization than existing state-of-the-art ADEMs and the ability to easily adapt to new domains with few-shot transfer learning.","score":4},{"url":"https://www.semanticscholar.org/paper/f8c041f0bd857c148788c284ae48117b70985558","title":"SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization","venue":"arXiv.org","year":2022,"referenceCount":64,"citationCount":13,"influentialCitationCount":2,"publicationDate":"20/12/2022","authors":"Hyunwoo Kim,Jack Hessel,Liwei Jiang,Ximing Lu,Youngjae Yu,Pei Zhou,Ronan Le Bras,Malihe Alikhani,Gunhee Kim,Maarten Sap,Yejin Choi","id":"f8c041f0bd857c148788c284ae48117b70985558","summary":"This work presents SODA: the first publicly available, million-scale high-quality social dialogue dataset, and trains COSMO: a generalizable conversation model that is significantly more natural and consistent on unseen datasets than best-performing conversation models (e.g., GODEL, BlenderBot-1, Koala, Vicuna).","score":4},{"url":"https://www.semanticscholar.org/paper/ce74df5126faad7d74f578f1e1953278611e235d","title":"Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation","venue":"arXiv.org","year":2021,"referenceCount":57,"citationCount":9,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"ce74df5126faad7d74f578f1e1953278611e235d","summary":"Compared with end-to-end RG models, self-talk models that externalize the knowledge grounding process by explicitly generating implicit knowledge also produce responses that are more informative, speciﬁc, and follow common sense.","score":4},{"url":"https://www.semanticscholar.org/paper/0934d7cac5a86b02fc49852334051bde540b34bd","title":"DialogSum: A Real-Life Scenario Dialogue Summarization Dataset","venue":"Findings","year":2021,"referenceCount":37,"citationCount":79,"influentialCitationCount":26,"publicationDate":2021,"authors":"Yulong Chen,Yang Liu,Liang Chen,Yue Zhang","id":"0934d7cac5a86b02fc49852334051bde540b34bd","summary":"Experimental results show unique challenges in dialogue summarization, such as spoken terms, special discourse structures, coreferences and ellipsis, pragmatics and social common sense, which require specific representation learning technologies to better deal with.","score":4},{"url":"https://www.semanticscholar.org/paper/a210df43018c682f6f57120cdb66b93a42c26699","title":"Probing Causal Common Sense in Dialogue Response Generation","venue":"arXiv.org","year":2021,"referenceCount":46,"citationCount":3,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Hyundong Justin Cho,J. Pujara,Xiang Ren","id":"a210df43018c682f6f57120cdb66b93a42c26699","summary":"The study if response generation models can emulate human reasoning process and use common sense to help produce better-quality responses finds that RG models have a hard time determining the logical validity of explanations but can identify grammatical naturalness of the explanation easily.","score":4},{"url":"https://www.semanticscholar.org/paper/1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a","title":"Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation","venue":"arXiv.org","year":2020,"referenceCount":47,"citationCount":22,"influentialCitationCount":1,"publicationDate":"10/09/2020","authors":"Junlong Li,Zhuosheng Zhang,Hai Zhao,Xi Zhou,Xiang Zhou","id":"1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a","summary":"A Dialogue-Adaptive Pre-training Objective (DAPO) based on some important qualities for assessing dialogues which are usually ignored by general LM pre-training objectives is designed and Experimental results show that models with DAPO surpass those with general LMPre- training objectives and other strong baselines on downstream DrNLP tasks.","score":4},{"url":"https://www.semanticscholar.org/paper/281b4a7e7fb057d8266ec0610888905c46fd715d","title":"Advances in Multi-turn Dialogue Comprehension: A Survey","venue":"arXiv.org","year":2021,"referenceCount":106,"citationCount":11,"influentialCitationCount":1,"publicationDate":"04/03/2021","authors":"Zhuosheng Zhang,Hai Zhao","id":"281b4a7e7fb057d8266ec0610888905c46fd715d","summary":"The characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension are summarized and categorize dialogue-related pre-training techniques which are employed to enhance PrLMs in dialogue scenarios.","score":4},{"url":"https://www.semanticscholar.org/paper/dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2","title":"Probing Commonsense Explanation in Dialogue Response Generation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":45,"citationCount":11,"influentialCitationCount":1,"publicationDate":"19/04/2021","authors":"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Justin Cho,J. Pujara,Xiang Ren","id":"dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2","summary":"This study formalizes the problem by framing commonsense as a latent variable in the RG task and using explanations for responses as textual form of commonsense, and collecting 6k annotated explanations justifying responses from four dialogue datasets and asking humans to verify them.","score":4},{"url":"https://www.semanticscholar.org/paper/2a3dd5cf961747adcb05f4f2834ff7a22261e861","title":"Commonsense-Focused Dialogues for Response Generation: An Empirical Study","venue":"SIGDIAL Conferences","year":2021,"referenceCount":45,"citationCount":25,"influentialCitationCount":5,"publicationDate":"14/09/2021","authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"2a3dd5cf961747adcb05f4f2834ff7a22261e861","summary":"This paper auto-extract commonsensical dialogues from existing dialogue datasets by leveraging ConceptNet, a commonsense knowledge graph, and proposes an approach for automatic evaluation of commonsense that relies on features derived from ConceptNet and pre-trained language and dialog models, and shows reasonable correlation with human evaluation of responses’ commonsense quality.","score":4},{"url":"https://www.semanticscholar.org/paper/0f17d7619e5de7bf41079d65783d4fb135825377","title":"CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":34,"citationCount":14,"influentialCitationCount":1,"publicationDate":"25/03/2022","authors":"Deepanway Ghosal,Siqi Shen,Navonil Majumder,Rada Mihalcea,Soujanya Poria","id":"0f17d7619e5de7bf41079d65783d4fb135825377","summary":"This paper curates CICERO, a dataset of dyadic conversations with five types of utterance-level reasoning-based inferences, and uses it to solve relevant generative and discriminative tasks: generation of cause and subsequent event; generation of prerequisite, motivation, and listener’s emotional reaction; and selection of plausible alternatives.","score":4},{"url":"https://www.semanticscholar.org/paper/fa71d25c07d6d3c890ef4b7547d5a4d117d0b96d","title":"Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches and Future Directions","venue":"arXiv.org","year":2022,"referenceCount":159,"citationCount":0,"influentialCitationCount":0,"publicationDate":"18/10/2022","authors":"Qi Jia,Siyu Ren,Yizhu Liu,Kenny Q. Zhu","id":"fa71d25c07d6d3c890ef4b7547d5a4d117d0b96d","summary":"This survey provides a comprehensive investigation on existing work for abstractive dialogue summarization from scenarios, approaches to evaluations and presents a taxonomy of existing techniques in three directions, namely, injecting dialogue features, designing auxiliary training tasks and using additional data.","score":4},{"url":"https://www.semanticscholar.org/paper/bc9d103493d93a9ad8e6b60af4d9a900e4470146","title":"CausalDialogue: Modeling Utterance-level Causality in Conversations","venue":"arXiv.org","year":2022,"referenceCount":50,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/12/2022","authors":"Yi-Lin Tuan,Alon Albalak,Wenda Xu,Michael Stephen Saxon,Connor Pryor,L. Getoor,William Yang Wang","id":"bc9d103493d93a9ad8e6b60af4d9a900e4470146","summary":"This research examines user utterances as causes and generated responses as effects and proposes a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models.","score":4},{"url":"https://www.semanticscholar.org/paper/d0adbba45ad8d8d1e748c9f3901569a09d8bc227","title":"Diplomat: A Dialogue Dataset for Situated Pragmatic Reasoning","venue":"arXiv.org","year":2023,"referenceCount":93,"citationCount":0,"influentialCitationCount":0,"publicationDate":"15/06/2023","authors":"Hengli Li,Songchun Zhu,Zilong Zheng","id":"d0adbba45ad8d8d1e748c9f3901569a09d8bc227","summary":"This paper introduces a novel challenge, DiPlomat, aiming at benchmarking machines' capabilities on pragmatic reasoning and situated conversational understanding, and proposes two tasks, Pragmatic Identification and Reasoning and Conversational Question Answering.","score":4},{"url":"https://www.semanticscholar.org/paper/817c8b9e3329baf812bfa2cea2132d9aa6054df5","title":"DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":63,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/12/2022","authors":"Yu Li,Baolin Peng,Pengcheng He,Michel Galley,Zhou Yu,Jianfeng Gao","id":"817c8b9e3329baf812bfa2cea2132d9aa6054df5","summary":"DIONYSUS (dynamic input optimization in pre-training for dialogue summarization), a pre-trained encoder-decoder model for summarizing dialogues in any new domain that outperforms existing methods on six datasets.","score":4},{"url":"https://www.semanticscholar.org/paper/b0b96270a9bbeb9f3ec040e70114d565fbcaaed9","title":"Learning from Dialogue after Deployment: Feed Yourself, Chatbot!","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":52,"citationCount":140,"influentialCitationCount":10,"publicationDate":"16/01/2019","authors":"Braden Hancock,Antoine Bordes,Pierre-Emmanuel Mazaré,J. Weston","id":"b0b96270a9bbeb9f3ec040e70114d565fbcaaed9","summary":"On the PersonaChat chit-chat dataset with over 131k training examples, it is found that learning from dialogue with a self-feeding chatbot significantly improves performance, regardless of the amount of traditional supervision.","score":3},{"url":"https://www.semanticscholar.org/paper/6b94dcac41325a03956402ff7862fa80936f9ddb","title":"A Survey of Natural Language Generation Techniques with a Focus on Dialogue Systems - Past, Present and Future Directions","venue":"arXiv.org","year":2019,"referenceCount":135,"citationCount":37,"influentialCitationCount":0,"publicationDate":"02/06/2019","authors":"Sashank Santhanam,Samira Shaikh","id":"6b94dcac41325a03956402ff7862fa80936f9ddb","summary":"This work provides a comprehensive review towards building open domain dialogue systems, an important application of natural language generation, and finds that, predominantly, the approaches for building dialogue systems use seq2seq or language models architecture.","score":3},{"url":"https://www.semanticscholar.org/paper/c131665638feb8c11f936989ffc6187317593b41","title":"Emotionally-Aware Chatbots: A Survey","venue":"arXiv.org","year":2019,"referenceCount":69,"citationCount":28,"influentialCitationCount":0,"publicationDate":"24/06/2019","authors":"Endang Wahyu Pamungkas","id":"c131665638feb8c11f936989ffc6187317593b41","summary":"In this paper, a systematic review of approaches in building an emotionally-aware chatbot (EAC) is provided and it is found that in the early development, EAC exploits a simple rule-based approach while now most of EAC use neural- based approach.","score":3},{"url":"https://www.semanticscholar.org/paper/b47698a589e35ec3f7a0bb30618939fbed0b9e41","title":"MoEL: Mixture of Empathetic Listeners","venue":"Conference on Empirical Methods in Natural Language Processing","year":2019,"referenceCount":65,"citationCount":130,"influentialCitationCount":39,"publicationDate":"21/08/2019","authors":"Zhaojiang Lin,Andrea Madotto,Jamin Shin,Peng Xu,Pascale Fung","id":"b47698a589e35ec3f7a0bb30618939fbed0b9e41","summary":"A novel end-to-end approach for modeling empathy in dialogue systems: Mixture of Empathetic Listeners (MoEL), which outperforms multitask training baseline in terms of empathy, relevance, and fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/2899ad28e9616779a251a78917e313b5e5011d78","title":"MIME: MIMicking Emotions for Empathetic Response Generation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":45,"citationCount":83,"influentialCitationCount":26,"publicationDate":"04/10/2020","authors":"Navonil Majumder,Pengfei Hong,Shanshan Peng,Jiankun Lu,Deepanway Ghosal,Alexander Gelbukh,Rada Mihalcea,Soujanya Poria","id":"2899ad28e9616779a251a78917e313b5e5011d78","summary":"This work argues that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content, and introduces stochasticity into the emotion mixture that yields emotionally more varied emPathetic responses than the previous work.","score":3},{"url":"https://www.semanticscholar.org/paper/4f480bae3196dbbc27ab383bce33478ea963f9b3","title":"LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models","venue":"arXiv.org","year":2023,"referenceCount":35,"citationCount":2,"influentialCitationCount":0,"publicationDate":"23/05/2023","authors":"Yen-Ting Lin,Yun-Nung (Vivian) Chen","id":"4f480bae3196dbbc27ab383bce33478ea963f9b3","summary":"LLM-Eval is proposed, a single prompt-based evaluation method that leverages a unified evaluation schema to cover multiple dimensions of conversation quality in a single model call and offers a versatile and robust solution for evaluating open-domain conversation systems.","score":3},{"url":"https://www.semanticscholar.org/paper/ca7570353bab859f515e9599bc38defc6ec40e98","title":"Less is more : An Empirical Analysis of Model Compression for Dialogue","venue":"","year":2021,"referenceCount":55,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"","id":"ca7570353bab859f515e9599bc38defc6ec40e98","summary":"This work performs an empirical evaluation of three model compression techniques on conversational agents specif-ically pre-trained on large language transformer networks using OpenAI GPT-2 transformer network to evaluate and compare the performance of open-domain dialogue models before and after undergoing compression.","score":3},{"url":"https://www.semanticscholar.org/paper/56dc1ce4df5ce80a48743be8ebd38025bdba24bf","title":"RAST: Domain-Robust Dialogue Rewriting as Sequence Tagging","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":38,"citationCount":9,"influentialCitationCount":0,"publicationDate":2021,"authors":"Jie Hao,Linfeng Song,Liwei Wang,Kun Xu,Zhaopeng Tu,Dong Yu","id":"56dc1ce4df5ce80a48743be8ebd38025bdba24bf","summary":"A novel sequence-tagging-based model is proposed so that the search space is significantly reduced, yet the core of this task is still well covered, and the model’s outputs may lack fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/89ba86c751e6fe6759c4f8cb07b6784adb117aeb","title":"SEPRG: Sentiment aware Emotion controlled Personalized Response Generation","venue":"International Conference on Natural Language Generation","year":2021,"referenceCount":51,"citationCount":1,"influentialCitationCount":0,"publicationDate":2021,"authors":"Mauajama Firdaus,U. Jain,Asif Ekbal,P. Bhattacharyya","id":"89ba86c751e6fe6759c4f8cb07b6784adb117aeb","summary":"Experimental results on the PersonaChat dataset show that the proposed framework significantly outperforms the existing baselines, thereby generating personalized emotional responses in accordance with the sentiment that provides better emotional connection and user satisfaction as desired in a social chatbot.","score":3},{"url":"https://www.semanticscholar.org/paper/1466200bb780899d5899ea7862a418039cf48131","title":"Projection of Turn Completion in Incremental Spoken Dialogue Systems","venue":"SIGDIAL Conferences","year":2021,"referenceCount":53,"citationCount":2,"influentialCitationCount":1,"publicationDate":2021,"authors":"Erik Ekstedt,Gabriel Skantze","id":"1466200bb780899d5899ea7862a418039cf48131","summary":"This work implements a mechanism to achieve fast response times by projecting what the interlocutor will say and estimating upcoming turn completions in an incremental spoken dialog system, by using a language model that generates possible futures to project upcoming completion points.","score":3},{"url":"https://www.semanticscholar.org/paper/b7a64a22f69a17ea0b007f7748580f7641b55cb6","title":"Dialogue in the Wild: Learning from a Deployed Role-Playing Game with Humans and Bots","venue":"Findings","year":2021,"referenceCount":36,"citationCount":10,"influentialCitationCount":0,"publicationDate":2021,"authors":"Kurt Shuster,Jack Urbanek,Emily Dinan,Arthur D. Szlam,J. Weston","id":"b7a64a22f69a17ea0b007f7748580f7641b55cb6","summary":"This work builds and deploy a role-playing game, whereby human players converse with learning agents situated in an open-domain fantasy world and shows that by training models on the conversations they have with humans in the game the models progressively improve, as measured by automatic metrics and online engagement scores.","score":3},{"url":"https://www.semanticscholar.org/paper/9588603547d14c81beca87f6de399334b8d3645d","title":"Enhancing the Open-Domain Dialogue Evaluation in Latent Space","venue":"Findings","year":2021,"referenceCount":51,"citationCount":11,"influentialCitationCount":2,"publicationDate":2021,"authors":"Zhangming Chan,Lemao Liu,Juntao Li,Haisong Zhang,Dongyan Zhao,Shuming Shi,Rui Yan","id":"9588603547d14c81beca87f6de399334b8d3645d","summary":"This paper proposes a self-supervised setting to obtain a smooth latent space that can both capture discourse-level context information and im-plicitly model more references in latent space and demonstrates the superiority of this method for open-domain dialogue evaluation.","score":3},{"url":"https://www.semanticscholar.org/paper/f6d0321e0a0447da0af4f4d8cafaff0704005116","title":"Anna: A Dapper Open-Domain Dialogue Agent Based on a Joint Attention Network","venue":"Journal of Natural Language Processing","year":2021,"referenceCount":38,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"Itsugun Cho,Hiroaki Saito","id":"f6d0321e0a0447da0af4f4d8cafaff0704005116","summary":"A high-quality open-domain dialogue generation model called Anna that is composed of a hierarchical self-attention network with multiple convolution filters and a topic-augmented network that outperforms baseline models in terms of response quality, parameter size and decoding speed.","score":3},{"url":"https://www.semanticscholar.org/paper/fa26b1182d1a76ad550694b57ba1d6afe73e238d","title":"Automatic Generation of Large-scale Multi-turn Dialogues from Reddit","venue":"International Conference on Computational Linguistics","year":2022,"referenceCount":19,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Daniil Huryn,William M. Hutsell,Jinho D. Choi","id":"fa26b1182d1a76ad550694b57ba1d6afe73e238d","summary":"Novel methods to automatically convert posts and their comments from discussion forums such as Reddit into multi-turn dialogues are presented, which are generalizable to any forums and allow for a massive amount of dialogues for diverse topics that can be used to pretrain language models.","score":3},{"url":"https://www.semanticscholar.org/paper/cddd04ca1810214a4bd17a39650043fd663eb373","title":"Neural Network With Hierarchical Attention Mechanism for Contextual Topic Dialogue Generation","venue":"IEEE Access","year":2022,"referenceCount":39,"citationCount":1,"influentialCitationCount":0,"publicationDate":2022,"authors":"Xiao Sun,Bingbing Ding","id":"cddd04ca1810214a4bd17a39650043fd663eb373","summary":"This work improves upon existing models and attention mechanisms and proposes a new hierarchical model to better solve the problem of dialogue context (the HAT model), which enables the model to obtain more contextual information when processing and improves the ability of the model in terms of contextual relevance to produce high-quality responses.","score":3},{"url":"https://www.semanticscholar.org/paper/d2bc6012afd5ea0eaf3b4f5484c179f465cbb66c","title":"SHONGLAP: A Large Bengali Open-Domain Dialogue Corpus","venue":"International Conference on Language Resources and Evaluation","year":2022,"referenceCount":49,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Syed Mostofa Monsur,Sakib Chowdhury,Shahrar Fatemi,Shafayat Ahmed","id":"d2bc6012afd5ea0eaf3b4f5484c179f465cbb66c","summary":"Experimental results show that the SHONGLAP corpus improves performance of large language models (BanglaBERT) in case of downstream classification tasks during fine-tuning and can serve as a strong baseline for future works.","score":3},{"url":"https://www.semanticscholar.org/paper/eb1ac44bbc0fe07c5f31f459c7199211239e90b8","title":"Open-domain Dialogue Generation: What We Can Do, Cannot Do, And Should Do Next","venue":"NLP4CONVAI","year":2022,"referenceCount":143,"citationCount":7,"influentialCitationCount":0,"publicationDate":2022,"authors":"Katharina Kann,Abteen Ebrahimi,Joewie J. Koh,Shiran Dudy,A. Roncone","id":"eb1ac44bbc0fe07c5f31f459c7199211239e90b8","summary":"The goal of this work is to provide an overview of recent advances in the field of open-domain dialogue, to summarize issues related to ethics, bias, and fairness that the field has identified as well as typical errors of dialogue systems and to outline important future challenges.","score":3},{"url":"https://www.semanticscholar.org/paper/4bd35d344c635b05f97f4d749741d196ff541bf3","title":"A Primer on Seq2Seq Models for Generative Chatbots","venue":"","year":2023,"referenceCount":196,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Vincenzo Scotti,L. Sbattella,R. Tedesco","id":"4bd35d344c635b05f97f4d749741d196ff541bf3","summary":"This paper examines recent trends in the development of open-domain data-driven generative chatbots, focusing on the Seq2Seq architectures, and examines possible architecture implementations as well as training and evaluation approaches.","score":3},{"url":"https://www.semanticscholar.org/paper/89e65078d37d076627818d9dba2c8ca9bf8f66bc","title":"Challenges in Building Intelligent Open-domain Dialog Systems","venue":"ACM Trans. Inf. Syst.","year":2019,"referenceCount":204,"citationCount":201,"influentialCitationCount":14,"publicationDate":"13/05/2019","authors":"Minlie Huang,Xiaoyan Zhu,Jianfeng Gao","id":"89e65078d37d076627818d9dba2c8ca9bf8f66bc","summary":"This article reviews the recent work on neural approaches that are devoted to addressing three challenges in developing intelligent open-domain dialog systems: semantics, consistency, and interactiveness.","score":3},{"url":"https://www.semanticscholar.org/paper/270b3f5201e835dd9a6a80fb8d749dba08dc88dd","title":"Generating Empathetic Responses by Looking Ahead the User’s Sentiment","venue":"IEEE International Conference on Acoustics, Speech, and Signal Processing","year":2019,"referenceCount":29,"citationCount":26,"influentialCitationCount":3,"publicationDate":"20/06/2019","authors":"Jamin Shin,Peng Xu,Andrea Madotto,Pascale Fung","id":"270b3f5201e835dd9a6a80fb8d749dba08dc88dd","summary":"This paper implements and evaluates three different possible implementations of sentiment look-ahead and empirically shows that the proposed approach can generate significantly more empathetic, relevant, and fluent responses than other competitive baselines such as multitask learning.","score":3},{"url":"https://www.semanticscholar.org/paper/6ebfbc954b9975d2f2651f380b9bdf46ae963178","title":"PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":37,"citationCount":193,"influentialCitationCount":27,"publicationDate":"17/10/2019","authors":"Siqi Bao,H. He,Fan Wang,Hua Wu","id":"6ebfbc954b9975d2f2651f380b9bdf46ae963178","summary":"This work proposes a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering, and introduces discrete latent variables to tackle the inherent one-to-many mapping problem in response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/11abce981e90585c142078b5c64b2cb8331b8794","title":"The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":56,"citationCount":57,"influentialCitationCount":8,"publicationDate":"09/11/2019","authors":"Kurt Shuster,Da Ju,Stephen Roller,Emily Dinan,Y-Lan Boureau,J. Weston","id":"11abce981e90585c142078b5c64b2cb8331b8794","summary":"D dodecaDialogue is introduced, a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the fine-tune and task transfer settings.","score":3},{"url":"https://www.semanticscholar.org/paper/3d8c305787ed208ea6ea0ccf958b740bcfccaece","title":"EmpDG: Multi-resolution Interactive Empathetic Dialogue Generation","venue":"International Conference on Computational Linguistics","year":2019,"referenceCount":62,"citationCount":84,"influentialCitationCount":21,"publicationDate":"20/11/2019","authors":"Qintong Li,Hongshen Chen,Z. Ren,Zhumin Chen,Zhaopeng Tu,Jun Ma","id":"3d8c305787ed208ea6ea0ccf958b740bcfccaece","summary":"A multi-resolution adversarial model – EmpDG is proposed, to generate more empathetic responses and an interactive adversarial learning framework which exploits the user feedback, to identify whether the generated responses evoke emotion perceptivity in dialogues.","score":3},{"url":"https://www.semanticscholar.org/paper/15704cdfe55ddd375e7fec9e71cba9956a73972e","title":"EmpTransfo: A Multi-head Transformer Architecture for Creating Empathetic Dialog Systems","venue":"The Florida AI Research Society","year":2020,"referenceCount":25,"citationCount":31,"influentialCitationCount":1,"publicationDate":"05/03/2020","authors":"Rohola Zandie,M. Mahoor","id":"15704cdfe55ddd375e7fec9e71cba9956a73972e","summary":"It is shown that utilizing the history of emotions and other metadata can improve the quality of generated conversations by the dialog system, and the proposed approach outperforms other models in terms of Hit@1 and PPL (Perplexity).","score":3},{"url":"https://www.semanticscholar.org/paper/404859dc02da6c9dcb924535894dad0dc56696f2","title":"An Empirical Investigation of Pre-Trained Transformer Language Models for Open-Domain Dialogue Generation","venue":"arXiv.org","year":2020,"referenceCount":69,"citationCount":15,"influentialCitationCount":2,"publicationDate":"09/03/2020","authors":"Piji Li","id":"404859dc02da6c9dcb924535894dad0dc56696f2","summary":"An empirical investigation of pre-trained Transformer-based auto-regressive language models for the task of open-domain dialogue generation with detailed numbers of automatic evaluation metrics on relevance and diversity of the generated results for the languages models as well as the baseline approaches are reported.","score":3},{"url":"https://www.semanticscholar.org/paper/71017cc6d270d28d9edcd47550450dc05edd65f4","title":"Can You Put it All Together: Evaluating Conversational Agents’ Ability to Blend Skills","venue":"Annual Meeting of the Association for Computational Linguistics","year":2020,"referenceCount":19,"citationCount":157,"influentialCitationCount":17,"publicationDate":"17/04/2020","authors":"Eric Michael Smith,Mary Williamson,Kurt Shuster,J. Weston,Y-Lan Boureau","id":"71017cc6d270d28d9edcd47550450dc05edd65f4","summary":"This work investigates several ways to combine models trained towards isolated capabilities, ranging from simple model aggregation schemes that require minimal additional training, to various forms of multi-task training that encompass several skills at all training stages.","score":3},{"url":"https://www.semanticscholar.org/paper/18c54279a916293153db45e6db8422eaa52539cd","title":"Open-Domain Conversational Agents: Current Progress, Open Problems, and Future Directions","venue":"arXiv.org","year":2020,"referenceCount":163,"citationCount":29,"influentialCitationCount":4,"publicationDate":"22/06/2020","authors":"Stephen Roller,Y.-Lan Boureau,J. Weston,Antoine Bordes,Emily Dinan,Angela Fan,David Gunning,Da Ju,Margaret Li,Spencer Poff,Pratik Ringshia,Kurt Shuster,Eric Michael Smith,Arthur D. Szlam,Jack Urbanek,Mary Williamson","id":"18c54279a916293153db45e6db8422eaa52539cd","summary":"The properties of continual learning, providing engaging content, and being well-behaved are discussed -- and how to measure success in providing them and their recommendations to the community are discussed.","score":3},{"url":"https://www.semanticscholar.org/paper/70af4173983eccc0beac29ed4602bf9db5568b92","title":"PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning","venue":"Findings","year":2020,"referenceCount":52,"citationCount":102,"influentialCitationCount":16,"publicationDate":"30/06/2020","authors":"Siqi Bao,H. He,Fan Wang,Hua Wu,Haifeng Wang,Wenquan Wu,Zhen Guo,Zhibin Liu,Xinchao Xu","id":"70af4173983eccc0beac29ed4602bf9db5568b92","summary":"To build a high-quality open-domain chatbot, this work introduces the effective training process of PLATO-2 via curriculum learning, achieving new state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/310ce0b1b4049206a260a711cc27cae5fad3700a","title":"Persona aware Response Generation with Emotions","venue":"IEEE International Joint Conference on Neural Network","year":2020,"referenceCount":45,"citationCount":3,"influentialCitationCount":0,"publicationDate":"01/07/2020","authors":"Mauajama Firdaus,Naveen Thangavelu,Asif Ekbal,P. Bhattacharyya","id":"310ce0b1b4049206a260a711cc27cae5fad3700a","summary":"This work proposes a persona aware attention framework employing an encoder-decoder approach in which the system can generate specific and consistent responses in accordance to the provided personality information and the conversational history.","score":3},{"url":"https://www.semanticscholar.org/paper/9fb623c516994ba4ec1365db16afced31ac23520","title":"What If Bots Feel Moods?","venue":"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval","year":2020,"referenceCount":46,"citationCount":12,"influentialCitationCount":1,"publicationDate":"25/07/2020","authors":"L. Qiu,Yingwai Shiu,Pingping Lin,Ruihua Song,Yue Liu,Dongyan Zhao,Rui Yan","id":"9fb623c516994ba4ec1365db16afced31ac23520","summary":"An emotion-aware transition network is proposed to model the dynamic emotional flow and enhance context-response matching in retrieval-based dialogue systems with learnt intrinsic emotion features through a multi-task learning framework and is applied to a real IoT application.","score":3},{"url":"https://www.semanticscholar.org/paper/d8a0f9bb452bdd4408343d80336055d320cb6b1e","title":"Which Kind Is Better in Open-domain Multi-turn Dialog, Hierarchical or Non-hierarchical Models? An Empirical Study","venue":"arXiv.org","year":2020,"referenceCount":32,"citationCount":1,"influentialCitationCount":0,"publicationDate":"07/08/2020","authors":"Tian Lan,Xian-Ling Mao,Wei Wei,Heyan Huang","id":"d8a0f9bb452bdd4408343d80336055d320cb6b1e","summary":"Nearly all hierarchical models are worse than non-hierarchical models in open-domain multi-turn dialog generation, except for the HRAN model, and the word-level attention mechanism is so powerful for hierarchical models is because it can leverage context information more effectively, especially the fine-grained information.","score":3},{"url":"https://www.semanticscholar.org/paper/63913530782522e0d7ca5deceb40c08d606cafab","title":"Deploying Lifelong Open-Domain Dialogue Learning","venue":"arXiv.org","year":2020,"referenceCount":38,"citationCount":17,"influentialCitationCount":1,"publicationDate":"18/08/2020","authors":"Kurt Shuster,Jack Urbanek,Emily Dinan,Arthur D. Szlam,J. Weston","id":"63913530782522e0d7ca5deceb40c08d606cafab","summary":"This work builds and deploy a role-playing game, whereby human players converse with learning agents situated in an open-domain fantasy world and shows that by training models on the conversations they have with humans in the game the models progressively improve, as measured by automatic metrics and online engagement scores.","score":3},{"url":"https://www.semanticscholar.org/paper/c6d38e105562ae0a5d9b21fb4333212f36a3e041","title":"A Survey of Evaluation Metrics Used for NLG Systems","venue":"ACM Computing Surveys","year":2020,"referenceCount":206,"citationCount":97,"influentialCitationCount":10,"publicationDate":"27/08/2020","authors":"Ananya B. Sai,Akash Kumar Mohankumar,Mitesh M. Khapra","id":"c6d38e105562ae0a5d9b21fb4333212f36a3e041","summary":"This survey of automatic evaluation metrics for evaluating Natural Language Generation (NLG) systems highlights the challenges, proposes a coherent taxonomy for organising existing evaluation metrics, and briefly describes different existing metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/fa544c82344a556b69316f05f2ea6f51fa202139","title":"The Adapter-Bot: All-In-One Controllable Conversational Model","venue":"AAAI Conference on Artificial Intelligence","year":2020,"referenceCount":75,"citationCount":46,"influentialCitationCount":3,"publicationDate":"28/08/2020","authors":"Andrea Madotto,Zhaojiang Lin,Yejin Bang,Pascale Fung","id":"fa544c82344a556b69316f05f2ea6f51fa202139","summary":"The Adapter-Bot is presented, a generative chat-bot that uses a fixed backbone conversational model such as DialGPT and triggers on-demand dialogue skills via different adapters that can be trained independently, thus allowing a continual integration of skills without retraining the entire model.","score":3},{"url":"https://www.semanticscholar.org/paper/7d5b2388945b5ba53512ab775d80f4659092307f","title":"Towards Empathetic Dialogue Generation over Multi-type Knowledge.","venue":"","year":2020,"referenceCount":55,"citationCount":16,"influentialCitationCount":7,"publicationDate":"21/09/2020","authors":"Qintong Li,Piji Li,Zhumin Chen,Z. Ren","id":"7d5b2388945b5ba53512ab775d80f4659092307f","summary":"This work proposes to leverage multi-type knowledge, i.e, the commonsense knowledge and emotional lexicon, to explicitly understand and express emotions in empathetic dialogue generation, and introduces a multi- type knowledge-aware context encoder to learn emotional context representations and distill emotional signals.","score":3},{"url":"https://www.semanticscholar.org/paper/66c8315b46c64e7bf375dc3b4b718d741bc697ee","title":"Empathetic Dialogue Generation via Knowledge Enhancing and Emotion Dependency Modeling","venue":"arXiv.org","year":2020,"referenceCount":49,"citationCount":9,"influentialCitationCount":3,"publicationDate":"21/09/2020","authors":"Qintong Li,Piji Li,Zhumin Chen,Z. Ren","id":"66c8315b46c64e7bf375dc3b4b718d741bc697ee","summary":"This work proposes a knowledge-enhanced framework, named Know-EDG, which outperforms state-of-the-art baselines in terms of automatic metrics and human evaluations and proposes an emotion-focused attention mechanism to exploit the emotional dependencies between dialogue context and target empathetic response.","score":3},{"url":"https://www.semanticscholar.org/paper/01caaf3a67ad31c93048a29fff90e62ad3dac167","title":"Knowledge Bridging for Empathetic Dialogue Generation","venue":"AAAI Conference on Artificial Intelligence","year":2020,"referenceCount":49,"citationCount":33,"influentialCitationCount":14,"publicationDate":"21/09/2020","authors":"Qintong Li,Pijian Li,Z. Ren,Pengjie Ren,Zhumin Chen","id":"01caaf3a67ad31c93048a29fff90e62ad3dac167","summary":"This work proposes to leverage external knowledge, including commonsense knowledge and emotional lexical knowledge, to explicitly understand and express emotions in empathetic dialogue generation to address the problems of lack of external knowledge and limited dialogue history.","score":3},{"url":"https://www.semanticscholar.org/paper/9c72b6a869cbec916d5e6b05c4ea36056c93c52c","title":"Spot the Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":40,"citationCount":23,"influentialCitationCount":2,"publicationDate":"05/10/2020","authors":"Jan Deriu,Don Tuggener,Pius von Däniken,Jon Ander Campos,Álvaro Rodrigo,Thiziri Belkacem,Aitor Soroa Etxabe,Eneko Agirre,Mark Cieliebak","id":"9c72b6a869cbec916d5e6b05c4ea36056c93c52c","summary":"A cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots, and incorporates a metric that measures which chatbot can uphold human-like behavior the longest, i.e., \\emph{Survival Analysis}.","score":3},{"url":"https://www.semanticscholar.org/paper/4236663e6416423fca02d5b058302adcb78f51f3","title":"COSMIC: COmmonSense knowledge for eMotion Identification in Conversations","venue":"Findings","year":2020,"referenceCount":45,"citationCount":141,"influentialCitationCount":37,"publicationDate":"06/10/2020","authors":"Deepanway Ghosal,Navonil Majumder,Alexander Gelbukh,Rada Mihalcea,Soujanya Poria","id":"4236663e6416423fca02d5b058302adcb78f51f3","summary":"This paper proposes COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation.","score":3},{"url":"https://www.semanticscholar.org/paper/ef3a96d8f42e8caa1994caba2e53ca98121b4d1f","title":"Plug-and-Play Conversational Models","venue":"Findings","year":2020,"referenceCount":65,"citationCount":42,"influentialCitationCount":6,"publicationDate":"09/10/2020","authors":"Andrea Madotto,Etsuko Ishii,Zhaojiang Lin,Sumanth Dathathri,Pascale Fung","id":"ef3a96d8f42e8caa1994caba2e53ca98121b4d1f","summary":"This paper proposes and evaluates plug-and-play methods for controllable response generation, and demonstrates a high degree of control over the generated conversational responses with regard to multiple desired attributes, while being fluent.","score":3},{"url":"https://www.semanticscholar.org/paper/314358d6e9969cb89da0ad0b6aa4f406294d3ff4","title":"Generalized Conditioned Dialogue Generation Based on Pre-trained Language Model","venue":"arXiv.org","year":2020,"referenceCount":38,"citationCount":3,"influentialCitationCount":1,"publicationDate":"21/10/2020","authors":"Yan Zeng,J. Nie","id":"314358d6e9969cb89da0ad0b6aa4f406294d3ff4","summary":"This work proposes to complement the labeled dialogue data with labeled non-dialogue text data, and fine-tune BERT based on them, and utilizes BERT for both encoder and decoder via different input representations and self-attention masks in order to distinguish the source and target side.","score":3},{"url":"https://www.semanticscholar.org/paper/0f8cb4a6c794ee18d5f9177782cf07d000adffca","title":"An Evaluation Protocol for Generative Conversational Systems","venue":"arXiv.org","year":2020,"referenceCount":52,"citationCount":5,"influentialCitationCount":2,"publicationDate":"24/10/2020","authors":"Seolhwa Lee,Heuiseok Lim,João Sedoc","id":"0f8cb4a6c794ee18d5f9177782cf07d000adffca","summary":"The findings show that DialoGPT and Blender are superior systems using Bradley-Terry model and TrueSkill ranking methods and demonstrate the feasibility of the protocol for the evaluation of conversational models using head-to-head pairwise comparison.","score":3},{"url":"https://www.semanticscholar.org/paper/240f3eb516051b1e9f5baced99855e8495a1298a","title":"A Taxonomy of Empathetic Response Intents in Human Social Conversations","venue":"International Conference on Computational Linguistics","year":2020,"referenceCount":58,"citationCount":51,"influentialCitationCount":7,"publicationDate":"01/12/2020","authors":"A. Welivita,P. Pu","id":"240f3eb516051b1e9f5baced99855e8495a1298a","summary":"A large-scale taxonomy for empathetic response intents is produced and novel and important empathy patterns in human-human open-domain conversations are revealed and can serve as heuristics for hybrid approaches.","score":3},{"url":"https://www.semanticscholar.org/paper/0e635104e5378bc226b0e07e429fcef44f959fc8","title":"Robust Dialogue Utterance Rewriting as Sequence Tagging","venue":"arXiv.org","year":2020,"referenceCount":29,"citationCount":6,"influentialCitationCount":2,"publicationDate":"29/12/2020","authors":"Jie Hao,Linfeng Song,Liwei Wang,Kun Xu,Zhaopeng Tu,Dong Yu","id":"0e635104e5378bc226b0e07e429fcef44f959fc8","summary":"A novel sequence-tagging-based model is proposed so that the search space is significantly reduced, yet the core of this task is still well covered, and the model's outputs may lack fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/6c48cedd98da74f4e1b29dc89aafd3c374e069fa","title":"Context-Controlled Topic-Aware Neural Response Generation for Open-Domain Dialog Systems","venue":"Information Processing & Management","year":2021,"referenceCount":52,"citationCount":20,"influentialCitationCount":0,"publicationDate":"01/01/2021","authors":"Yanxiang Ling,Fei Cai,Xuejun Hu,Jun Liu,Wanyu Chen,Honghui Chen","id":"6c48cedd98da74f4e1b29dc89aafd3c374e069fa","summary":"A Context-Controlled Topic-Aware neural response generation model, i.e., CCTA, which makes dialog context interact with the process of topic representing and transiting to achieve balanced improvements on response informativeness and contextual coherence and finds that topic transition modeling can work as an auxiliary learning task to boost the response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/983921bd0ccaee71df7580ce13dd0d53dba5f368","title":"Empathetic BERT2BERT Conversational Model: Learning Arabic Language Generation with Little Data","venue":"Workshop on Arabic Natural Language Processing","year":2021,"referenceCount":34,"citationCount":12,"influentialCitationCount":1,"publicationDate":"07/03/2021","authors":"Tarek Naous,Wissam Antoun,Reem A. Mahmoud,Hazem M. Hajj","id":"983921bd0ccaee71df7580ce13dd0d53dba5f368","summary":"A transformer-based encoder-decoder initialized with AraBERT parameters is proposed, validating its high capability in exhibiting empathy while generating relevant and fluent responses in open-domain settings.","score":3},{"url":"https://www.semanticscholar.org/paper/5b41b3c31edb20f7b08ebb8fa49b9d0887f01a3c","title":"Enhancing Cognitive Models of Emotions with Representation Learning","venue":"Workshop on Cognitive Modeling and Computational Linguistics","year":2021,"referenceCount":27,"citationCount":1,"influentialCitationCount":0,"publicationDate":"20/04/2021","authors":"Yuting Guo,Jinho D. Choi","id":"5b41b3c31edb20f7b08ebb8fa49b9d0887f01a3c","summary":"A novel deep learning-based framework to generate embedding representations of fine-grained emotions that can be used to computationally describe psychological models of emotions that enables to interpret dynamically learned representations optimized for an emotion classification task.","score":3},{"url":"https://www.semanticscholar.org/paper/f4bef31094420c572e6c4159c45234c741d9e5bf","title":"Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":23,"citationCount":14,"influentialCitationCount":0,"publicationDate":"25/05/2021","authors":"Tatsuya Ide,Daisuke Kawahara","id":"f4bef31094420c572e6c4159c45234c741d9e5bf","summary":"This model based on BART, a pre-trained transformer encoder-decoder model, is trained to generate responses and recognize emotions simultaneously, and weight the losses for the tasks to control the update of parameters.","score":3},{"url":"https://www.semanticscholar.org/paper/87102d1054611d8cf8bc4e743516ef3a613766ac","title":"A Simple and Efficient Multi-Task Learning Approach for Conditioned Dialogue Generation","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":39,"citationCount":10,"influentialCitationCount":1,"publicationDate":"01/06/2021","authors":"Yan Zeng,J. Nie","id":"87102d1054611d8cf8bc4e743516ef3a613766ac","summary":"This work proposes a multi-task learning approach to leverage both labeled dialogue and text data, which outperforms the state-of-the-art models by leveraging the labeled texts, and it obtains larger improvement in performance comparing to the previous methods to leverage text data.","score":3},{"url":"https://www.semanticscholar.org/paper/a7a00e14c60fd13bf08dc435e9b0fdd96d050b99","title":"Generating Negative Samples by Manipulating Golden Responses for Unsupervised Learning of a Response Evaluation Model","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":28,"citationCount":4,"influentialCitationCount":0,"publicationDate":"01/06/2021","authors":"chaeHun Park,Eugene Jang,Wonsuk Yang,Jong C. Park","id":"a7a00e14c60fd13bf08dc435e9b0fdd96d050b99","summary":"It is found that using the negative samples generated by the unsupervised learning of a golden response to create a new negative response that is designed to be inappropriate within the context while maintaining high similarity with the original golden response can increase the model's correlation with human evaluations.","score":3},{"url":"https://www.semanticscholar.org/paper/c8419114a8972e4945052e9699b69dfa858ab17c","title":"Towards Quantifiable Dialogue Coherence Evaluation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":29,"citationCount":10,"influentialCitationCount":3,"publicationDate":"01/06/2021","authors":"Zheng Ye,Liucun Lu,Lishan Huang,Liang Lin,Xiaodan Liang","id":"c8419114a8972e4945052e9699b69dfa858ab17c","summary":"Experimental results show that the model trained by QuantiDCE presents stronger correlations with human judgements than the other state-of-the-art metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/753baa88a7f49f6605ae30f77a54dbb9e074c8b4","title":"DynaEval: Unifying Turn and Dialogue Level Evaluation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":61,"citationCount":35,"influentialCitationCount":6,"publicationDate":"02/06/2021","authors":"Chen Zhang,Yiming Chen,L. F. D’Haro,Yan Zhang,Thomas Friedrichs,Grandee Lee,Haizhou Li","id":"753baa88a7f49f6605ae30f77a54dbb9e074c8b4","summary":"DynaEval, a unified automatic evaluation framework which is not only capable of performing turn-level evaluation, but also holistically considers the quality of the entire dialogue, is proposed.","score":3},{"url":"https://www.semanticscholar.org/paper/d08a6a41e2b16928a1dc93b259bffbe37dae021d","title":"Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation","venue":"Findings","year":2021,"referenceCount":93,"citationCount":15,"influentialCitationCount":2,"publicationDate":"10/06/2021","authors":"Prakhar Gupta,Yulia Tsvetkov,Jeffrey P. Bigham","id":"d08a6a41e2b16928a1dc93b259bffbe37dae021d","summary":"This work proposes mask-and-fill and keyword-guided approaches that generate negative examples for training more robust dialogue systems and proposes approaches for automatically creating adversarial negative training data to help ranking and evaluation models learn features beyond content similarity.","score":3},{"url":"https://www.semanticscholar.org/paper/88064de690af282dbdf222774f03ff070b9df22b","title":"Beyond Goldfish Memory: Long-Term Open-Domain Conversation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":39,"citationCount":104,"influentialCitationCount":32,"publicationDate":"15/07/2021","authors":"Jing Xu,Arthur D. Szlam,J. Weston","id":"88064de690af282dbdf222774f03ff070b9df22b","summary":null,"score":3},{"url":"https://www.semanticscholar.org/paper/8f31038de5cadc3171735c0410511c044d216463","title":"Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":18,"citationCount":8,"influentialCitationCount":3,"publicationDate":"19/07/2021","authors":"Nyoungwoo Lee,Suwon Shin,J. Choo,Ho‐Jin Choi,S. Myaeng","id":"8f31038de5cadc3171735c0410511c044d216463","summary":"Automatic metrics and human evaluation results show that the proposed 45k multi-modal dialogue dataset can be effectively used as training data for multi- modal dialogue systems which require an understanding of images and text in a context-aware manner.","score":3},{"url":"https://www.semanticscholar.org/paper/9f54b02d32835a6dc977a335444df707494763ec","title":"Proto: A Neural Cocktail for Generating Appealing Conversations","venue":"arXiv.org","year":2021,"referenceCount":38,"citationCount":7,"influentialCitationCount":0,"publicationDate":"06/09/2021","authors":"Sougata Saha,Souvik Das,Elizabeth Soper,Erin Pacquetet,R. Srihari","id":"9f54b02d32835a6dc977a335444df707494763ec","summary":"This paper dissect and analyze the different components and conversation strategies implemented by the socialbot, which enables it to generate colloquial, empathetic, engaging, self-rectifying, factually correct, and on-topic response, which has helped it achieve consistent scores throughout the competition.","score":3},{"url":"https://www.semanticscholar.org/paper/91aca4acc06348c67df00180191d02297c563d9f","title":"Empathetic Dialogue Generation with Pre-trained RoBERTa-GPT2 and External Knowledge","venue":"International Workshop on Spoken Dialogue Systems Technology","year":2021,"referenceCount":43,"citationCount":7,"influentialCitationCount":2,"publicationDate":"07/09/2021","authors":"Ye Liu,Wolfgang Maier,W. Minker,Stefan Ultes","id":"91aca4acc06348c67df00180191d02297c563d9f","summary":"To enable the empathetic ability of RoBERTa-GPT2 model, this work proposes a commonsense knowledge and emotional concepts extractor, in which the commonsensible andotional concepts of dialogue context are extracted for the GPT-2 decoder.","score":3},{"url":"https://www.semanticscholar.org/paper/690edf89431f26d355fc4a991a489d9d080e1ebe","title":"Alquist 4.0: Towards Social Intelligence Using Generative Models and Dialogue Personalization","venue":"arXiv.org","year":2021,"referenceCount":30,"citationCount":10,"influentialCitationCount":1,"publicationDate":"16/09/2021","authors":"Jakub Konrád,Jan Pichl,Petro Marek,Petr Lorenc,Van Duy Ta,Ondrej Kobza,L. Hýlová,J. Sedivý","id":"690edf89431f26d355fc4a991a489d9d080e1ebe","summary":"The principles and inner workings of individual components of the open-domain dialogue system Alquist developed within the Alexa Prize Socialbot Grand Challenge 4 are presented and the experiments conducted to evaluate them are presented.","score":3},{"url":"https://www.semanticscholar.org/paper/30873c32db5a219a58be928d5692cce48be1d3a0","title":"Few-Shot Bot: Prompt-Based Learning for Dialogue Systems","venue":"arXiv.org","year":2021,"referenceCount":116,"citationCount":35,"influentialCitationCount":6,"publicationDate":"15/10/2021","authors":"Andrea Madotto,Zhaojiang Lin,Genta Indra Winata,Pascale Fung","id":"30873c32db5a219a58be928d5692cce48be1d3a0","summary":"An end-to-end chatbot named the Few-Shot Bot is created, which automatically selects the most appropriate conversational skill, queries different knowledge bases or the internet, and uses the retrieved knowledge to generate a human-like response, all using only few dialogue examples per skill.","score":3},{"url":"https://www.semanticscholar.org/paper/84363d3326105df2d297898e411be02b62e7df63","title":"Modeling Performance in Open-Domain Dialogue with PARADISE","venue":"arXiv.org","year":2021,"referenceCount":65,"citationCount":3,"influentialCitationCount":0,"publicationDate":"21/10/2021","authors":"M. Walker,Colin Harmon,James Graupera,Davan Harrison,S. Whittaker","id":"84363d3326105df2d297898e411be02b62e7df63","summary":"A PARADISE model is developed for predicting the performance of Athena, a dialogue system that has participated in thousands of conversations with real users, while competing as a finalist in the Alexa Prize.","score":3},{"url":"https://www.semanticscholar.org/paper/54e00dfd4821b0b21bb4e8392336a8c8ac062d43","title":"Conversational Agents: Goals, Technologies, Vision and Challenges","venue":"Italian National Conference on Sensors","year":2021,"referenceCount":254,"citationCount":21,"influentialCitationCount":1,"publicationDate":"01/12/2021","authors":"Merav Allouch,A. Azaria,Rina Azoulay-Schwartz","id":"54e00dfd4821b0b21bb4e8392336a8c8ac062d43","summary":"The main areas in which CAs are successful are described along with the main technologies that enable the creation of CAs and the primary tools and datasets that may be useful for the development and evaluation ofCAs of different categories are described.","score":3},{"url":"https://www.semanticscholar.org/paper/3af37400f1f9a4f4f211c4a472e18963edc2b34f","title":"ValueNet: A New Dataset for Human Value Driven Dialogue System","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":47,"citationCount":11,"influentialCitationCount":0,"publicationDate":"12/12/2021","authors":"Liang Qiu,Yizhou Zhao,Jinchao Li,Pan Lu,Baolin Peng,Jianfeng Gao,Song-Chun Zhu","id":"3af37400f1f9a4f4f211c4a472e18963edc2b34f","summary":"This work presents a new large-scale human value dataset called ValueNet, which contains human attitudes on 21,374 text scenarios and is the first one trying to incorporate a value model into emotionally intelligent dialogue systems.","score":3},{"url":"https://www.semanticscholar.org/paper/c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7","title":"Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":54,"citationCount":10,"influentialCitationCount":6,"publicationDate":"16/12/2021","authors":"Yoonna Jang,J. Lim,Yuna Hur,Dongsuk Oh,Suhyune Son,Yeonsoo Lee,Donghoon Shin,Seungryong Kim,Heuiseok Lim","id":"c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7","summary":"This work introduces a call For Customized conversation (FoCus) dataset where the customized answers are built with the user's persona and Wikipedia knowledge and shows that the utterances of the data are constructed with the proper knowledge and persona through grounding quality assessment.","score":3},{"url":"https://www.semanticscholar.org/paper/e0af8f2dd390fabcdf2c373640833efc62faa530","title":"FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":48,"citationCount":3,"influentialCitationCount":0,"publicationDate":"14/02/2022","authors":"Jianqiao Zhao,Yanyang Li,Wanyu Du,Yangfeng Ji,Dong Yu,M. Lyu,Liwei Wang","id":"e0af8f2dd390fabcdf2c373640833efc62faa530","summary":"This work develops the first consensus-based dialogue evaluation framework, FlowEval, which provides a reference-free approach for dialog evaluation by finding pseudo-references and proposes segment act, an extension of dialog act from utterance level to segment level, and crowdsource a large-scale dataset for it.","score":3},{"url":"https://www.semanticscholar.org/paper/c8fba3d80a3b6add6fb386f458850d02b77f34bb","title":"Generating Relevant and Informative Questions for Open-Domain Conversations","venue":"ACM Trans. Inf. Syst.","year":2022,"referenceCount":80,"citationCount":1,"influentialCitationCount":0,"publicationDate":"14/02/2022","authors":"Yanxiang Ling,Fei Cai,Jun Liu,Honghui Chen,M. de Rijke","id":"c8fba3d80a3b6add6fb386f458850d02b77f34bb","summary":"A context-enhanced neural question generation model that leverages the conversational context to predict question content and pattern, then performs question decoding, and is the first to extend the application of QG to the multi-turn open-domain conversational scenario.","score":3},{"url":"https://www.semanticscholar.org/paper/d73d3a82da0bc93be238c286abfd06722247d298","title":"Rethinking and Refining the Distinct Metric","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":50,"citationCount":3,"influentialCitationCount":0,"publicationDate":"28/02/2022","authors":"Siyang Liu,Sahand Sabour,Yinhe Zheng,Pei Ke,Xiaoyan Zhu,Minlie Huang","id":"d73d3a82da0bc93be238c286abfd06722247d298","summary":"This work refine the calculation of distinct scores by scaling the number of distinct tokens based on their expectations, and shows that the proposed metric, Expectation-Adjusted Distinct (EAD), correlates better with human judgment in evaluating response diversity.","score":3},{"url":"https://www.semanticscholar.org/paper/1e704b99a04aad6d6d7e665616b7d4ed2513da02","title":"Probing the Robustness of Trained Metrics for Conversational Dialogue Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":19,"citationCount":2,"influentialCitationCount":0,"publicationDate":"28/02/2022","authors":"Jan Deriu,Don Tuggener,Pius von Daniken,Mark Cieliebak","id":"1e704b99a04aad6d6d7e665616b7d4ed2513da02","summary":"An adversarial method to stress-test trained metrics for the evaluation of conversational dialogue systems using Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics is introduced.","score":3},{"url":"https://www.semanticscholar.org/paper/4ebff21b83277a523d9ce84c5cc745074b1f642e","title":"MISC: A Mixed Strategy-Aware Model integrating COMET for Emotional Support Conversation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":56,"citationCount":24,"influentialCitationCount":5,"publicationDate":"25/03/2022","authors":"Quan Tu,Yanran Li,Jianwei Cui,Bin Wang,Jiaxin Wen,Rui Yan","id":"4ebff21b83277a523d9ce84c5cc745074b1f642e","summary":"A novel model is proposed, which firstly infers the user’s fine-grained emotional status, and then responds skillfully using a mixture of strategy, which reveals the benefits of fine- grained emotion understanding as well as mixed-up strategy modeling.","score":3},{"url":"https://www.semanticscholar.org/paper/aab1dead436211a7d9eb7a717ee63a5d23cf23f0","title":"Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional Characters with only a Few Utterances","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":58,"citationCount":6,"influentialCitationCount":1,"publicationDate":"22/04/2022","authors":"Seungju Han,Beomsu Kim,Jin Yong Yoo,Seokjun Seo,Sangbum Kim,Enkhbayar Erdenee,Buru Chang","id":"aab1dead436211a7d9eb7a717ee63a5d23cf23f0","summary":"A new method named Pseudo Dialog Prompting (PDP) is proposed that generates responses by leveraging the power of large-scale language models with prompts containing the target character’s utterances to better reflect the style of fictional characters.","score":3},{"url":"https://www.semanticscholar.org/paper/32f87b51e3ba42894821716b8145bde41fc65983","title":"Semantic Diversity in Dialogue with Natural Language Inference","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":36,"citationCount":6,"influentialCitationCount":0,"publicationDate":"03/05/2022","authors":"Katherine Stasaski,Marti A. Hearst","id":"32f87b51e3ba42894821716b8145bde41fc65983","summary":"It is shown that the contradiction relation is more useful than the neutral relation for measuring this diversity and that incorporating the NLI model’s confidence achieves state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/77ced33cba86b4d01fbfe6622c8f564c89d6a1b3","title":"A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration","venue":"arXiv.org","year":2022,"referenceCount":39,"citationCount":6,"influentialCitationCount":0,"publicationDate":"05/05/2022","authors":"Shaojie Jiang,Ruqing Zhang,Svitlana Vakulenko,M. de Rijke","id":"77ced33cba86b4d01fbfe6622c8f564c89d6a1b3","summary":"The key idea is to teach a LM to generate high probabilities for label tokens and low probabilities of negative candidates, which yields much less repetitive texts and a higher generation quality than baseline approaches, achieving the new state-of-the-art performance on text degeneration.","score":3},{"url":"https://www.semanticscholar.org/paper/086f3f9f023f0127f4be03a21189a1e90ffbb01f","title":"Empathetic Conversational Systems: A Review of Current Advances, Gaps, and Opportunities","venue":"IEEE Transactions on Affective Computing","year":2022,"referenceCount":132,"citationCount":3,"influentialCitationCount":0,"publicationDate":"09/05/2022","authors":"Aravind Sesagiri Raamkumar,Yinping Yang","id":"086f3f9f023f0127f4be03a21189a1e90ffbb01f","summary":"It is recommended that future studies should address key gaps in areas of detecting and authenticating emotions at the entity level, handling multimodal inputs, displaying more nuanced empathetic behaviors, and encompassing additional dialogue system features.","score":3},{"url":"https://www.semanticscholar.org/paper/d69ec0bbc9fc4fe898ac8cb73f629d253358bf66","title":"Stop Filtering: Multi-View Attribute-Enhanced Dialogue Learning","venue":"arXiv.org","year":2022,"referenceCount":67,"citationCount":2,"influentialCitationCount":0,"publicationDate":"23/05/2022","authors":"Yiwei Li,Bin Sun,Shaoxiong Feng,Kan Li","id":"d69ec0bbc9fc4fe898ac8cb73f629d253358bf66","summary":"A multi-view attribute-enhanced dialogue learning framework that strengthens the attribute-related features more robustly and comprehensively and can improve the performance of models by enhancing dialogue attributes and fusing view-speciﬁc knowledge.","score":3},{"url":"https://www.semanticscholar.org/paper/d6a60f41e6e53469042259ce3c281907907c0993","title":"Building a Dialogue Corpus Annotated with Expressed and Experienced Emotions","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":26,"citationCount":2,"influentialCitationCount":0,"publicationDate":"24/05/2022","authors":"Tatsuya Ide,Daisuke Kawahara","id":"d6a60f41e6e53469042259ce3c281907907c0993","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/36c50e6638dddc8324eef9bfa064bfcab80cbef4","title":"ProsocialDialog: A Prosocial Backbone for Conversational Agents","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":56,"citationCount":32,"influentialCitationCount":6,"publicationDate":"25/05/2022","authors":"Hyunwoo Kim,Youngjae Yu,Liwei Jiang,Ximing Lu,Daniel Khashabi,Gunhee Kim,Yejin Choi,Maarten Sap","id":"36c50e6638dddc8324eef9bfa064bfcab80cbef4","summary":"This work introduces ProsocialDialog, the first large-scale multi-turn dialogue dataset to teach conversational agents to respond to problematic content following social norms, and introduces a dialogue safety detection module, Canary, capable of generating RoTs given conversational context, and a socially-informed dialogue agent, Prost.","score":3},{"url":"https://www.semanticscholar.org/paper/cb1ecd3a14c5a65c3f887cfd3072bc05f1eea70c","title":"CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI","venue":"arXiv.org","year":2022,"referenceCount":83,"citationCount":7,"influentialCitationCount":1,"publicationDate":"29/05/2022","authors":"Yirong Chen,Weiquan Fan,Xiaofen Xing,Jianxin Pang,Minlie Huang,W. Han,Qianfeng Tie,Xiangmin Xu","id":"cb1ecd3a14c5a65c3f887cfd3072bc05f1eea70c","summary":"This work proposes CPED, a large-scale Chinese personalized and emotional dialogue dataset, which consists of multi-source knowledge related to empathy and personal characteristic, to be widely adopted by the NLP community as a new open benchmark for conversational AI research.","score":3},{"url":"https://www.semanticscholar.org/paper/e86869d44e78d4cffd1bf1b62f2f8e56a519e23c","title":"E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation","venue":"arXiv.org","year":2022,"referenceCount":83,"citationCount":12,"influentialCitationCount":0,"publicationDate":"30/05/2022","authors":"Qihuang Zhong,Liang Ding,Juhua Liu,Bo Du,Dacheng Tao","id":"e86869d44e78d4cffd1bf1b62f2f8e56a519e23c","summary":"This work proposes an encoding-enhancedseq2seq pretraining strategy, namely E2S2, which improves the seq2seq models via integrating more efﬁcient self-supervised information into the encoders, and proves that the encoder takes an important but under-exploitation role than the decoder regarding the downstream performance and neuron activation.","score":3},{"url":"https://www.semanticscholar.org/paper/45645b392ce5cd914007b5ae2c572c0cd591e835","title":"Emotion Recognition in Conversation using Probabilistic Soft Logic","venue":"arXiv.org","year":2022,"referenceCount":40,"citationCount":0,"influentialCitationCount":0,"publicationDate":"14/07/2022","authors":"Eriq Augustine,Pegah Jandaghi,Alon Albalak,Connor Pryor,Charles Dickens,William Wang,L. Getoor","id":"45645b392ce5cd914007b5ae2c572c0cd591e835","summary":"This work explores an approach to ERC that exploits the use of neural embeddings along with complex structures in dialogues, and implements it in a framework called Probabilistic Soft Logic (PSL), a declarative templating language that uses first-order like logical rules that when combined with data, define a particular class of graphical model.","score":3},{"url":"https://www.semanticscholar.org/paper/5c474c68dea579784eb61f84c6250d3d22dfc485","title":"Towards a sentiment-aware conversational agent","venue":"International Conference on Intelligent Virtual Agents","year":2022,"referenceCount":39,"citationCount":0,"influentialCitationCount":0,"publicationDate":"24/07/2022","authors":"Isabel Dias,Ricardo Rei,Patrícia Pereira,Luísa Coheur","id":"5c474c68dea579784eb61f84c6250d3d22dfc485","summary":"Results show that explicitly guiding the text generation model with a pre-defined set of sentiment sentences leads to clear improvements, regarding the expressed sentiment and the quality of the generated text.","score":3},{"url":"https://www.semanticscholar.org/paper/1c25b49fb6a2789597320a9e3591a6e51f1ed6ed","title":"Neural Generation Meets Real People: Building a Social, Informative Open-Domain Dialogue Agent","venue":"SIGDIAL Conferences","year":2022,"referenceCount":71,"citationCount":1,"influentialCitationCount":0,"publicationDate":"25/07/2022","authors":"Ethan A. Chi,Ashwin Paranjape,A. See,Caleb Chiam,Kathleen Kenealy,Swee Kiat Lim,Amelia Hardy,Chetanya Rastogi,Hao Li,Alexander Iyabor,Yutong He,Hari Sowrirajan,Peng Qi,Kaushik Ram Sadagopan,Nguyet Minh Phu,Dilara Soylu,Jillian Tang,A. Narayan,Giovanni Campagna,Christopher D. Manning","id":"1c25b49fb6a2789597320a9e3591a6e51f1ed6ed","summary":"Aiming to be both informative and conversational, the Chirpy Cardinal bot chats with users in an authentic, emotionally intelligent way by integrating controlled neural generation with scaffolded, hand-written dialogue, producing an engaging and socially fluent experience.","score":3},{"url":"https://www.semanticscholar.org/paper/b0e7055fcbb33e0cf1a93a27b483db66a57ffd5b","title":"A Systematic Evaluation of Response Selection for Open Domain Dialogue","venue":"SIGDIAL Conferences","year":2022,"referenceCount":41,"citationCount":2,"influentialCitationCount":2,"publicationDate":"08/08/2022","authors":"Behnam Hedayatnia,Di Jin,Yang Liu,Dilek Z. Hakkani-Tür","id":"b0e7055fcbb33e0cf1a93a27b483db66a57ffd5b","summary":"This work curated a dataset where responses from multiple response generators produced for the same dialog context are manually annotated as appropriate (positive) and inappropriate (negative) and argues that such training data better matches the actual use case examples, enabling the models to learn to rank responses effectively.","score":3},{"url":"https://www.semanticscholar.org/paper/9a1e0b8cc7a94dbe3929bb350bd04f5017a88515","title":"Building the Intent Landscape of Real-World Conversational Corpora with Extractive Question-Answering Transformers","venue":"arXiv.org","year":2022,"referenceCount":44,"citationCount":0,"influentialCitationCount":0,"publicationDate":"26/08/2022","authors":"Jean-Philippe Corbeil,Mia Taige Li,H. Ghavidel","id":"9a1e0b8cc7a94dbe3929bb350bd04f5017a88515","summary":"This work proposes an unsupervised pipeline that extracts the intents and the taxonomy of intents from real-world dialogues and demonstrates the generalization ability of an ELECTRA large model tuned on the SQuAD2 dataset to understand dialogues.","score":3},{"url":"https://www.semanticscholar.org/paper/cd6652fe413d57d05b44e0f3aa036c54f0eef464","title":"Towards Boosting the Open-Domain Chatbot with Human Feedback","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":43,"citationCount":3,"influentialCitationCount":1,"publicationDate":"30/08/2022","authors":"Hua Lu,Siqi Bao,H. He,Fan Wang,Hua Wu,Haifeng Wang","id":"cd6652fe413d57d05b44e0f3aa036c54f0eef464","summary":"A novel and efficient framework Diamante is proposed to boost the open-domain chatbot, where two kinds of human feedback are collected and leveraged and the implicit preference in the data collection process and the generation-evaluation joint training is introduced.","score":3},{"url":"https://www.semanticscholar.org/paper/051808bd0abd0350b6d642cf4f0cb63533b3f06d","title":"Prediction, selection, and generation: a knowledge-driven conversation system","venue":"Neural computing & applications (Print)","year":2022,"referenceCount":51,"citationCount":0,"influentialCitationCount":0,"publicationDate":"18/09/2022","authors":"Cheng Luo,Dayiheng Liu,Chanjuan Li,Li Lu,Jiancheng Lv","id":"051808bd0abd0350b6d642cf4f0cb63533b3f06d","summary":"This paper proposes a knowledge-driven conversation system that outperforms a strong baseline and achieves state-of-the-art results, and proposes the Bert2Transformer model as the dialogue generator, which can generate rich and fluent utterances based on contextual and relevant knowledge.","score":3},{"url":"https://www.semanticscholar.org/paper/52788fec0b67236d110eaa2d6ce637febb9ef4aa","title":"An Explainable Artificial Intelligence Approach for Detecting Empathy in Textual Communication","venue":"Applied Sciences","year":2022,"referenceCount":67,"citationCount":1,"influentialCitationCount":0,"publicationDate":"20/09/2022","authors":"Edwin Carlos Montiel-Vázquez,J. R. Ramírez Uresti,O. Loyola-González","id":"52788fec0b67236d110eaa2d6ce637febb9ef4aa","summary":"It is shown that an explicative pattern-based approach (PBC4cip) is, to date, the best approach for detecting empathy in texts by measuring performance in both nominal and ordinal metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/59a8057b8c2d0f72b09e46b9c4d43b4971eef930","title":"A response generator with response-aware encoder for generating specific and relevant responses","venue":"Soft Computing - A Fusion of Foundations, Methodologies and Applications","year":2022,"referenceCount":51,"citationCount":0,"influentialCitationCount":0,"publicationDate":"28/11/2022","authors":"So-Eon Kim,Hyun-Je Song,Seong-Bae Park","id":"59a8057b8c2d0f72b09e46b9c4d43b4971eef930","summary":"The proposed model is the first attempt to use a golden response directly for generating a query representation, whereas previous studies used the responses for its implicit and indirect reflection.","score":3},{"url":"https://www.semanticscholar.org/paper/89924944fe899fc26e8dfa447900ca849f47b76a","title":"DialogCC: Large-Scale Multi-Modal Dialogue Dataset","venue":"arXiv.org","year":2022,"referenceCount":46,"citationCount":2,"influentialCitationCount":0,"publicationDate":"08/12/2022","authors":"Young-Jun Lee,ByungSoo Ko,Han-Gyu Kim,Ho-Jin Choi","id":"89924944fe899fc26e8dfa447900ca849f47b76a","summary":"It is demonstrated that training a multi-modal dialogue model with the proposed DialogCC dataset can improve generalization performance and existing models trained with the dataset achieve state-of-the-art performance on image and text retrieval tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/cb4cfa57f14f8120827b34107a36b4aa20b0c9a4","title":"Open-Domain Response Generation in Low-Resource Settings using Self-Supervised Pre-Training of Warm-Started Transformers","venue":"ACM Trans. Asian Low Resour. Lang. Inf. Process.","year":2023,"referenceCount":41,"citationCount":3,"influentialCitationCount":0,"publicationDate":"05/01/2023","authors":"Tarek Naous,Zahraa Bassyouni,Bassel Mousi,Hazem M. Hajj,Wassim El Hajj,K. Shaban","id":"cb4cfa57f14f8120827b34107a36b4aa20b0c9a4","summary":"A framework for training open-domain response generation models in low-resource settings that is capable of generating fluent responses in multiple dialects with an average human-evaluated fluency score above 4 and fine-tuned on a very small labeled dataset for open- domain response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/12d13eb67b05a74d49fda150d62deb0fc4462dc2","title":"Improving Open-Domain Dialogue Evaluation with a Causal Inference Model","venue":"arXiv.org","year":2023,"referenceCount":56,"citationCount":1,"influentialCitationCount":0,"publicationDate":"31/01/2023","authors":"Cat P. Le,Luke Dai,Michael Johnston,Yang Liu,M. Walker,R. Ghanadan","id":"12d13eb67b05a74d49fda150d62deb0fc4462dc2","summary":"This work explores the creation of automated methods for predicting both expert and user ratings of open-domain dialogues and shows that the CF-LSTM achieves the best performance for predicting dialogue ratings and classiﬁcation.","score":3},{"url":"https://www.semanticscholar.org/paper/5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691","title":"PLACES: Prompting Language Models for Social Conversation Synthesis","venue":"Findings","year":2023,"referenceCount":63,"citationCount":9,"influentialCitationCount":1,"publicationDate":"07/02/2023","authors":"Maximillian Chen,A. Papangelis,Chenyang Tao,Seokhwan Kim,Andrew Rosenbaum,Yang Liu,Zhou Yu,Dilek Z. Hakkani-Tür","id":"5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691","summary":"This work uses a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting, and demonstrates that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi- party tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/36c8d3ef11c1ebe311489c27dffca56d19369c38","title":"Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue Response Generation Models by Causal Discovery","venue":"Transactions of the Association for Computational Linguistics","year":2023,"referenceCount":64,"citationCount":0,"influentialCitationCount":0,"publicationDate":"02/03/2023","authors":"Tao Feng,Lizhen Qu,Gholamreza Haffari","id":"36c8d3ef11c1ebe311489c27dffca56d19369c38","summary":"Inspired by causal discovery algorithms, a novel model-agnostic method for training and inference using a conditional independence classifier is proposed, trained by a constrained self-training method, coined ConSTrain, to overcome data sparsity.","score":3},{"url":"https://www.semanticscholar.org/paper/c12473c442f59613f5640b76acea389c1d4f518a","title":"Weakly Supervised Turn-level Engagingness Evaluator for Dialogues","venue":"Conference on Human Information Interaction and Retrieval","year":2023,"referenceCount":40,"citationCount":0,"influentialCitationCount":0,"publicationDate":"19/03/2023","authors":"Shaojie Jiang,S. Vakulenko,M. de Rijke","id":"c12473c442f59613f5640b76acea389c1d4f518a","summary":"This work pioneer an alternative approach, Weakly Supervised Engagingness Evaluator (WeSEE), which uses the remaining depth for each turn as a heuristic weak label for engagingness, thus serving as a good learning proxy for this metric.","score":3},{"url":"https://www.semanticscholar.org/paper/86dcd6268324b65960f0ac6287dabf155647c5f7","title":"Heterogeneous-Branch Collaborative Learning for Dialogue Generation","venue":"arXiv.org","year":2023,"referenceCount":58,"citationCount":0,"influentialCitationCount":0,"publicationDate":"21/03/2023","authors":"Yiwei Li,Shaoxiong Feng,Bin Sun,Kan Li","id":"86dcd6268324b65960f0ac6287dabf155647c5f7","summary":"This work considers the dialogue attributes in the training of network branches and proposes a dual group-based knowledge distillation method, consisting of positive distillation and negative distillation, to further diversify the features of different branches in a steadily and interpretable way.","score":3},{"url":"https://www.semanticscholar.org/paper/3562571fdfed2bfc7b6061c8721c9a5183240e67","title":"Emotion Prediction in Conversation Based on Relationship Extraction","venue":"IEEE International Conference on Cyborg and Bionic Systems","year":2023,"referenceCount":25,"citationCount":0,"influentialCitationCount":0,"publicationDate":"24/03/2023","authors":"Yingjian Liu,Xiaoping Wang,Lei Shanglin","id":"3562571fdfed2bfc7b6061c8721c9a5183240e67","summary":"A simple and effective framework for emotion prediction in conversation based on relationship extraction (DiaRP), consisting of two curricula: Dialogue Relationship Capture (DRC) and Next Emotion Prediction (NEP), which observe a significant performance improvement over a wide range of existing ERC models and achieve new state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/22c872c4e2761089cbb7688f258e00c4e6c7a39a","title":"When Crowd Meets Persona: Creating a Large-Scale Open-Domain Persona Dialogue Corpus","venue":"arXiv.org","year":2023,"referenceCount":33,"citationCount":0,"influentialCitationCount":0,"publicationDate":"01/04/2023","authors":"Won Ik Cho,Yoon Kyung Lee,Seoyeon Bae,Ji-Hwan Kim,S. Park,Moosung Kim,S. Hahn,N. Kim","id":"22c872c4e2761089cbb7688f258e00c4e6c7a39a","summary":"This study tackles issues when creating a large-scale open-domain persona dialogue corpus, where persona implies that the conversation is performed by several actors with a fixed persona and user-side workers from an unspecified crowd.","score":3},{"url":"https://www.semanticscholar.org/paper/616597b6c8cc3d24339d9f16bb4b195624046abe","title":"Is ChatGPT Equipped with Emotional Dialogue Capabilities?","venue":"arXiv.org","year":2023,"referenceCount":47,"citationCount":6,"influentialCitationCount":0,"publicationDate":"19/04/2023","authors":"Weixiang Zhao,Yanyan Zhao,Xin Lu,Shilong Wang,Yanpeng Tong,Bing Qin","id":"616597b6c8cc3d24339d9f16bb4b195624046abe","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/34305fa411aefdc309f590d0da85fc22731dc7de","title":"Triggering Empathy out of Malicious Intent: The Role of Empathy in Social Engineering Attacks","venue":"EMPATHICH","year":2023,"referenceCount":47,"citationCount":0,"influentialCitationCount":0,"publicationDate":"23/04/2023","authors":"Verena Distler,Yasmeen Abdrabou,Felix Dietz,Florian Alt","id":"34305fa411aefdc309f590d0da85fc22731dc7de","summary":"This paper focuses on the malicious ways in which empathy can be instrumentalized in social engineering, and explores potential solutions (including the automated detection of empathy-triggering communication, or of empathetic communication on the part of a potential victim).","score":3},{"url":"https://www.semanticscholar.org/paper/5ef881b8f06bec87452032a59983c83e9e02ea86","title":"A Critical Analysis of EmpatheticDialogues as a Corpus for Empathetic Engagement","venue":"EMPATHICH","year":2023,"referenceCount":35,"citationCount":0,"influentialCitationCount":0,"publicationDate":"23/04/2023","authors":"Alok Debnath,Owen Conlan","id":"5ef881b8f06bec87452032a59983c83e9e02ea86","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/0d18915e55b7868468c4ffc80478f242e3b60ddb","title":"Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting","venue":"arXiv.org","year":2023,"referenceCount":74,"citationCount":1,"influentialCitationCount":0,"publicationDate":"24/05/2023","authors":"Akhila Yerukola,Xuhui Zhou,Maarten Sap","id":"0d18915e55b7868468c4ffc80478f242e3b60ddb","summary":"This paper proposes context-infused versions of common automatic metrics, and shows that these better reflect human preferences, and conducts a comparative evaluation of rewriting through few-shot prompting of GPT-3.5 and GPT NeoX, comparing non-contextual rewrites to contextual re Writes.","score":3},{"url":"https://www.semanticscholar.org/paper/d8728e3707fc10deae8dc0b89dc1ddd58696cee8","title":"COMET-M: Reasoning about Multiple Events in Complex Sentences","venue":"arXiv.org","year":2023,"referenceCount":45,"citationCount":0,"influentialCitationCount":0,"publicationDate":"24/05/2023","authors":"Sahithya Ravi,R. Ng,Vered Shwartz","id":"d8728e3707fc10deae8dc0b89dc1ddd58696cee8","summary":"ComET-M (Multi-Event), an event-centric commonsense model capable of generating commonsense inferences for a target event within a complex sentence, is proposed and holds promise for downstream tasks involving natural text such as coreference resolution, dialogue, and story understanding.","score":3},{"url":"https://www.semanticscholar.org/paper/ec66bec9594e9359dfee2a874cbdd8349986bfad","title":"Dior-CVAE: Diffusion Priors in Variational Dialog Generation","venue":"arXiv.org","year":2023,"referenceCount":72,"citationCount":0,"influentialCitationCount":0,"publicationDate":"24/05/2023","authors":"Tianyu Yang,Thy Thy Tran,Iryna Gurevych","id":"ec66bec9594e9359dfee2a874cbdd8349986bfad","summary":"Dior-CVAE, a hierarchical CVAE model with an informative prior produced by a diffusion model, which derives a series of layer-wise latent variables using attention mechanism and infusing them into decoder layers accordingly and proposes memory dropout in the latent infusion to alleviate posterior collapse.","score":3},{"url":"https://www.semanticscholar.org/paper/dd0c6a687c493ffdcba529282ebc6a9ef7335883","title":"Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":37,"citationCount":0,"influentialCitationCount":0,"publicationDate":"26/05/2023","authors":"Kun Zhao,Bohao Yang,Chenghua Lin,Wenge Rong,A. Villavicencio,Xiaohui Cui","id":"dd0c6a687c493ffdcba529282ebc6a9ef7335883","summary":"A novel learning-based automatic evaluation metric (CMN) is proposed, which can robustly evaluate open-domain dialogues by augmenting Conditional Variational Autoencoders with a Next Sentence Prediction (NSP) objective and employing Mutual Information to model the semantic similarity of text in the latent space.","score":3},{"url":"https://www.semanticscholar.org/paper/a5fdef6f6d45cce6f5bcfeb84bbc80f246f2a872","title":"Overview of Robust and Multilingual Automatic Evaluation Metrics for Open-Domain Dialogue Systems at DSTC 11 Track 4","venue":"arXiv.org","year":2023,"referenceCount":59,"citationCount":0,"influentialCitationCount":0,"publicationDate":"22/06/2023","authors":"Mario Rodr'iguez-Cantelar,Chen Zhang,Chengguang Tang,Ke Shi,Sarik Ghazarian,João Sedoc,L. F. D’Haro,Alexander I. Rudnicky","id":"a5fdef6f6d45cce6f5bcfeb84bbc80f246f2a872","summary":"The datasets and baselines provided to participants are described and the submission and result details of the two proposed subtasks are discussed, which promote robust and multilingual automatic evaluation metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/74fedee9d809ec766a2089a89435fa7dd1346693","title":"How About Kind of Generating Hedges using End-to-End Neural Models?","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":71,"citationCount":0,"influentialCitationCount":0,"publicationDate":"26/06/2023","authors":"Alafate Abulimiti,C. Clavel,Justine Cassell","id":"74fedee9d809ec766a2089a89435fa7dd1346693","summary":"This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier.","score":3},{"url":"https://www.semanticscholar.org/paper/94adf8b8ccfaae8c55b2dee041fa6415470f5a77","title":"DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":39,"citationCount":0,"influentialCitationCount":0,"publicationDate":"29/06/2023","authors":"Ang Lv,Jinpeng Li,Yuhan Chen,Xing Gao,Ji Zhang,Rui Yan","id":"94adf8b8ccfaae8c55b2dee041fa6415470f5a77","summary":"This paper proposes DialoGue Path Sampling (DialoGPS) method in continuous semantic space, the first many-to-many augmentation method for multi-turn dialogues, and maps a dialogue to the extended Brownian Bridge, a special Gaussian process.","score":3},{"url":"https://www.semanticscholar.org/paper/2cc805b3b4a0a6a619a44bb7dd6d91d15f117016","title":"Think Before You Speak: Learning to Generate Implicit Knowledge for Response Generation by Self-Talk","venue":"NLP4CONVAI","year":2021,"referenceCount":17,"citationCount":6,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Behnam Hedayatnia,Karthik Gopalakrishnan,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"2cc805b3b4a0a6a619a44bb7dd6d91d15f117016","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/dfcdf6c4e1d43097d911e0da304b2540f857cfb8","title":"DialogSum Challenge: Summarizing Real-Life Scenario Dialogues","venue":"International Conference on Natural Language Generation","year":2021,"referenceCount":22,"citationCount":17,"influentialCitationCount":3,"publicationDate":2021,"authors":"Yulong Chen,Yang Liu,Yue Zhang","id":"dfcdf6c4e1d43097d911e0da304b2540f857cfb8","summary":"This work carefully annotates a large-scale dialogue summarization dataset based on multiple public dialogue corpus, opening the door to all kinds of summarization models.","score":3},{"url":"https://www.semanticscholar.org/paper/e764dee4e50db01d77976e8f313fc092fc0eba85","title":"GRICE: A Grammar-based Dataset for Recovering Implicature and Conversational rEasoning","venue":"Findings","year":2021,"referenceCount":70,"citationCount":3,"influentialCitationCount":1,"publicationDate":2021,"authors":"Zilong Zheng,Shuwen Qiu,Lifeng Fan,Yixin Zhu,Song-Chun Zhu","id":"e764dee4e50db01d77976e8f313fc092fc0eba85","summary":"A grammar-based dialogue dataset, GRICE, designed to bring implicature into pragmatic reasoning in the context of conversations, and shows an overall performance boost in conversational reasoning.","score":3},{"url":"https://www.semanticscholar.org/paper/8b6a633c33f20933d1d42eb9ba5b5470be1a3fa8","title":"TCS_WITM_2022 @ DialogSum : Topic oriented Summarization using Transformer based Encoder Decoder Model","venue":"","year":2022,"referenceCount":18,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Vipul Chauhan,Prasenjeet Roy,Lipika Dey,Tushar Goel","id":"8b6a633c33f20933d1d42eb9ba5b5470be1a3fa8","summary":"This paper's approach to the DialogSum challenge, which was proposed as a shared task aimed to summarize dialogues from real-life scenarios, is presented and it is found that since conversations usually veer around a topic, using topics along with the dialoagues, helps to generate more human-like summaries.","score":3},{"url":"https://www.semanticscholar.org/paper/8089bfe8aa59151147b78d9c9968026119cd5420","title":"Dialogue-adaptive language model pre-training from quality estimation☆","venue":"Neurocomputing","year":2020,"referenceCount":53,"citationCount":0,"influentialCitationCount":0,"publicationDate":"10/09/2020","authors":"Junlong Li,Zhuosheng Zhang,Hai Zhao","id":"8089bfe8aa59151147b78d9c9968026119cd5420","summary":"Experimental results on widely used open-domain response selection and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of estimating quality evaluation factors into pre-training.","score":3},{"url":"https://www.semanticscholar.org/paper/614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac","title":"A Survey on Response Selection for Retrieval-based Dialogues","venue":"International Joint Conference on Artificial Intelligence","year":2021,"referenceCount":53,"citationCount":13,"influentialCitationCount":0,"publicationDate":"01/08/2021","authors":"Chongyang Tao,Jiazhan Feng,Rui Yan,Wei Wu,Daxin Jiang","id":"614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac","summary":"A comprehensive survey of recent advances in response selection for retrieval-based dialogues and summarizes some recent advances on the research of response selection, including incorporation with extra knowledge and exploration on more effective model learning.","score":3},{"url":"https://www.semanticscholar.org/paper/81b58944372ea10436ff7252b115e21e893d11c6","title":"Enhanced Speaker-Aware Multi-Party Multi-Turn Dialogue Comprehension","venue":"IEEE/ACM Transactions on Audio Speech and Language Processing","year":2021,"referenceCount":99,"citationCount":8,"influentialCitationCount":2,"publicationDate":"09/09/2021","authors":"Xinbei Ma,Zhuosheng Zhang,Hai Zhao","id":"81b58944372ea10436ff7252b115e21e893d11c6","summary":"The Enhanced Speaker-Aware method (ESA) helps achieve state-of-the-art performance on the Molweni dataset, as well as significant improvements on the FriendsQA dataset, and analysis shows that the method makes steady improvements on stronger backbones.","score":3},{"url":"https://www.semanticscholar.org/paper/2820c2f6147ca8dbc19181fa712b2662dd0c3ae0","title":"Guiding Topic Flows in the Generative Chatbot by Enhancing the ConceptNet with the Conversation Corpora","venue":"arXiv.org","year":2021,"referenceCount":40,"citationCount":0,"influentialCitationCount":0,"publicationDate":"12/09/2021","authors":"Pengda Si,Yao Qiu,Jinchao Zhang,Yujiu Yang","id":"2820c2f6147ca8dbc19181fa712b2662dd0c3ae0","summary":"This work proposes the method to supply more concept relations extracted from the conversational corpora and reconstruct an enhanced concept graph for the chatbot construction and presents a novel, powerful, and fast graph encoding architecture named the Edge-Transformer to replace the traditional GNN architecture.","score":3},{"url":"https://www.semanticscholar.org/paper/6f1c10534f6407ef3b090032b4dc2f9073569526","title":"Think Before You Speak: Explicitly Generating Implicit Commonsense Knowledge for Response Generation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":64,"citationCount":12,"influentialCitationCount":1,"publicationDate":"16/10/2021","authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"6f1c10534f6407ef3b090032b4dc2f9073569526","summary":"Think-Before-Speaking is presented, a generative approach to first externalize implicit commonsense knowledge (think) and use this knowledge to generate responses (speak), arguing that externalizing implicit knowledge allows more efficient learning, produces more informative responses, and enables more explainable models.","score":3},{"url":"https://www.semanticscholar.org/paper/2ae757afd718d5219cdee3a6c4cee0d226378efd","title":"Representation Learning for Conversational Data using Discourse Mutual Information Maximization","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":50,"citationCount":2,"influentialCitationCount":0,"publicationDate":"04/12/2021","authors":"Bishal Santra,Sumegh Roychowdhury,Aishik Mandal,Vasu Gurram,Atharva Naik,Manish Gupta,Pawan Goyal","id":"2ae757afd718d5219cdee3a6c4cee0d226378efd","summary":"This work proposes a structure-aware Mutual Information based loss-function DMI (Discourse Mutual Information) for training dialog-representation models, that additionally captures the inherent uncertainty in response prediction.","score":3},{"url":"https://www.semanticscholar.org/paper/3c9ba25baca64151af4e9d50c7947de28eb2a599","title":"Survey of Hallucination in Natural Language Generation","venue":"ACM Computing Surveys","year":2022,"referenceCount":250,"citationCount":285,"influentialCitationCount":24,"publicationDate":"08/02/2022","authors":"Ziwei Ji,Nayeon Lee,Rita Frieske,Tiezheng Yu,D. Su,Yan Xu,Etsuko Ishii,Yejin Bang,Wenliang Dai,Andrea Madotto,Pascale Fung","id":"3c9ba25baca64151af4e9d50c7947de28eb2a599","summary":"A broad overview of the research progress and challenges in the hallucination problem in NLG is provided, including task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation.","score":3},{"url":"https://www.semanticscholar.org/paper/d179082956ab75d08311ddc1bbb20783031d15b1","title":"Leveraging speaker-aware structure and factual knowledge for faithful dialogue summarization","venue":"Knowledge-Based Systems","year":2022,"referenceCount":75,"citationCount":2,"influentialCitationCount":0,"publicationDate":"01/03/2022","authors":"Lulu Zhao,Weiran Xu,Chunyun Zhang,Jun Guo","id":"d179082956ab75d08311ddc1bbb20783031d15b1","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/3c05f71157c713fe45704bdd130f01620b7ab771","title":"Towards Robust Online Dialogue Response Generation","venue":"arXiv.org","year":2022,"referenceCount":53,"citationCount":1,"influentialCitationCount":0,"publicationDate":"07/03/2022","authors":"Leyang Cui,Fandong Meng,Yanjun Liu,Jie Zhou,Yue Zhang","id":"3c05f71157c713fe45704bdd130f01620b7ab771","summary":"This paper proposes a hierarchical sampling-based method consisting of both utterance-level sampling and semi-utterance- level sampling, to alleviate the discrepancy between training and real-world testing, which implicitly increases the dialogue coherence.","score":3},{"url":"https://www.semanticscholar.org/paper/d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3","title":"Multiview Contextual Commonsense Inference: A New Dataset and Task","venue":"arXiv.org","year":2022,"referenceCount":25,"citationCount":1,"influentialCitationCount":0,"publicationDate":"06/10/2022","authors":"Siqi Shen,Deepanway Ghosal,Navonil Majumder,Henry Lim,Rada Mihalcea,Soujanya Poria","id":"d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3","summary":"This work creates CICEROv2, a dataset consisting of 8,351 instances from 2,379 dialogues, containing multiple human-written answers for each contextual commonsense inference question, representing a type of explanation on cause, subsequent event, motivation, and emotional reaction.","score":3},{"url":"https://www.semanticscholar.org/paper/d1feb79f63ea52839f4a784fbd7d60bb73dd98dd","title":"ComFact: A Benchmark for Linking Contextual Commonsense Knowledge","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":68,"citationCount":5,"influentialCitationCount":0,"publicationDate":"23/10/2022","authors":"Silin Gao,Jena D. Hwang,Saya Kanno,Hiromi Wakaki,Yuki Mitsufuji,Antoine Bosselut","id":"d1feb79f63ea52839f4a784fbd7d60bb73dd98dd","summary":"This work proposes the new task of commonsense fact linking, where models are given contexts and trained to identify situationally-relevant commonsense knowledge from KGs, and shows that heuristic fact linking approaches are imprecise knowledge extractors.","score":3},{"url":"https://www.semanticscholar.org/paper/c44176020bc7034f5ea788cb8de7fcdda5f6a91d","title":"Social Influence Dialogue Systems: A Scoping Survey of the Efforts Towards Influence Capabilities of Dialogue Systems","venue":"arXiv.org","year":2022,"referenceCount":93,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Kushal Chawla,Weiyan Shi,Jingwen Zhang,Gale M. Lucas,Zhou Yu,J. Gratch","id":"c44176020bc7034f5ea788cb8de7fcdda5f6a91d","summary":"This work formally deﬁne and introduces the category of social inﬂuence dialogue systems that in-situ users’ cognitive and emotional responses are changed, leading to changes in thoughts, opinions, and behaviors through natural conversations.","score":3},{"url":"https://www.semanticscholar.org/paper/a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88","title":"Social Influence Dialogue Systems: A Survey of Datasets and Models For Social Influence Tasks","venue":"Conference of the European Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":98,"citationCount":0,"influentialCitationCount":0,"publicationDate":"11/10/2022","authors":"Kushal Chawla,Weiyan Shi,Jingwen Zhang,Gale M. Lucas,Zhou Yu,J. Gratch","id":"a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88","summary":"This work formally define and introduce the category of social influence dialogue systems that influence users’ cognitive and emotional responses, leading to changes in thoughts, opinions, and behaviors through natural conversations.","score":3},{"url":"https://www.semanticscholar.org/paper/dca519be8c02a29566985e9cadc138d7d64626ce","title":"A Survey of Document Grounded Dialogue Systems (DGDS)","venue":"","year":2020,"referenceCount":145,"citationCount":0,"influentialCitationCount":0,"publicationDate":2020,"authors":"Apple Siri,MicrosoftâĂŹs,Cortana,Amazon Alexa","id":"dca519be8c02a29566985e9cadc138d7d64626ce","summary":"This paper presents a meta-modelling system that automates the very labor-intensive and therefore time-heavy and expensive and therefore expensive and expensive process of social computing and information Retrieval.","score":2},{"url":"https://www.semanticscholar.org/paper/35763b04ca7ec8d1cbdacb3be5635015d2f7ad9b","title":"A Survey of Document Grounded Dialogue Systems (DGDS)","venue":"arXiv.org","year":2020,"referenceCount":143,"citationCount":12,"influentialCitationCount":2,"publicationDate":2020,"authors":"Longxuan Ma,Weinan Zhang,Mingda Li,Ting Liu","id":"35763b04ca7ec8d1cbdacb3be5635015d2f7ad9b","summary":"The classification, architecture, datasets, models, and future development trends of the DGDS are analyzed, hoping to help researchers in this field.","score":2},{"url":"https://www.semanticscholar.org/paper/df39e25d31e76427e5a6e91246951b1049b639ab","title":"Proxy Indicators for the Quality of Open-domain Dialogues","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":31,"citationCount":1,"influentialCitationCount":0,"publicationDate":2021,"authors":"R. Nedelchev,Jens Lehmann,Ricardo Usbeck","id":"df39e25d31e76427e5a6e91246951b1049b639ab","summary":"This work investigates using a deep-learning model trained on the General Language Understanding Evaluation (GLUE) benchmark to serve as a quality indication of open-domain dialogues to reduce the need for additional training data or responses that serve as quality references.","score":2},{"url":"https://www.semanticscholar.org/paper/205a405e5d2823c9bfdf77a3452b2ac8481a1525","title":"Can Contextualizing User Embeddings Improve Sarcasm and Hate Speech Detection?","venue":"NLPCSS","year":2022,"referenceCount":60,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Kim Breitwieser","id":"205a405e5d2823c9bfdf77a3452b2ac8481a1525","summary":"It is shown that task-related topics can have a noticeable effect on model performance, especially when dealing with intended expressions like sarcasm, but less so for hate speech, which is usually labelled as such on the receiving end.","score":2},{"url":"https://www.semanticscholar.org/paper/658a912984d6a4899d1369ca674b06c7aafd45d0","title":"DIRECT: Toward Dialogue-Based Reading Comprehension Tutoring","venue":"IEEE Access","year":2023,"referenceCount":44,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Jin-Xia Huang,Yohan Lee,Oh-Woog Kwon","id":"658a912984d6a4899d1369ca674b06c7aafd45d0","summary":"A dialogue-based intelligent tutoring system (ITS) that imitates human expert tutors that asks questions, assesses student answers, provides hints, and even chats to encourage student engagement is developed.","score":2},{"url":"https://www.semanticscholar.org/paper/b0df9c1a785618c1cfa9090cbca4c6110be092fe","title":"Emotion-Aware and Human-Like Autonomous Agents","venue":"","year":2019,"referenceCount":227,"citationCount":1,"influentialCitationCount":0,"publicationDate":"20/12/2019","authors":"Nabiha Asghar","id":"b0df9c1a785618c1cfa9090cbca4c6110be092fe","summary":"This thesis addresses two challenges: replicating the human ability to correctly perceive and adopt emotions, and communicate effectively through language, and devise an active learning technique that elicits user feedback during a conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/d08463bd665589d04619f04dbde84183ffcf2e63","title":"Towards a Human-like Open-Domain Chatbot","venue":"arXiv.org","year":2020,"referenceCount":63,"citationCount":646,"influentialCitationCount":93,"publicationDate":"27/01/2020","authors":"Daniel De Freitas,Minh-Thang Luong,David R. So,Jamie Hall,Noah Fiedel,Romal Thoppilan,Zi Yang,Apoorv Kulshreshtha,Gaurav Nemade,Yifeng Lu,Quoc V. Le","id":"d08463bd665589d04619f04dbde84183ffcf2e63","summary":"Meena, a multi-turn open-domain chatbot trained end-to-end on data mined and filtered from public domain social media conversations, is presented and a human evaluation metric called Sensibleness and Specificity Average (SSA) is proposed, which captures key elements of a human-like multi- turn conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/343eef7387dbc7d0ffa463cfe1cfab237f82aa66","title":"Gunrock 2.0: A User Adaptive Social Conversational System","venue":"arXiv.org","year":2020,"referenceCount":42,"citationCount":17,"influentialCitationCount":0,"publicationDate":"17/11/2020","authors":"Kai-Hui Liang,Author Chau,Yu Li,Xueyuan Lu,Dian Yu,Mingyang Zhou,Ishan Jain,Sam Davidson,Josh Arnold,Minh Le Nguyen,Zhou Yu","id":"343eef7387dbc7d0ffa463cfe1cfab237f82aa66","summary":"Gunrock 2.0 is built on top of Gunrock with an emphasis on user adaptation and combines various neural natural language understanding modules, including named entity detection, linking, and dialog act prediction, to improve user understanding.","score":2},{"url":"https://www.semanticscholar.org/paper/77b101d2c0f3d2842edb4acdbca0c4e859cda4d5","title":"A survey on empathetic dialogue systems","venue":"Information Fusion","year":2020,"referenceCount":152,"citationCount":117,"influentialCitationCount":1,"publicationDate":"01/12/2020","authors":"Yukun Ma,Khanh Linh Nguyen,Frank Xing,E. Cambria","id":"77b101d2c0f3d2842edb4acdbca0c4e859cda4d5","summary":"This review article focuses on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge, and identifies three key features that underpin such systems: emotion-awareness, personality-awareness and knowledge-accessibility.","score":2},{"url":"https://www.semanticscholar.org/paper/fac8d660e9c0cef1da5d35aea35c572ed776e887","title":"Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":40,"citationCount":13,"influentialCitationCount":2,"publicationDate":"31/12/2020","authors":"Weiyan Shi,Yu Li,Saurav Sahay,Zhou Yu","id":"fac8d660e9c0cef1da5d35aea35c572ed776e887","summary":"This model outperforms previous state-of-the-art dialogue models on both automatic metrics and human evaluation results on a donation persuasion task, and generates more diverse, consistent and persuasive conversations according to the user feedback.","score":2},{"url":"https://www.semanticscholar.org/paper/56586eb758d7fabdbbd5ee4c5ed7e30c6d457d30","title":"Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":84,"citationCount":10,"influentialCitationCount":0,"publicationDate":"20/02/2021","authors":"Haoming Jiang,Bo Dai,Mengjiao Yang,Wei Wei,T. Zhao","id":"56586eb758d7fabdbbd5ee4c5ed7e30c6d457d30","summary":"ENIGMA only requires a handful of pre-collected experience data, and therefore does not involve human interaction with the target policy during the evaluation, making automatic evaluations feasible, and significantly outperforms existing methods in terms of correlation with human evaluation scores.","score":2},{"url":"https://www.semanticscholar.org/paper/23bb7ac9d1164b0b429e59eb012584c1c1c64e73","title":"Structural Characterization for Dialogue Disentanglement","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":62,"citationCount":11,"influentialCitationCount":2,"publicationDate":"15/10/2021","authors":"Xinbei Ma,Zhuosheng Zhang,Hai Zhao","id":"23bb7ac9d1164b0b429e59eb012584c1c1c64e73","summary":"This work specially takes structure factors into account and design a novel model for dialogue disentangling that achieves new state-of-the-art on the Ubuntu IRC benchmark dataset and contributes to dialogue-related comprehension.","score":2},{"url":"https://www.semanticscholar.org/paper/8ac5f84cd417b04dd178e963d7aa03f3be27d74b","title":"Dialogue System Augmented with Commonsense Knowledge","venue":"Vilnius University Open Series","year":2022,"referenceCount":31,"citationCount":0,"influentialCitationCount":0,"publicationDate":"13/05/2022","authors":"I. Lasy,Virginijus Marcinkevicius","id":"8ac5f84cd417b04dd178e963d7aa03f3be27d74b","summary":"This work proposes usage of structured knowledge base ConceptNet for knowledge-grounded dialogue generation and novel knowledge extraction algorithm is proposed which is then used to incorporate knowledge into existing dialogue datasets.","score":2},{"url":"https://www.semanticscholar.org/paper/82eea58ca6e16e7b2df9a6f76b796da5a7cfcbc5","title":"Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":78,"citationCount":1,"influentialCitationCount":0,"publicationDate":"31/10/2022","authors":"Nyoungwoo Lee,chaeHun Park,Ho-Jin Choi,J. Choo","id":"82eea58ca6e16e7b2df9a6f76b796da5a7cfcbc5","summary":"Experimental results on dialogue selection tasks show that the proposed method outperforms other methods of synthesizing adversarial negative responses and suggest that the method can be an effective alternative to human annotators in generating adversarial responses.","score":2},{"url":"https://www.semanticscholar.org/paper/891082eb8ec9796d9e6041a93c2dfcf1654daf76","title":"1 c-TextGen : Conditional Text Generation for Harmonious Human-Machine Interaction","venue":"","year":2019,"referenceCount":90,"citationCount":0,"influentialCitationCount":0,"publicationDate":2019,"authors":"Bin Guo,Hao Wang,Yasan Ding,Shaoyang Hao,Yueqi Sun","id":"891082eb8ec9796d9e6041a93c2dfcf1654daf76","summary":"The paper is presented at the 2016 ACM meeting in Washington, DC, where it was presented as well as at the ACM workshop in New York, USA, where the paper was presented in person for the first time.","score":2},{"url":"https://www.semanticscholar.org/paper/d4e7ae066bc9a5652dc6caf0e75e9f44f1f63f47","title":"Conditional Variational Autoencoders for Emotionally-aware Chatbot Based on Transformer","venue":"","year":2020,"referenceCount":23,"citationCount":0,"influentialCitationCount":0,"publicationDate":2020,"authors":"Yubo Xie","id":"d4e7ae066bc9a5652dc6caf0e75e9f44f1f63f47","summary":"This paper focuses on the need for the variational empathetic chatbot and proposes a model that combines the plain Transformer chatbot model and Conditional Variational Autoencoders (CVAE) to generate high-quality abstractive conversation responses following designated emotions.","score":2},{"url":"https://www.semanticscholar.org/paper/d8d67b7e943f088351ae5b4a12e35a5448d00846","title":"Challenges in the Evaluation of Conversational Search Systems","venue":"","year":2020,"referenceCount":70,"citationCount":0,"influentialCitationCount":0,"publicationDate":2020,"authors":"S. Kallumadi,U. Porwal,T. Taula","id":"d8d67b7e943f088351ae5b4a12e35a5448d00846","summary":"It is argued that the currently in-use evaluation schemes have critical limitations and simplify the conversational search tasks to a degree that makes it questionable whether the authors can trust the findings they deliver.","score":2},{"url":"https://www.semanticscholar.org/paper/ab7ea333afb81b937592078fd18544cfdb625255","title":"Seeking an Empathy-abled Conversational Agent","venue":"Romanian Conference on Human-Computer Interaction","year":2020,"referenceCount":14,"citationCount":2,"influentialCitationCount":0,"publicationDate":2020,"authors":"Andreea Grosuleac,Stefania Budulan,Traian Rebedea","id":"ab7ea333afb81b937592078fd18544cfdb625255","summary":"This paper presents an open-domain empathic chatbot, encompassing two of the biggest challenges of dialog systems: understanding emotions and offering appropriate responses, while offering a further refined dialogue persona.","score":2},{"url":"https://www.semanticscholar.org/paper/fc3c05b152e325cd87d0d6275df469c27cc9149e","title":"Challenges in the Evaluation of Conversational Search Systems","venue":"Converse@KDD","year":2020,"referenceCount":70,"citationCount":12,"influentialCitationCount":0,"publicationDate":2020,"authors":"Gustavo Penha,C. Hauff","id":"fc3c05b152e325cd87d0d6275df469c27cc9149e","summary":"It is argued that the currently in-use evaluation schemes have critical limitations and simplify the conversational search tasks to a degree that makes it questionable whether the authors can trust the findings they deliver.","score":2},{"url":"https://www.semanticscholar.org/paper/e42fd8c71b6d4acd4da0fece2e9f18cdd781e7ab","title":"Empathy-driven Arabic Conversational Chatbot","venue":"Workshop on Arabic Natural Language Processing","year":2020,"referenceCount":22,"citationCount":16,"influentialCitationCount":2,"publicationDate":2020,"authors":"Tarek Naous,Christian Hokayem,Hazem M. Hajj","id":"e42fd8c71b6d4acd4da0fece2e9f18cdd781e7ab","summary":"This work creates an Arabic conversational dataset that comprises empathetic responses and proposes a special encoder-decoder composed of a Long Short-Term Memory (LSTM) Sequence-to-Sequence (Seq2Seq) with Attention to address the limitation of data scale.","score":2},{"url":"https://www.semanticscholar.org/paper/26a15c0e1becb323f40a616003a15db48ea1581a","title":"MRF-Chat: Improving Dialogue with Markov Random Fields","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":28,"citationCount":0,"influentialCitationCount":0,"publicationDate":2021,"authors":"Ishaan Grover,Matthew Huggins,C. Breazeal,Hae Won Park","id":"26a15c0e1becb323f40a616003a15db48ea1581a","summary":"This work proposes a novel probabilistic approach using Markov Random Fields (MRF) to augment existing deep-learning methods for improved next utterance prediction and shows that this augmentation approach significantly improves the performance of existing state-of-the-art retrieval models for open-domain conversational agents.","score":2},{"url":"https://www.semanticscholar.org/paper/7dd25287048fbc8753f412f30d30509e87308071","title":"An Investigation of Suitability of Pre-Trained Language Models for Dialogue Generation – Avoiding Discrepancies","venue":"Findings","year":2021,"referenceCount":29,"citationCount":5,"influentialCitationCount":0,"publicationDate":2021,"authors":"Yan Zeng,Jian-Yun Nie","id":"7dd25287048fbc8753f412f30d30509e87308071","summary":"This study experimentally compares pre-trained language models used in response generation for open-domain dialogue and proposes two solutions to reduce discrepancies, which successfully improve the model performance.","score":2},{"url":"https://www.semanticscholar.org/paper/59583454cef87dfee40ddb4db1ae67b277a5bacb","title":"Characterizing Social Spambots by their Human Traits","venue":"Findings","year":2021,"referenceCount":54,"citationCount":4,"influentialCitationCount":0,"publicationDate":2021,"authors":"Salvatore Giorgi,Lyle Ungar,H. A. Schwartz","id":"59583454cef87dfee40ddb4db1ae67b277a5bacb","summary":"How well social bots can be identified only using the 17 variables of these human attributes is considered and ended up with a new state of the art in social spambot detection (e.g. F1 = .946).","score":2},{"url":"https://www.semanticscholar.org/paper/189d797b29bb886cd68ceaf35cee4f48fd632404","title":"Proto-Gen: An end-to-end neural generator for persona and knowledge grounded response generation","venue":"CCGPK","year":2022,"referenceCount":20,"citationCount":1,"influentialCitationCount":0,"publicationDate":2022,"authors":"Sougata Saha,Souvik Das,R. Srihari","id":"189d797b29bb886cd68ceaf35cee4f48fd632404","summary":"P Proto-Gen facilitates learning dependencies between facts, persona and the context, and outperforms existing baselines on the FoCus dataset for both the sub-tasks of persona and fact selection, and response generation.","score":2},{"url":"https://www.semanticscholar.org/paper/c4c07000129020df74b932836347d67f95b89fda","title":"Focus on FoCus: Is FoCus focused on Context, Knowledge and Persona?","venue":"CCGPK","year":2022,"referenceCount":28,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Seungyoon Lee,Jungseob Lee,Chanjun Park,Sugyeong Eo,Hyeonseok Moon,Jaehyung Seo,Jeongbae Park,Heu-Jeoung Lim","id":"c4c07000129020df74b932836347d67f95b89fda","summary":"It is presented that the FoCus model could not correctly blend the knowledge according to the input dialogue and that the dataset design is unsuitable for the multi-turn conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/b0291bee1d532e8dc082753329d2579549100479","title":"Eliciting Transferability in Multi-task Learning with Task-level Mixture-of-Experts","venue":"arXiv.org","year":2022,"referenceCount":45,"citationCount":3,"influentialCitationCount":0,"publicationDate":2022,"authors":"Qinyuan Ye,Juan Zha,Xiang Ren","id":"b0291bee1d532e8dc082753329d2579549100479","summary":"It is shown that the learned routing decisions and experts partially rediscover human categorization of NLP tasks – certain experts are strongly associated with extractive tasks, some with classiﬁcation tasks, and some with tasks requiring world knowledge.","score":2},{"url":"https://www.semanticscholar.org/paper/08f7aeca8f94bedbeb425bef1f0b3fcd9361f785","title":"SafetyKit: First Aid for Measuring Safety in Open-domain Conversational Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":131,"citationCount":25,"influentialCitationCount":2,"publicationDate":2022,"authors":"Emily Dinan,Gavin Abercrombie,A. Bergman,S. Spruit,Dirk Hovy,Y-Lan Boureau,Verena Rieser","id":"08f7aeca8f94bedbeb425bef1f0b3fcd9361f785","summary":"This position paper surveys the problem of safety for end-to-end conversational AI, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects, and empirically assess the extent to which current tools can measure these effects and current systems display them.","score":2},{"url":"https://www.semanticscholar.org/paper/25eba922c7076e1a8a0a86fd0eed2bfcdbe0bbc3","title":"AugESC: Large-scale Data Augmentation for Emotional Support Conversation with Pre-trained Language Models","venue":"arXiv.org","year":2022,"referenceCount":27,"citationCount":13,"influentialCitationCount":2,"publicationDate":2022,"authors":"Chujie Zheng,Sahand Sabour,Jiaxin Wen,Minlie Huang","id":"25eba922c7076e1a8a0a86fd0eed2bfcdbe0bbc3","summary":"This paper proposes exploiting large-scale pre-trained language models for data augmentation, and demonstrates with interactive evaluation that A UG ESC can further enhance dialog models tuned on ESConv to handle various conversation topics and to provide signiﬁcantly more effective emotional support.","score":2},{"url":"https://www.semanticscholar.org/paper/f5d6f6bffb89dfbff38afdbfa51eebd039a935e3","title":"Explicit Use of Topicality in Dialogue Response Generation","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":21,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Takumi Yoshikoshi,Hayato Atarashi,Takashi Kodama,S. Kurohashi","id":"f5d6f6bffb89dfbff38afdbfa51eebd039a935e3","summary":"Experimental results show that the proposed dialogue system can follow the topic more than the existing dialogue system that considers only the context, and generate topic-relevant responses based on the estimated topicality.","score":2},{"url":"https://www.semanticscholar.org/paper/5fa273f7db53ef98d3789b26a8f2dcf3b71fe005","title":"Empirical study on BlenderBot 2.0 Errors Analysis in terms of Model, Data and User-Centric Approach","venue":"arXiv.org","year":2022,"referenceCount":28,"citationCount":4,"influentialCitationCount":0,"publicationDate":2022,"authors":"Jungseob Lee,Midan Shim,Suhyune Son,Yujin Kim,Chanjun Park,Heuiseok Lim","id":"5fa273f7db53ef98d3789b26a8f2dcf3b71fe005","summary":"This work examined BlenderBot 2.0’s limitations and errors from three perspectives: model, data, and user, and highlights the unclear guidelines provided to workers during the crowdsourcing process and lack of a process for re-ﬁning hate speech in the collected data and verifying the accuracy of internet-based information.","score":2},{"url":"https://www.semanticscholar.org/paper/5e251503c1ce484cc50accac7b0ad695f32c1a91","title":"Primary Program Committees","venue":"","year":2022,"referenceCount":66,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Young-Jun Lee,Chae-Gyun Lim,Yunsu Choi,Ji-Hui Lm,Ho-Jin Choi","id":"5e251503c1ce484cc50accac7b0ad695f32c1a91","summary":"It is presented that the FoCus model could not correctly blend the knowledge according to the input dialogue and that the dataset design is unsuitable for the multiturn conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/9c0826ad683efd6c3a81235a28124c025f957e7b","title":"EmoDM: Empathetic Response Generation with Emotion-aware Dialogue Management","venue":"","year":2022,"referenceCount":43,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Yuhan Liu,Jun Gao,Jiachen Du,Lanjun Zhou,Ruifeng Xu","id":"9c0826ad683efd6c3a81235a28124c025f957e7b","summary":"A novel empathetic response generation model with emotion-aware dialogue management that predicts a target emotion and a user’s intent based on the results of the emotion state tracking and is used to guide the generation of responses.","score":2},{"url":"https://www.semanticscholar.org/paper/e0d3a34ea616d181eedae9e56126e86daefdd2c8","title":"Enhancing Dialogue Generation with Conversational Concept Flows","venue":"Findings","year":2023,"referenceCount":50,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Siheng Li,Wangjie Jiang,Pengda Si,Cheng Yang,Qiu Yao,Jinchao Zhang,Jie Zhou,Yujiu Yang","id":"e0d3a34ea616d181eedae9e56126e86daefdd2c8","summary":"This work extracts abundant concepts and relations from natural conversations and builds a new conversation-aware knowledge graph and designs a novel relation-aware graph encoder to capture the concept flows guided by the knowledge graph.","score":2},{"url":"https://www.semanticscholar.org/paper/5da8ef8573a1504804314f612c97bf7ab6a563df","title":"Empathy Identification Systems are not Accurately Accounting for Context","venue":"Conference of the European Chapter of the Association for Computational Linguistics","year":2023,"referenceCount":40,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Andrew Lee,Jonathan K. Kummerfeld,Lawrence An,Rada Mihalcea","id":"5da8ef8573a1504804314f612c97bf7ab6a563df","summary":"A simple model that checks if an input utterance is similar to a small set of empathetic examples is considered, which indicates that current systems rely on the surface form of the response, rather than whether it is suitable in context.","score":2},{"url":"https://www.semanticscholar.org/paper/f2d257625e8029f6f4998deb6279f97e07e2893c","title":"MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations","venue":"Annual Meeting of the Association for Computational Linguistics","year":2018,"referenceCount":34,"citationCount":460,"influentialCitationCount":134,"publicationDate":"05/10/2018","authors":"Soujanya Poria,Devamanyu Hazarika,Navonil Majumder,Gautam Naik,E. Cambria,Rada Mihalcea","id":"f2d257625e8029f6f4998deb6279f97e07e2893c","summary":"The Multimodal EmotionLines Dataset (MELD), an extension and enhancement of Emotion lines, contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends and shows the importance of contextual and multimodal information for emotion recognition in conversations.","score":2},{"url":"https://www.semanticscholar.org/paper/592d500e44f99e39f35d5d96f8787b94f51aa914","title":"Approximating Interactive Human Evaluation with Self-Play for Open-Domain Dialog Systems","venue":"Neural Information Processing Systems","year":2019,"referenceCount":44,"citationCount":70,"influentialCitationCount":7,"publicationDate":"01/06/2019","authors":"Asma Ghandeharioun,J. Shen,Natasha Jaques,Craig Ferguson,Noah J. Jones,Àgata Lapedriza,Rosalind W. Picard","id":"592d500e44f99e39f35d5d96f8787b94f51aa914","summary":"It is shown that this metric is capable of capturing the human-rated quality of a dialog model better than any automated metric known to-date, achieving a significant Pearson correlation (r>.7, p<.05).","score":2},{"url":"https://www.semanticscholar.org/paper/11ed7f038bd7efd1491f3957959e1e30bc120c38","title":"CAiRE: An Empathetic Neural Chatbot.","venue":"","year":2019,"referenceCount":30,"citationCount":16,"influentialCitationCount":2,"publicationDate":"28/07/2019","authors":"Zhaojiang Lin,Peng Xu,Genta Indra Winata,Farhad Bin Siddique,Zihan Liu,Jamin Shin,Pascale Fung","id":"11ed7f038bd7efd1491f3957959e1e30bc120c38","summary":"This system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection.","score":2},{"url":"https://www.semanticscholar.org/paper/9fc0ddd6811cf682500d12585da78385b01a1e6b","title":"CAiRE: An End-to-End Empathetic Chatbot","venue":"AAAI Conference on Artificial Intelligence","year":2019,"referenceCount":31,"citationCount":88,"influentialCitationCount":10,"publicationDate":"28/07/2019","authors":"Zhaojiang Lin,Peng Xu,Genta Indra Winata,Zihan Liu,Pascale Fung","id":"9fc0ddd6811cf682500d12585da78385b01a1e6b","summary":"This system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection.","score":2},{"url":"https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920","title":"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction","venue":"arXiv.org","year":2019,"referenceCount":182,"citationCount":5,"influentialCitationCount":0,"publicationDate":"08/09/2019","authors":"Bin Guo,Hao Wang,Yasan Ding,Shaoyang Hao,Yueqi Sun,Zhiwen Yu","id":"e324d92c005ccdec0ce04dfb9941dd99ded21920","summary":"This work aims to give a comprehensive review of the new research trends of c-TextGen, and gives a brief literature review of text generation technology, based on which it formalizes the concept model of c.TextGen.","score":2},{"url":"https://www.semanticscholar.org/paper/e4b14cc43f2bceaafd056b2c43a93f2cc81086b7","title":"Follow Alice into the Rabbit Hole: Giving Dialogue Agents Understanding of Human Level Attributes","venue":"arXiv.org","year":2019,"referenceCount":43,"citationCount":2,"influentialCitationCount":0,"publicationDate":"18/10/2019","authors":"Aaron W. Li,Veronica Jiang,Steven Y. Feng,Julia Sprague,W. Zhou,J. Hoey","id":"e4b14cc43f2bceaafd056b2c43a93f2cc81086b7","summary":"This work proposes Human Level Attributes based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters and introduces a three-component system, ALOHA, that combines character space mapping, character community detection, and language style retrieval to build a character (or personality) specific language model.","score":2},{"url":"https://www.semanticscholar.org/paper/2162c863639414f590f78bb11889dda9e418ee96","title":"ALOHA: Artificial Learning of Human Attributes for Dialogue Agents","venue":"AAAI Conference on Artificial Intelligence","year":2019,"referenceCount":44,"citationCount":18,"influentialCitationCount":4,"publicationDate":"18/10/2019","authors":"Aaron W. Li,Veronica Jiang,Steven Y. Feng,Julia Sprague,Wei Zhou,J. Hoey","id":"2162c863639414f590f78bb11889dda9e418ee96","summary":"This work proposes Human Level Attributes based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters and introduces a three-component system, ALOHA, that combines character space mapping, character community detection, and language style retrieval to build a character (or personality) specific language model.","score":2},{"url":"https://www.semanticscholar.org/paper/f83d2439ce294eebee6b8303ab717fb2c0be6386","title":"Emotional Neural Language Generation Grounded in Situational Contexts","venue":"CCNLG","year":2019,"referenceCount":37,"citationCount":11,"influentialCitationCount":1,"publicationDate":"25/11/2019","authors":"Sashank Santhanam,Samira Shaikh","id":"f83d2439ce294eebee6b8303ab717fb2c0be6386","summary":"This work develops a language modeling approach that generates affective content when the dialogue is situated in a given context and outperforms the state-of-the-art method on the perplexity metric and achieves a higher BLEU metric score.","score":2},{"url":"https://www.semanticscholar.org/paper/14ff8d13e0324982a7718c66657071fcf2e527b3","title":"Generating Emotionally Aligned Responses in Dialogues using Affect Control Theory","venue":"arXiv.org","year":2020,"referenceCount":62,"citationCount":5,"influentialCitationCount":0,"publicationDate":"07/03/2020","authors":"Nabiha Asghar,I. Kobyzev,J. Hoey,P. Poupart,Muhammad Bilal Sheikh","id":"14ff8d13e0324982a7718c66657071fcf2e527b3","summary":"This work investigates how ACT can be used to develop affect-aware neural conversational agents, which produce emotionally aligned responses to prompts and take into consideration the affective identities of the interactants.","score":2},{"url":"https://www.semanticscholar.org/paper/37383c30930391c1f67fb5817563c98f1889d3ef","title":"Variational Transformers for Diverse Response Generation","venue":"arXiv.org","year":2020,"referenceCount":32,"citationCount":44,"influentialCitationCount":1,"publicationDate":"28/03/2020","authors":"Zhaojiang Lin,Genta Indra Winata,Peng Xu,Zihan Liu,Pascale Fung","id":"37383c30930391c1f67fb5817563c98f1889d3ef","summary":"The Variational Transformer is proposed, a variational self-attentive feed-forward sequence model that combines the parallelizability and global receptive field of the Transformer with the variational nature of the CVAE by incorporating stochastic latent variables into Transformers.","score":2},{"url":"https://www.semanticscholar.org/paper/9910882e86fb264fa96c0e3e92e52b34997e8091","title":"Will I Sound like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":47,"citationCount":38,"influentialCitationCount":4,"publicationDate":"13/04/2020","authors":"Hyunwoo Kim,Byeongchang Kim,Gunhee Kim","id":"9910882e86fb264fa96c0e3e92e52b34997e8091","summary":"Inspired by social cognition and pragmatics, existing dialogue agents are endow with public self-consciousness on the fly through an imaginary listener to enforce dialogue agents to refrain from uttering contradiction and improve consistency of existing dialogue models.","score":2},{"url":"https://www.semanticscholar.org/paper/24181cb896b16d7e423b2c289ee831a10f829ecb","title":"A Wizard-of-Oz Interface and Persona-based Methodology for Collecting Health Counseling Dialog","venue":"CHI Extended Abstracts","year":2020,"referenceCount":51,"citationCount":14,"influentialCitationCount":1,"publicationDate":"25/04/2020","authors":"William R. Kearns,Neha Kaura,Myra Divina,C. Vo,Dong Si,T. Ward,Weichao Yuwen","id":"24181cb896b16d7e423b2c289ee831a10f829ecb","summary":"This work describes an interface designed to augment the ability of clinicians to efficiently engage in high-quality and empathetic health counseling dialog with their patients and presents a WOZ protocol for collecting this dialog using standardized patient actors each playing a role from a pool of caregiver personas.","score":2}]}