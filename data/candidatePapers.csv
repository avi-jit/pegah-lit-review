"id","score","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount","url"
"8f926c0c3f1557a9241b7e75609082a1f207a75e",2,"InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning","This work introduces InstructDial, an instruction tuning framework for dialogue, which consists of a repository of 48 diverse dialogue tasks in a unified text-to-text format created from 59 openly available dialogue datasets, and introduces novel meta-tasks to ensure that models adhere to instructions.","Conference on Empirical Methods in Natural Language Processing",2022,"Prakhar Gupta,Cathy Jiao,Yi-Ting Yeh,Shikib Mehri,M. Eskénazi,Jeffrey P. Bigham",10,124,0,"https://www.semanticscholar.org/paper/8f926c0c3f1557a9241b7e75609082a1f207a75e"
"b13c3e87a80f491899068524e7e860872b521a27",2,"DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization","DIONYSUS (dynamic input optimization in pre-training for dialogue summarization), a pre-trained encoder-decoder model for summarizing dialogues in any new domain outperforms existing methods on six datasets, as demonstrated by its ROUGE scores in zero-shot and few-shot settings.","ArXiv",2022,"Yu Li,Baolin Peng,Pengcheng He,Michel Galley,Zhou Yu,Jianfeng Gao",0,56,0,"https://www.semanticscholar.org/paper/b13c3e87a80f491899068524e7e860872b521a27"
"3e50d38ffc6cc01d4adeda5f35dbfdef2cc91dc6",1,"SemEval-2020 Task 4: Commonsense Validation and Explanation","This paper presents SemEval-2020 Task 4,CommonsenseValidation andExplanation (ComVE), which includes three subtasks, aiming to evaluate whether a system can distinguish anatural language statement that makes senseto humans from one that does not, and provide thereasons.","International Workshop on Semantic Evaluation",2020,"Cunxiang Wang,Shuailong Liang,Yili Jin,Yilong Wang,Xiaodan Zhu,Yue Zhang",65,69,12,"https://www.semanticscholar.org/paper/3e50d38ffc6cc01d4adeda5f35dbfdef2cc91dc6"
"70f2c1567ef94fdf4581e1290bf7667cc9a4dcfc",1,"LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning","A comprehensive dataset, named LogiQA, is built, which is sourced from expert-written questions for testing human Logical reasoning, and shows that state-of-the-art neural models perform by far worse than human ceiling.","International Joint Conference on Artificial Intelligence",2020,"Jian Liu,Leyang Cui,Hanmeng Liu,Dandan Huang,Yile Wang,Yue Zhang",57,40,17,"https://www.semanticscholar.org/paper/70f2c1567ef94fdf4581e1290bf7667cc9a4dcfc"
"d8ea988072efb115ee8c85e159c1fa4a816360b5",1,"Does BERT Solve Commonsense Task via Commonsense Knowledge?","This work proposes two attention-based methods to analyze commonsense knowledge inside BERT, and finds that attention heads successfully capture the structured commonsenseknowledge encoded in ConceptNet, which helps BERT solve commonsense tasks directly.","ArXiv",2020,"Leyang Cui,Sijie Cheng,Yu Wu,Yue Zhang",20,45,1,"https://www.semanticscholar.org/paper/d8ea988072efb115ee8c85e159c1fa4a816360b5"
"1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a",1,"Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation","A Dialogue-Adaptive Pre-training Objective (DAPO) based on some important qualities for assessing dialogues which are usually ignored by general LM pre-training objectives is designed and Experimental results show that models with DAPO surpass those with general LMPre- training objectives and other strong baselines on downstream DrNLP tasks.","ArXiv",2020,"Junlong Li,Zhuosheng Zhang,Hai Zhao,Xi Zhou,Xiang Zhou",17,47,1,"https://www.semanticscholar.org/paper/1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a"
"6e323af2a690128783a3f04df4eabcccb437dad5",1,"An Empirical Study on Deep Neural Network Models for Chinese Dialogue Generation","An empirical study for state-of-the-art DNN-based dialogue generation models in various Chinese corpora to evaluate a wide range of dialoguegeneration models that are based on the symmetrical architecture of Seq2Seq, RNNSearch, transformer, generative adversarial nets, and reinforcement learning respectively.","Symmetry",2020,"Zhe Li,M. Maimaiti,Jiabao Sheng,Zunwang Ke,Wushour Silamu,Qinyong Wang,Xiuhong Li",1,48,0,"https://www.semanticscholar.org/paper/6e323af2a690128783a3f04df4eabcccb437dad5"
"1e4704c54059fa1e5d2d0ec40d5ebaa784f290f7",1,"Generating Math Word Problems from Equations with Topic Controlling and Commonsense Enforcement","This paper presents a novel equation-to-problem text generation model, which outperforms baseline and previous models in both accuracy and richness of generated problem text.","ArXiv",2020,"Tianyang Cao,Shuang Zeng,Songge Zhao,Mairgup Mansur,Baobao Chang",0,51,0,"https://www.semanticscholar.org/paper/1e4704c54059fa1e5d2d0ec40d5ebaa784f290f7"
"0e2d653a6a2961fe9cbc2b99e5380975ed550633",1,"Generating Math Word Problems from Equations with Topic Consistency Maintaining and Commonsense Enforcement","","International Conference on Artificial Neural Networks",2021,"Tianyang Cao,Shuang Zeng,Songge Zhao,Mairgup Mansur,Baobao Chang",2,4,1,"https://www.semanticscholar.org/paper/0e2d653a6a2961fe9cbc2b99e5380975ed550633"
"dfcdf6c4e1d43097d911e0da304b2540f857cfb8",1,"DialogSum Challenge: Summarizing Real-Life Scenario Dialogues","This work carefully annotates a large-scale dialogue summarization dataset based on multiple public dialogue corpus, opening the door to all kinds of summarization models.","International Conference on Natural Language Generation",2021,"Yulong Chen,Yang Liu,Yue Zhang",14,22,2,"https://www.semanticscholar.org/paper/dfcdf6c4e1d43097d911e0da304b2540f857cfb8"
"51be27f16fcfa68fb2c91a63058ec4e43cef8eb3",1,"CTRD: A Chinese Theme-Rheme Discourse Dataset","","Natural Language Processing and Chinese Computing",2021,"Biao Fu,Yiqi Tong,Dawei Tian,Yidong Chen,X. Shi,Ming Zhu",0,14,0,"https://www.semanticscholar.org/paper/51be27f16fcfa68fb2c91a63058ec4e43cef8eb3"
"562236dbb6651370d8ab0c0a194773d032de76c8",1,"Graphs and Commonsense Knowledge improve the Dialogue Reasoning Ability","This paper is using the advantages of graph structure in reasoning, putting the context and candidate responses in the same graph, and using commonsense knowledge to explicitly show the associated features, thereby improving the dialogue system’s reasoning ability.","International Workshop on the Semantic Web",2021,"Minglei Gao,Sai Zhang,Xiaowang Zhang,Zhiyong Feng,Wenhuan Lu",0,5,0,"https://www.semanticscholar.org/paper/562236dbb6651370d8ab0c0a194773d032de76c8"
"2cc805b3b4a0a6a619a44bb7dd6d91d15f117016",1,"Think Before You Speak: Learning to Generate Implicit Knowledge for Response Generation by Self-Talk","","NLP4CONVAI",2021,"Pei Zhou,Behnam Hedayatnia,Karthik Gopalakrishnan,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür",5,17,1,"https://www.semanticscholar.org/paper/2cc805b3b4a0a6a619a44bb7dd6d91d15f117016"
"0934d7cac5a86b02fc49852334051bde540b34bd",1,"DialogSum: A Real-Life Scenario Dialogue Summarization Dataset","Experimental results show unique challenges in dialogue summarization, such as spoken terms, special discourse structures, coreferences and ellipsis, pragmatics and social common sense, which require specific representation learning technologies to better deal with.","Findings",2021,"Yulong Chen,Yang Liu,Liang Chen,Yue Zhang",56,37,18,"https://www.semanticscholar.org/paper/0934d7cac5a86b02fc49852334051bde540b34bd"
"1db86e01300e2f30fd08b46e63ea11656cb6dcf5",1,"TGEA: An Error-Annotated Dataset and Benchmark Tasks for TextGeneration from Pretrained Language Models","TGEA, an error-annotated dataset with multiple benchmark tasks for text generation from pretrained language models (PLMs), is proposed, which is the first dataset with comprehensive annotations for PLM-generated texts, which facilitates the diagnostic evaluation ofPLM-based text generation.","Annual Meeting of the Association for Computational Linguistics",2021,"Jie He,Bo Peng,Yi Liao,Qun Liu,Deyi Xiong",4,57,1,"https://www.semanticscholar.org/paper/1db86e01300e2f30fd08b46e63ea11656cb6dcf5"
"c3d4f9f721a2b1164f043d7ca2db10daaeb19e68",1,"Do It Once: An Embarrassingly Simple Joint Matching Approach to Response Selection","A joint matching (JM) approach which performs matching only once regardless of the number of options is explored, which enables a cheap but effective data augmentation method.","Findings",2021,"Linhao Zhang,Dehong Ma,Sujian Li,Houfeng Wang",1,15,0,"https://www.semanticscholar.org/paper/c3d4f9f721a2b1164f043d7ca2db10daaeb19e68"
"e764dee4e50db01d77976e8f313fc092fc0eba85",1,"GRICE: A Grammar-based Dataset for Recovering Implicature and Conversational rEasoning","A grammar-based dialogue dataset, GRICE, designed to bring implicature into pragmatic reasoning in the context of conversations, and shows an overall performance boost in conversational reasoning.","Findings",2021,"Zilong Zheng,Shuwen Qiu,Lifeng Fan,Yixin Zhu,Song-Chun Zhu",1,70,0,"https://www.semanticscholar.org/paper/e764dee4e50db01d77976e8f313fc092fc0eba85"
"011869f932f89d047ce2bd36d73a95cc04888193",1,"RICA: Evaluating Robust Inference Capabilities Based on Commonsense Axioms","A new challenge, RICA: Robust Inference using Commonsense Axioms, that evaluates robust commonsense inference despite textual perturbations and shows that PTLMs perform no better than random guessing on the zero-shot setting, are heavily impacted by statistical biases, and are not robust to perturbation attacks.","Conference on Empirical Methods in Natural Language Processing",2020,"Pei Zhou,Rahul Khanna,Bill Yuchen Lin,Daniel Ho,J. Pujara,Xiang Ren",23,55,1,"https://www.semanticscholar.org/paper/011869f932f89d047ce2bd36d73a95cc04888193"
"07b95736960731b49b6ce5aa0b29f10bd0586a6d",1,"On Commonsense Cues in BERT for Solving Commonsense Tasks","Using two different measures, it is found that BERT does use relevant knowledge for solving the task, and the presence of commonsense knowledge is positively correlated to the model accuracy.","Findings",2020,"Leyang Cui,Sijie Cheng,Yu Wu,Yue Zhang",6,55,0,"https://www.semanticscholar.org/paper/07b95736960731b49b6ce5aa0b29f10bd0586a6d"
"8f088ede342f2aaaf6de553f4eb741f1585c60c3",1,"Filling the Gap of Utterance-aware and Speaker-aware Representation for Multi-turn Dialogue","A novel model is proposed to fill the gap in retrieval-based multi-turn dialogue modeling by modeling the effective utterance-aware and speaker-aware representations entailed in a dialogue history by decouple the contextualized word representations by masking mechanisms in Transformer-based PrLM.","AAAI Conference on Artificial Intelligence",2020,"Longxiang Liu,Zhuosheng Zhang,Hai Zhao,Xi Zhou,Xiang Zhou",20,54,2,"https://www.semanticscholar.org/paper/8f088ede342f2aaaf6de553f4eb741f1585c60c3"
"ffbfce72f12aa0be619be5e49698c2657853409f",1,"Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts","ConTRoL is a new dataset for ConTextual Reasoning over Long texts, a passage-level NLI dataset with a focus on complex contextual reasoning types such as logical reasoning, derived from competitive selection and recruitment test for police recruitment with expert level quality.","AAAI Conference on Artificial Intelligence",2020,"Hanmeng Liu,Leyang Cui,Jian Liu,Yue Zhang",14,52,3,"https://www.semanticscholar.org/paper/ffbfce72f12aa0be619be5e49698c2657853409f"
"9698cff93ec15e4c92b1fccb2332673ef4074899",1,"A Graph Reasoning Network for Multi-turn Response Selection via Customized Pre-training","A graph- reasoning network (GRN) is proposed to address response selection for multi-turn conversation in retrieval-based chatbots and can dramatically outperform the strong baseline methods and can achieve performance which is close to human-level.","AAAI Conference on Artificial Intelligence",2020,"Yongkang Liu,Shi Feng,Daling Wang,Kaisong Song,Feiliang Ren,Yifei Zhang",9,33,2,"https://www.semanticscholar.org/paper/9698cff93ec15e4c92b1fccb2332673ef4074899"
"114be5db62209a0d0682279f5a054a316f56697e",1,"Dialogue Graph Modeling for Conversational Machine Reading","This work proposes a dialogue graph modeling framework by incorporating two complementary graph models, i.e., explicit discourse graph and implicit discourse graph, which respectively capture explicit and implicit interactions hidden in the rule documents.","Findings",2020,"Siru Ouyang,Zhuosheng Zhang,Hai Zhao",25,44,4,"https://www.semanticscholar.org/paper/114be5db62209a0d0682279f5a054a316f56697e"
"639eb8f1c663e18930ae2a55abe7bfd1d836ec16",1,"Multi-Turn Dialogue Reading Comprehension With Pivot Turns and Knowledge","This work proposes a pivot-oriented deep selection model (PoDS) on top of the Transformer-based language models for dialogue comprehension by extracting substantially important turns as pivot utterances and utilizing external knowledge to enhance the representation of context.","IEEE/ACM Transactions on Audio Speech and Language Processing",2021,"Zhuosheng Zhang,Junlong Li,Hai Zhao",10,61,2,"https://www.semanticscholar.org/paper/639eb8f1c663e18930ae2a55abe7bfd1d836ec16"
"281b4a7e7fb057d8266ec0610888905c46fd715d",1,"Advances in Multi-turn Dialogue Comprehension: A Survey","The characteristics and challenges of dialogue comprehension in contrast to plaintext reading comprehension are summarized and three typical patterns of dialogue modeling that are widely-used in dialogue comprehension tasks such as response selection and conversation questionanswering are discussed.","ArXiv",2021,"Zhuosheng Zhang,Hai Zhao",10,106,1,"https://www.semanticscholar.org/paper/281b4a7e7fb057d8266ec0610888905c46fd715d"
"dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2",1,"Probing Commonsense Explanation in Dialogue Response Generation","This study formalizes the problem by framing commonsense as a latent variable in the RG task and using explanations for responses as textual form of commonsense, and collecting 6k annotated explanations justifying responses from four dialogue datasets and asking humans to verify them.","Conference on Empirical Methods in Natural Language Processing",2021,"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Justin Cho,J. Pujara,Xiang Ren",8,45,1,"https://www.semanticscholar.org/paper/dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2"
"a210df43018c682f6f57120cdb66b93a42c26699",1,"Probing Causal Common Sense in Dialogue Response Generation","The study if response generation models can emulate human reasoning process and use common sense to help produce better-quality responses finds that RG models have a hard time determining the logical validity of explanations but can identify grammatical naturalness of the explanation easily.","ArXiv",2021,"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Hyundong Justin Cho,J. Pujara,Xiang Ren",2,46,0,"https://www.semanticscholar.org/paper/a210df43018c682f6f57120cdb66b93a42c26699"
"5d6800ae2f543e2e7135071bdc24a3266c70570d",1,"Problems and Countermeasures in Natural Language Processing Evaluation","The human language ability evaluation standard is referred to, a series of basic principles and implementation ideas for human-like machinelanguage ability evaluation from the three aspects of reliability, difficulty and validity are proposed.","ArXiv",2021,"Qingxiu Dong,Zhifang Sui,W. Zhan,Baobao Chang",1,65,0,"https://www.semanticscholar.org/paper/5d6800ae2f543e2e7135071bdc24a3266c70570d"
"6d3287e0de1474d3143c386c4e95cdf9437df1a3",1,"Fact-driven Logical Reasoning","It is argued that the natural logic units would be the group of backbone constituents of the sentence such as the subject-verb-object formed ""facts"", covering both global and local knowledge pieces that are necessary as the basis for logical reasoning.","ArXiv",2021,"Siru Ouyang,Zhuosheng Zhang,Hai Zhao",11,43,6,"https://www.semanticscholar.org/paper/6d3287e0de1474d3143c386c4e95cdf9437df1a3"
"a03844a1cb957feae7ded3a327cd3a445e2175ad",1,"Structural Pre-training for Dialogue Comprehension","SPIDER, Structural PretraIned DialoguE Reader, is presented, to capture dialogue exclusive features and proposes two training objectives in addition to the original LM objectives, which regularizes the model to improve the factual correctness of summarized subject-verb-object triplets.","Annual Meeting of the Association for Computational Linguistics",2021,"Zhuosheng Zhang,Hai Zhao",14,63,0,"https://www.semanticscholar.org/paper/a03844a1cb957feae7ded3a327cd3a445e2175ad"
"70a3b5c4d46490a35ee544306de06cf8c7c0e787",1,"A taxonomy, data set, and benchmark for detecting and classifying malevolent dialogue responses","This work defines the task and presents a hierarchical malevolent dialogue taxonomy and applies state‐of‐the‐art text classification methods to the MDRDC task, and reports on experiments aimed at assessing the performance of these approaches.","J. Assoc. Inf. Sci. Technol.",2021,"Yangjun Zhang,Pengjie Ren,M. de Rijke",4,108,1,"https://www.semanticscholar.org/paper/70a3b5c4d46490a35ee544306de06cf8c7c0e787"
"a8debd8f58ee690005d996d223c37239e25273ec",1,"CIDER: Commonsense Inference for Dialogue Explanation and Reasoning","This work introduces CIDER – a manually curated dataset that contains dyadic dialogue explanations in the form of implicit and explicit knowledge triplets inferred using contextual commonsense inference that can be conducive to improving several downstream applications.","SIGDIAL Conferences",2021,"Deepanway Ghosal,Pengfei Hong,Siqi Shen,Navonil Majumder,Rada Mihalcea,Soujanya Poria",7,31,1,"https://www.semanticscholar.org/paper/a8debd8f58ee690005d996d223c37239e25273ec"
"4ca39cf99747b8962fe37e7e025e284872df3425",1,"Comparing Test Sets with Item Response Theory","Quoref, HellaSwag, and MC-TACO are best suited for distinguishing among state-of-the-art models, while SNLI, MNLI, and CommitmentBank seem to be saturated for current strong models.","Annual Meeting of the Association for Computational Linguistics",2021,"Clara Vania,Phu Mon Htut,William Huang,Dhara Mungra,Richard Yuanzhe Pang,Jason Phang,Haokun Liu,Kyunghyun Cho,Sam Bowman",9,66,0,"https://www.semanticscholar.org/paper/4ca39cf99747b8962fe37e7e025e284872df3425"
"976a5d4acfd761e236fe54a92b269239084ec5f4",1,"Multi -Turn Response Selection with Temporal Gated Graph Convolutional Networks","A novel graph-based retrieval model that first construct a temporal graph based on both dialogue contexts and utterance relations, and then leverage the gated graph convolutional networks to aggregate significant information from all neighboring utterances to perform accurate reasoning over multi-turn dialogues.","IEEE International Joint Conference on Neural Network",2021,"Siyu Tao,Qiang Zhao,Linlin Wang,Liang He",0,28,0,"https://www.semanticscholar.org/paper/976a5d4acfd761e236fe54a92b269239084ec5f4"
"614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac",1,"A Survey on Response Selection for Retrieval-based Dialogues","A comprehensive survey of recent advances in response selection for retrieval-based dialogues and summarizes some recent advances on the research of response selection, including incorporation with extra knowledge and exploration on more effective model learning.","International Joint Conference on Artificial Intelligence",2021,"Chongyang Tao,Jiazhan Feng,Rui Yan,Wei Wu,Daxin Jiang",11,68,0,"https://www.semanticscholar.org/paper/614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac"
"6d62cd2611b972bc2a9b3c7d4a133fbad0984afe",1,"Validation on machine reading comprehension software without annotated labels: a property-based method","A property- based validation method for MRC software with Metamorphic Testing to supplement the reference-based validation that does not refer to the labels and hence can make much data available for testing and reveal problems that have been concealed by the traditional validation.","ESEC/SIGSOFT FSE",2021,"Songqiang Chen,Shuo Jin,Xiaoyuan Xie",9,70,1,"https://www.semanticscholar.org/paper/6d62cd2611b972bc2a9b3c7d4a133fbad0984afe"
"52c5c9575ebd990ed34867708dd42aa8ba9d561f",1,"Smoothing Dialogue States for Open Conversational Machine Reading","This work proposes an effective gating strategy by smoothing the two dialogue states in only one decoder and bridge decision making and question generation to provide a richer dialogue state reference and achieves new state-of-the-art results.","Conference on Empirical Methods in Natural Language Processing",2021,"Zhuosheng Zhang,Siru Ouyang,Hai Zhao,M. Utiyama,E. Sumita",5,45,2,"https://www.semanticscholar.org/paper/52c5c9575ebd990ed34867708dd42aa8ba9d561f"
"53baebc368d2b7943c7c4fd56a3716ccfc472d51",1,"Self- and Pseudo-self-supervised Prediction of Speaker and Key-utterance for Multi-party Dialogue Reading Comprehension","Two labour-free self- and pseudo-self-supervised prediction tasks on speaker and key-utterance to implicitly model the speaker information, and capture salient clues in a long dialogue are designed.","Conference on Empirical Methods in Natural Language Processing",2021,"Yiyang Li,Hai Zhao",7,39,2,"https://www.semanticscholar.org/paper/53baebc368d2b7943c7c4fd56a3716ccfc472d51"
"81b58944372ea10436ff7252b115e21e893d11c6",1,"Enhanced Speaker-aware Multi-party Multi-turn Dialogue Comprehension","An enhanced speaker-aware model with masking attention and heterogeneous graph networks to comprehensively capture discourse clues from both sides of speaker property and speaker- Aware relationships is proposed.","ArXiv",2021,"Xinbei Ma,Zhuosheng Zhang,Hai Zhao",6,49,1,"https://www.semanticscholar.org/paper/81b58944372ea10436ff7252b115e21e893d11c6"
"0a729d180bdf126bf0f350d7ac7ec2b2157eefa6",1,"An Evaluation Dataset and Strategy for Building Robust Multi-turn Response Selection Model","The weaknesses of the open-domain Korean Multi-turn response selection models are analyzed and an adversarial dataset is published to evaluate these weaknesses and a strategy to build a robust model in this adversarial environment is suggested.","Conference on Empirical Methods in Natural Language Processing",2021,"Kijong Han,Seojin Lee,Wooin Lee,Joosung Lee,Donghun Lee",3,26,1,"https://www.semanticscholar.org/paper/0a729d180bdf126bf0f350d7ac7ec2b2157eefa6"
"2820c2f6147ca8dbc19181fa712b2662dd0c3ae0",1,"Guiding Topic Flows in the Generative Chatbot by Enhancing the ConceptNet with the Conversation Corpora","This work proposes the method to supply more 017 concept relations extracted from the conversa- 018 tional corpora and build an enhanced concept 019 graph for the chatbot construction, which significantly outperforms strong baseline systems and achieves new SOTA results.","ArXiv",2021,"Pengda Si,Yao Qiu,Jinchao Zhang,Yujiu Yang",0,40,0,"https://www.semanticscholar.org/paper/2820c2f6147ca8dbc19181fa712b2662dd0c3ae0"
"2a3dd5cf961747adcb05f4f2834ff7a22261e861",1,"Commonsense-Focused Dialogues for Response Generation: An Empirical Study","This paper auto-extract commonsensical dialogues from existing dialogue datasets by leveraging ConceptNet, a commonsense knowledge graph, and proposes an approach for automatic evaluation of commonsense that relies on features derived from ConceptNet and pre-trained language and dialog models, and shows reasonable correlation with human evaluation of responses’ commonsense quality.","SIGDIAL Conferences",2021,"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür",19,45,1,"https://www.semanticscholar.org/paper/2a3dd5cf961747adcb05f4f2834ff7a22261e861"
"cef565dfb89aaa30191ec359c5cf7ca2cbc129fd",1,"FCM: A Fine-grained Comparison Model for Multi-turn Dialogue Reasoning","Inspired by human’s behavior in reading comprehension, a comparison mechanism is proposed to focus on the fine-grained differences in the representation of each response candidate, to tackle the problem of logical consistency in multi-turn dialogue reasoning.","Conference on Empirical Methods in Natural Language Processing",2021,"Xu Wang,Hainan Zhang,Shuai Zhao,Yanyan Zou,Hongshen Chen,Zhuoye Ding,Bo Cheng,Yanyan Lan",4,32,0,"https://www.semanticscholar.org/paper/cef565dfb89aaa30191ec359c5cf7ca2cbc129fd"
"ce74df5126faad7d74f578f1e1953278611e235d",1,"Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation","This paper presents a self-talk approach that first generates the implicit commonsense knowledge and then generates response by referencing the externalized knowledge, all using one generative model.","ArXiv",2021,"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür",6,60,0,"https://www.semanticscholar.org/paper/ce74df5126faad7d74f578f1e1953278611e235d"
"b2785368eea52d1cdfc225fc6268f84a1831c350",1,"Modeling Hierarchical Reasoning Chains by Linking Discourse Units and Key Phrases for Reading Comprehension","A holistic graph network (HGN) that deals with context at both discourse-level and word-level as the basis for logical reasoning to provide a more fine-grained relation extraction and is modeled by a hierarchical interaction mechanism to improve the interpretation of MRC systems.","International Conference on Computational Linguistics",2022,"Jialin Chen,Zhuosheng Zhang,Hai Zhao",0,39,0,"https://www.semanticscholar.org/paper/b2785368eea52d1cdfc225fc6268f84a1831c350"
"721a09d68364aef489fa593b446923df4c6df8f2",1,"RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners","RobustLR, a diagnostic benchmark that evaluates the robustness of language models to minimal logical edits in the inputs and different logical equivalence conditions, is presented and it is observed that the models trained on deductive reasoning datasets find it especially hard to learn logical negation operators.","Conference on Empirical Methods in Natural Language Processing",2022,"Soumya Sanyal,Zeyi Liao,Xiang Ren",0,27,0,"https://www.semanticscholar.org/paper/721a09d68364aef489fa593b446923df4c6df8f2"
"c8559021289f08eaf8cf2294e406bc1c6b506d19",1,"Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey","This survey is the most comprehensive and up-to-date one at present in the area of dialogue systems and dialogue-related tasks, extensively covering the popular frameworks, topics, and datasets.","Artificial Intelligence Review",2021,"Jinjie Ni,Tom Young,Vlad Pandelea,Fuzhao Xue,V. Adiga,E. Cambria",60,480,3,"https://www.semanticscholar.org/paper/c8559021289f08eaf8cf2294e406bc1c6b506d19"
"6f1c10534f6407ef3b090032b4dc2f9073569526",1,"Think Before You Speak: Explicitly Generating Implicit Commonsense Knowledge for Response Generation","Think-Before-Speaking is presented, a generative approach to first externalize implicit commonsense knowledge (think) and use this knowledge to generate responses (speak), arguing that externalizing implicit knowledge allows more efficient learning, produces more informative responses, and enables more explainable models.","Annual Meeting of the Association for Computational Linguistics",2021,"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür",6,69,0,"https://www.semanticscholar.org/paper/6f1c10534f6407ef3b090032b4dc2f9073569526"
"2ae757afd718d5219cdee3a6c4cee0d226378efd",1,"Representation Learning for Conversational Data using Discourse Mutual Information Maximization","This work proposes a structure-aware Mutual Information based loss-function DMI (Discourse Mutual Information) for training dialog-representation models, that additionally captures the inherent uncertainty in response prediction.","North American Chapter of the Association for Computational Linguistics",2021,"Bishal Santra,Sumegh Roychowdhury,Aishik Mandal,Vasu Gurram,Atharva Naik,Manish Gupta,Pawan Goyal",1,50,0,"https://www.semanticscholar.org/paper/2ae757afd718d5219cdee3a6c4cee0d226378efd"
"3c9ba25baca64151af4e9d50c7947de28eb2a599",1,"Survey of Hallucination in Natural Language Generation","A broad overview of the research progress and challenges in the hallucination problem in NLG is provided, including task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation.","ACM Computing Surveys",2022,"Ziwei Ji,Nayeon Lee,Rita Frieske,Tiezheng Yu,D. Su,Yan Xu,Etsuko Ishii,Yejin Bang,Wenliang Dai,Andrea Madotto,Pascale Fung",55,250,4,"https://www.semanticscholar.org/paper/3c9ba25baca64151af4e9d50c7947de28eb2a599"
"242eaa55cce5daad200850dd10a788a0f960cdd8",1,"Logical Reasoning for Task Oriented Dialogue Systems","This work proposes a novel method to fine-tune pretrained transformer models such as Roberta and T5, to reason over a set of facts in a given dialogue context, and shows that the transformer based model can perform logical reasoning to answer questions when the dialogue context contains all the required information.","ECNLP",2022,"Sajjad Beygi,M. Fazel-Zarandi,Alessandra Cervone,Prakash Krishnan,Siddhartha R. Jonnalagadda",1,32,0,"https://www.semanticscholar.org/paper/242eaa55cce5daad200850dd10a788a0f960cdd8"
"d179082956ab75d08311ddc1bbb20783031d15b1",1,"Leveraging speaker-aware structure and factual knowledge for faithful dialogue summarization","","Knowledge-Based Systems",2022,"Lulu Zhao,Weiran Xu,Chunyun Zhang,Jun Guo",2,75,0,"https://www.semanticscholar.org/paper/d179082956ab75d08311ddc1bbb20783031d15b1"
"3c05f71157c713fe45704bdd130f01620b7ab771",1,"Towards Robust Online Dialogue Response Generation","A hierarchical sampling-based method consist- of both utterance-level sampling and semi- 017 utterance -level sampling, to alleviate the dis- 018 crepancy, which implicitly increases the dia- 019 logue coherence.","ArXiv",2022,"Leyang Cui,Fandong Meng,Yanjun Liu,Jie Zhou,Yue Zhang",0,53,0,"https://www.semanticscholar.org/paper/3c05f71157c713fe45704bdd130f01620b7ab771"
"596b1f054db22bdd148676cdfcce26d22c2c14cb",1,"Learning-by-Narrating: Narrative Pre-Training for Zero-Shot Dialogue Comprehension","A novel narrative-guided pre-training strategy that learns by narrating the key information from a dialogue input by automatically aligning movie subtitles and their synopses is developed and Experimental results show that the model achieves superior zero-shot performance but also exhibits stronger fine-grained dialogue comprehension capabilities.","Annual Meeting of the Association for Computational Linguistics",2022,"Chao Zhao,Wenlin Yao,Dian Yu,Kaiqiang Song,Dong Yu,Jianshu Chen",1,29,0,"https://www.semanticscholar.org/paper/596b1f054db22bdd148676cdfcce26d22c2c14cb"
"0f17d7619e5de7bf41079d65783d4fb135825377",1,"CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues","This paper curates CICERO, a dataset of dyadic conversations with five types of utterance-level reasoning-based inferences, and uses it to solve relevant generative and discriminative tasks: generation of cause and subsequent event; generation of prerequisite, motivation, and listener’s emotional reaction; and selection of plausible alternatives.","Annual Meeting of the Association for Computational Linguistics",2022,"Deepanway Ghosal,Siqi Shen,Navonil Majumder,Rada Mihalcea,Soujanya Poria",6,34,1,"https://www.semanticscholar.org/paper/0f17d7619e5de7bf41079d65783d4fb135825377"
"706c6b3781374b0b11f98f204a4ddd05b26ed009",1,"Knowledge Infused Decoding","Knowledge Infused Decoding (KID)—a novel decoding algorithm for generative LMs, which dynamically infuses external knowledge into each step of the LM decoding, which maintains a local knowledge memory based on the current context, interacting with a dynamically created external knowledge trie, and continuously update the local memory as a knowledge-aware constraint to guide decoding via reinforcement learning.","International Conference on Learning Representations",2022,"Ruibo Liu,Guoqing Zheng,Shashank Gupta,Radhika Gaonkar,Chongyang Gao,Soroush Vosoughi,Milad Shokouhi,A. Awadallah",6,98,1,"https://www.semanticscholar.org/paper/706c6b3781374b0b11f98f204a4ddd05b26ed009"
"860552613fa7529553c4cd934b98be52c57e2528",1,"Autoencoding Language Model Based Ensemble Learning for Commonsense Validation and Explanation","AlMEn, an advanced pre-trained language models based method for commonsense validation and explanation based on Siamese neural net-works, can distinguish natural language statements that are against commonsense (validation subtask) and correctly identify the reason for making against Commonsense (explanation selection subtask).","ArXiv",2022,"Ngo Quang Huy,Tu Minh Phuong,Ngo Xuan Bach",0,33,0,"https://www.semanticscholar.org/paper/860552613fa7529553c4cd934b98be52c57e2528"
"4cc6d310c0d5584f50836f1bd6bdbcac1c1c86a6",1,"Towards Fine-grained Causal Reasoning and QA","A novelne-grained causal reasoning dataset is introduced and a series of novel predictive tasks in NLP, such as causality detection, event causality extraction, and Causal QA are presented, to highlight potential research opportunities.","ArXiv",2022,"Linyi Yang,Zhen Wang,Yu-Xin Wu,Jie Yang,Yue Zhang",2,61,1,"https://www.semanticscholar.org/paper/4cc6d310c0d5584f50836f1bd6bdbcac1c1c86a6"
"7ba28d214d98f2a9c2e37e6cdf294d0d4e2a1e50",1,"Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling","This work proposes Bidirectional Information Decoupling Network (BiDeN) as a universal dialogue encoder, which explicitly incorporates both the past and future contexts and can be generalized to a wide range of dialogue-related tasks.","Conference on Empirical Methods in Natural Language Processing",2022,"Yiyang Li,Hai Zhao,Zhuosheng Zhang",0,42,0,"https://www.semanticscholar.org/paper/7ba28d214d98f2a9c2e37e6cdf294d0d4e2a1e50"
"8b78827faf49277b8f9f4510a766cba30e5fbe20",1,"LogiGAN: Learning Logical Reasoning via Adversarial Pre-training","LogiGAN is presented, an unsupervised adversarial pre-training framework for improving logical reasoning abilities of language models and ablation studies on LogiGAN components reveal the relative orthogonality between linguistic and logic abilities and suggest that reﬂective thinking’s facilitation effect might also generalize to machine learning.","ArXiv",2022,"Xinyu Pi,Wanjun Zhong,Yan Gao,Nan Duan,Jian-Guang Lou",2,82,0,"https://www.semanticscholar.org/paper/8b78827faf49277b8f9f4510a766cba30e5fbe20"
"a6880a4c3f4b2f0a1d492d689569683ffbc03076",1,"DFM: Dialogue Foundation Model for Universal Large-Scale Dialogue-Oriented Task Learning","Experiments show that, compared with models of the same size, DFM can achieve state-of-the-art or competitive performance on very rich cross-domain downstream dialogue tasks, and demonstrates that DFM largely ex-tends the ability of uniﬁed dialogue pre-trained model.","",2022,"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Xinhsuai Dong,Fujiang Ge,Qingliang Miao,Jian-Guang Lou,Kai Yu",1,92,0,"https://www.semanticscholar.org/paper/a6880a4c3f4b2f0a1d492d689569683ffbc03076"
"7e582b03b597d8865f6641c511c1a63b6255b821",1,"DialogZoo: Large-Scale Dialog-Oriented Task Learning","The experimental results show that the building a uniﬁed foundation model which can solve massive diverse dialogue tasks and improves the ability of dialogue generation and knowledge distillation, but also the representation ability of models.","ArXiv",2022,"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Jian-Guang Lou,Kai Yu",3,86,0,"https://www.semanticscholar.org/paper/7e582b03b597d8865f6641c511c1a63b6255b821"
"663de4d82f1f46770aea50f5c51b424b1f4761df",1,"Discourse-Aware Graph Networks for Textual Logical Reasoning","This work proposes logic structural-constraint modeling to solve the logical reasoning QA and introduces discourse-aware graph networks (DAGNs), which demonstrate the reasonability of the logical structures built in DAGNs and the effectiveness of the learned logic features.","ArXiv",2022,"Yinya Huang,Lemao Liu,Kun Xu,Meng Fang,Liang Lin,Xi Liang",0,117,0,"https://www.semanticscholar.org/paper/663de4d82f1f46770aea50f5c51b424b1f4761df"
"7d3895652d37242f0f2214b6963b09c04273b923",1,"Semantic-based Pre-training for Dialogue Understanding","A semantic-based pre-training framework that extends the standard pre- training framework by three tasks for learning 1) core semantic units, 2) semantic relations and 3) the overall semantic representation according to AMR graphs is proposed.","International Conference on Computational Linguistics",2022,"Xuefeng Bai,Linfeng Song,Yue Zhang",2,72,0,"https://www.semanticscholar.org/paper/7d3895652d37242f0f2214b6963b09c04273b923"
"4d991660c5e34dec1a3f26ffcc28d4a3f3d5263e",1,"ET5: A Novel End-to-end Framework for Conversational Machine Reading Comprehension","A novel end-to-end framework for conversational machine reading comprehension based on shared parameter mechanism, called entailment reasoning T5 (ET5), is proposed, which achieves new state-of-the-art results on the ShARC leaderboard with the BLEU-4 score of 55.2.","International Conference on Computational Linguistics",2022,"Xiao Zhang,Heyan Huang,Zewen Chi,Xian-Ling Mao",1,24,0,"https://www.semanticscholar.org/paper/4d991660c5e34dec1a3f26ffcc28d4a3f3d5263e"
"d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3",1,"Multiview Contextual Commonsense Inference: A New Dataset and Task","This work creates CICEROv2, a dataset consisting of 8,351 instances from 2,379 dialogues, containing multiple human-written answers for each contextual commonsense inference question, representing a type of explanation on cause, subsequent event, motivation, and emotional reaction.","ArXiv",2022,"Siqi Shen,Deepanway Ghosal,Navonil Majumder,Henry Lim,Rada Mihalcea,Soujanya Poria",1,25,0,"https://www.semanticscholar.org/paper/d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3"
"f74a7c4a2d0a0fe41a77357ce11a519f5b059dee",1,"Towards End-to-End Open Conversational Machine Reading","This work model OR-CMR as a unified text-to-text task in a fully end-toend style and shows the effectiveness of the proposed end- to-end framework on both sub-tasks by a large margin, achieving new state-of-theart results.","ArXiv",2022,"Sizhe Zhou,Siru Ouyang,Zhuosheng Zhang,Hai Zhao Department of Computer Science,Engineering,S. University,Key Laboratory of Shanghai Education Commission for In Interaction,Cognitive Engineering,Moe Intelligence,AI Institute",0,28,0,"https://www.semanticscholar.org/paper/f74a7c4a2d0a0fe41a77357ce11a519f5b059dee"
"fa71d25c07d6d3c890ef4b7547d5a4d117d0b96d",1,"Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches and Future Directions","This survey provides a comprehensive investigation on existing work for abstractive dialogue summarization from scenarios, approaches to evaluations and presents a taxonomy of existing techniques in three directions, namely, injecting dialogue features, designing auxiliary training tasks and using additional data.","ArXiv",2022,"Qi Jia,Siyu Ren,Yizhu Liu,Kenny Q. Zhu",0,159,0,"https://www.semanticscholar.org/paper/fa71d25c07d6d3c890ef4b7547d5a4d117d0b96d"
"70f1419c0778350abb75ff884691b9933e408888",1,"Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers","ReasonFormer, a uniﬁed reasoning framework for mirroring the modular and compositional reasoning process of humans in complex decision-making, demonstrates substantial performance boosts and shows the modularity of reasoning modules as different tasks activate distinct reasoning skills at different reasoning depths.","ArXiv",2022,"Wanjun Zhong,Tingting Ma,Jia-hai Wang,Jian Yin,T. Zhao,Chin-Yew Lin,Nan Duan",0,42,0,"https://www.semanticscholar.org/paper/70f1419c0778350abb75ff884691b9933e408888"
"2b22a3acb3ba1581d320b70b02343d4a0f356e3e",1,"MetaLogic: Logical Reasoning Explanations with Fine-Grained Structure","The experimental results show that generating reasoning graphs remains a challenging task for current models, even with the help of giant pre-trained language models on the proposed comprehensive logical reasoning explanation form.","Conference on Empirical Methods in Natural Language Processing",2022,"Yinya Huang,Hongming Zhang,Ruixin Hong,Xiaodan Liang,Changshui Zhang,Dong Yu",0,35,0,"https://www.semanticscholar.org/paper/2b22a3acb3ba1581d320b70b02343d4a0f356e3e"
"d1feb79f63ea52839f4a784fbd7d60bb73dd98dd",1,"ComFact: A Benchmark for Linking Contextual Commonsense Knowledge","This work proposes the new task of commonsense fact linking, where models are given contexts and trained to identify situationally-relevant commonsense knowledge from KGs, and shows that heuristic fact linking approaches are imprecise knowledge extractors.","Conference on Empirical Methods in Natural Language Processing",2022,"Silin Gao,Jena D. Hwang,Saya Kanno,Hiromi Wakaki,Yuki Mitsufuji,Antoine Bosselut",2,67,0,"https://www.semanticscholar.org/paper/d1feb79f63ea52839f4a784fbd7d60bb73dd98dd"
"36b1bb9d1149586ae4e9a1867a179760051028e9",1,"DialogConv: A Lightweight Fully Convolutional Network for Multi-view Response Selection","This paper proposes a novel lightweight fully convolutional architecture, called DialogConv, for response selection, exclusively built on top of convolution to extract matching features of context and response.","Conference on Empirical Methods in Natural Language Processing",2022,"Yongkang Liu,Shi Feng,W. Gao,Daling Wang,Yifei Zhang",0,45,0,"https://www.semanticscholar.org/paper/36b1bb9d1149586ae4e9a1867a179760051028e9"
"f7b2ff0dc7022d67a15ff5df594058587091fc6f",1,"Improving conversational search with query reformulation using selective contextual history","","Data and Information Management",2022,"Haya Al-Thani,T. Elsayed,B. Jansen",0,30,0,"https://www.semanticscholar.org/paper/f7b2ff0dc7022d67a15ff5df594058587091fc6f"
"54a3f23363bf28c11f98a135ace5167dd5f0d51e",1,"Channel-aware Decoupling Network for Multi-turn Dialogue Comprehension","This work proposes compositional learning for holistic interaction across the utterances beyond the sequential contextualization from PrLMs, in order to capture the utterance-aware and speaker-aware representations entailed in a dialog history.","IEEE Transactions on Neural Networks and Learning Systems",2022,"Zhuosheng Zhang,Hai Zhao,Longxiang Liu",0,78,0,"https://www.semanticscholar.org/paper/54a3f23363bf28c11f98a135ace5167dd5f0d51e"
"ddbbf78334ef65d412520236e5d9067c82ef8984",1,"Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality","Surprisingly, it is found that simply prompting GPT3 to “think” about CG generates 30% more quality responses, showing promising benefits to integrating CG into the RG process.","Conference on Empirical Methods in Natural Language Processing",2022,"Pei Zhou,Hyundong Justin Cho,Pegah Jandaghi,Dong-Ho Lee,Bill Yuchen Lin,J. Pujara,Xiang Ren",1,37,0,"https://www.semanticscholar.org/paper/ddbbf78334ef65d412520236e5d9067c82ef8984"
"ed4e9a69594aee3c39a02b2f4fe1a614bc156da5",1,"IRRGN: An Implicit Relational Reasoning Graph Network for Multi-turn Response Selection","The Utterance Relational Reasoner (URR) and the Option Dual Comparator (ODC) are proposed, which aims to implicitly extract dependencies between utterances, as well as utterances and options, and make reasoning with relational graph convolutional networks.","Conference on Empirical Methods in Natural Language Processing",2022,"Jing-Hui Deng,Hengwei Dai,Xuewei Guo,Yuanchen Ju,Wei Peng",0,45,0,"https://www.semanticscholar.org/paper/ed4e9a69594aee3c39a02b2f4fe1a614bc156da5"
"52fe39b8d4d59f42ef22bc375d169c891748f819",1,"HiBERT: Detecting the illogical patterns with hierarchical BERT for multi-turn dialogue reasoning","","Neurocomputing",2022,"Xu Wang,Hainan Zhang,Shuai Zhao,Hongshen Chen,Bo Cheng,Zhuoye Ding,Sulong Xu,Weipeng P. Yan,Yanyan Lan",0,26,0,"https://www.semanticscholar.org/paper/52fe39b8d4d59f42ef22bc375d169c891748f819"
"493a6e7aef4ead8fafa8913ce404a870d862c08b",1,"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","This work surveys the motivation for enhancing DSs with knowledge, used datasets, and methods for knowledge search, knowledge encoding, and knowledge incorporation, and proposes how to improve existing systems based on theories from linguistics and cognitive science.","ArXiv",2022,"Sagi Shaier,L. Hunter,Katharina Kann",0,159,0,"https://www.semanticscholar.org/paper/493a6e7aef4ead8fafa8913ce404a870d862c08b"
"105cbcf6806a868d1d933305e210715e807eac30",1,"Bridging The Gap: Entailment Fused-T5 for Open-retrieval Conversational Machine Reading Comprehension","A novel one-stage end-to-end framework, called Entailment Fused-T5 (EFT), is proposed to bridge the information gap between decision-making and generation in a global understanding manner and achieves new state-of-the-art performance on the OR-ShARC benchmark.","ArXiv",2022,"Xiao Zhang,Heyan Huang,Zewen Chi,Xian-Ling Mao",0,19,0,"https://www.semanticscholar.org/paper/105cbcf6806a868d1d933305e210715e807eac30"
"bc9d103493d93a9ad8e6b60af4d9a900e4470146",1,"CausalDialogue: Modeling Utterance-level Causality in Conversations","This research examines user utterances as causes and generated responses as effects and proposes a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models.","ArXiv",2022,"Yi-Lin Tuan,Alon Albalak,Wenda Xu,Michael Stephen Saxon,Connor Pryor,L. Getoor,William Yang Wang",0,50,0,"https://www.semanticscholar.org/paper/bc9d103493d93a9ad8e6b60af4d9a900e4470146"
"0c003db762ad6edcdbabf178ae4e6776eb08a56e",1,"STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension","A novel type of dialogue summarization task - STRUctured DiaLoguE Summarization (STRUDEL) - that can help pre-trained language models to better understand dialogues and improve their performance on important dialogue comprehension tasks is proposed.","Conference on Empirical Methods in Natural Language Processing",2022,"Borui Wang,Chengcheng Feng,Arjun Nair,Madelyn Mao,Jai Desai,Asli Celikyilmaz,Haoran Li,Yashar Mehdad,Dragomir R. Radev",0,31,0,"https://www.semanticscholar.org/paper/0c003db762ad6edcdbabf178ae4e6776eb08a56e"
"8089bfe8aa59151147b78d9c9968026119cd5420",1,"Dialogue-adaptive language model pre-training from quality estimation☆","Experimental results on widely used open-domain response selection and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of estimating quality evaluation factors into pre-training.","Neurocomputing",2020,"Junlong Li,Zhuosheng Zhang,Hai Zhao",0,53,0,"https://www.semanticscholar.org/paper/8089bfe8aa59151147b78d9c9968026119cd5420"
"8866789034c3021b80dfb4c0b2c21989aa97a8d5",1,"SAPBERT: Speaker-Aware Pretrained BERT for Emotion Recognition in Conversation","A new pre-trained model is proposed, SAPBERT, that learns to identify speakers in a conversation to capture the speaker-dependent contexts and address the ERC task.","Algorithms",2022,"Seunguook Lim,Jihie Kim",0,12,0,"https://www.semanticscholar.org/paper/8866789034c3021b80dfb4c0b2c21989aa97a8d5"
"7f3fb456319181ee092b4e335302fb953523aaba",1,"Towards Emotion-Aware Agents For Negotiation Dialogues","This work explores the prediction of two important subjective goals in a negotiation – outcome satisfaction and partner perception and studies three degrees of emotion dimensions – emoticons, lexical, and contextual by leveraging affective lexicons and a state-of-the-art deep learning architecture.","Affective Computing and Intelligent Interaction",2021,"Kushal Chawla,Rene Clever,Jaysa Ramirez,Gale M. Lucas,J. Gratch",4,40,2,"https://www.semanticscholar.org/paper/7f3fb456319181ee092b4e335302fb953523aaba"
"ec64e324ce1210fe5245dfd0fb5a92058732e5b9",1,"Benchmarking Generalization via In-Context Instructions on 1, 600+ Language Tasks","This work introduces N ATURAL -I NSTRUCTIONS v 2, a collection of 1,600+ diverse language tasks and their expert written instructions that covers 70+ distinct task types, such as tagging, in-ﬁlling, and rewriting.","ArXiv",2022,"Yizhong Wang,Swaroop Mishra,Pegah Alipoormolabashi,Yeganeh Kordi,Amirreza Mirzaei,Anjana Arunkumar,Arjun Ashok,Arut Selvan Dhanasekaran,Atharva Naik,David Stap,Eshaan Pathak,Giannis Karamanolakis,Haizhi Gary Lai,I. Purohit,Ishani Mondal,Jacob Anderson,Kirby Kuznia,Krima Doshi,Maitreya Patel,Kuntal Kumar Pal,M. Moradshahi,Mihir Parmar,Mirali Purohit,Neeraj Varshney,Phani Rohitha Kaza,Pulkit Verma,Ravsehaj Singh Puri,Rushang Karia,Shailaja Keyur Sampat,Savan Doshi,S. Mishra,Sujan Reddy,Sumanta Patro,Tanay Dixit,Xudong Shen,Chitta Baral,Yejin Choi,Hannaneh Hajishirzi,Noah A. Smith,Daniel Khashabi",35,61,9,"https://www.semanticscholar.org/paper/ec64e324ce1210fe5245dfd0fb5a92058732e5b9"
"06d7cb8c8816360feb33c3367073e0ef66d7d0b0",1,"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks","Tk-Instruct is built, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples) that outperforms existing instruction-following models such as InstructGPT by over 9% on the authors' benchmark despite being an order of magnitude smaller.","Conference on Empirical Methods in Natural Language Processing",2022,"Yizhong Wang,Swaroop Mishra,Pegah Alipoormolabashi,Yeganeh Kordi,Amirreza Mirzaei,Anjana Arunkumar,Arjun Ashok,Arut Selvan Dhanasekaran,Atharva Naik,David Stap,Eshaan Pathak,Giannis Karamanolakis,Haizhi Gary Lai,I. Purohit,Ishani Mondal,Jacob Anderson,Kirby Kuznia,Krima Doshi,Maitreya Patel,Kuntal Kumar Pal,M. Moradshahi,Mihir Parmar,Mirali Purohit,Neeraj Varshney,Phani Rohitha Kaza,Pulkit Verma,Ravsehaj Singh Puri,Rushang Karia,Shailaja Keyur Sampat,Savan Doshi,S. Mishra,Sujan Reddy,Sumanta Patro,Tanay Dixit,Xudong Shen,Chitta Baral,Yejin Choi,Noah A. Smith,Hanna Hajishirzi,Daniel Khashabi",12,52,3,"https://www.semanticscholar.org/paper/06d7cb8c8816360feb33c3367073e0ef66d7d0b0"
"304c860cd33f6630fc2fb0d14b6f3ca62b0fa7dc",1,"Opponent Modeling in Negotiation Dialogues by Related Data Adaptation","This work proposes a ranker for identifying these priorities from negotiation dialogues and devise ways to adapt related data sources for this task to provide more explicit supervision for incorporating the opponent’s preferences and offers, as a proxy to relying on granular utterance-level annotations.","NAACL-HLT",2022,"Kushal Chawla,Gale M. Lucas,Jonathan May,J. Gratch",3,40,1,"https://www.semanticscholar.org/paper/304c860cd33f6630fc2fb0d14b6f3ca62b0fa7dc"
"c44176020bc7034f5ea788cb8de7fcdda5f6a91d",1,"Social Influence Dialogue Systems: A Scoping Survey of the Efforts Towards Influence Capabilities of Dialogue Systems","This work formally deﬁne and introduces the category of social inﬂuence dialogue systems that in-situ users’ cognitive and emotional responses are changed, leading to changes in thoughts, opinions, and behaviors through natural conversations.","ArXiv",2022,"Kushal Chawla,Weiyan Shi,Jingwen Zhang,Gale M. Lucas,Zhou Yu,J. Gratch",0,93,0,"https://www.semanticscholar.org/paper/c44176020bc7034f5ea788cb8de7fcdda5f6a91d"
"a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88",1,"Social Influence Dialogue Systems: A Survey of Datasets and Models For Social Influence Tasks","This work formally deﬁne and introduces the category of social inﬂuence dialogue systems that in-situ users’ cognitive and emotional responses are changed, leading to changes in thoughts, opinions, and behaviors through natural conversations.","",2022,"Kushal Chawla,Weiyan Shi,Jingwen Zhang,Gale M. Lucas,Zhou Yu,J. Gratch",0,98,0,"https://www.semanticscholar.org/paper/a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88"
"e89ed6bb1864558e3889f5f2fb8931643c633479",1,"Human-level play in the game of Diplomacy by combining language models with strategic reasoning","Cicero, the first AI agent to achieve human-level performance in Diplomacy, a strategy game involving both cooperation and competition that emphasizes natural language negotiation and tactical coordination between seven players, is introduced.","Science",2022,"A. Bakhtin,Noam Brown,Emily Dinan,Gabriele Farina,Colin Flaherty,Daniel Fried,Andrew Goff,Jonathan Gray,Hengyuan Hu,Athul Paul Jacob,Mojtaba Komeili,Karthik Konath,Minae Kwon,Adam Lerer,Mike Lewis,Alexander H. Miller,S. Mitts,Adithya Renduchintala,Stephen Roller,Dirk Rowe,Weiyan Shi,Joe Spisak,Alexander Wei,David J. Wu,Hugh Zhang,Markus Zijlstra",16,60,1,"https://www.semanticscholar.org/paper/e89ed6bb1864558e3889f5f2fb8931643c633479"
"b4e8ec7547d736a5a006af18d95491f96b294bdc",1,"Werewolf Among Us: A Multimodal Dataset for Modeling Persuasion Behaviors in Social Deduction Games","This paper introduces the first multimodal dataset for modeling persuasion behaviors and explores the generalization ability of language models for persuasion modeling and the role of persuasion strategies in predicting social deduction game outcomes.","ArXiv",2022,"Bolin Lai,Hongxin Zhang,Miao Liu,Aryan Pariani,Fiona Ryan,Wenqi Jia,Shirley Anugrah Hayati,James M. Rehg,Diyi Yang",0,32,0,"https://www.semanticscholar.org/paper/b4e8ec7547d736a5a006af18d95491f96b294bdc"
"0974035826cd6d4be9c604a8679621c8621aff5f",1,"Let's Negotiate! A Survey of Negotiation Dialogue Systems","This work aims to provide the community with a systematic overview of negotiation dialogue systems, covering benchmarks, evaluations, and methodologies, and to inspire future research.","ArXiv",2022,"Haolan Zhan,Yufei Wang,Tao Feng,Yuncheng Hua,Suraj Sharma,Zhuang Li,Lizhen Qu,Gholamreza Haffari",0,57,0,"https://www.semanticscholar.org/paper/0974035826cd6d4be9c604a8679621c8621aff5f"