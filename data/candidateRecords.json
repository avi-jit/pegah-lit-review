{"papers":[{"url":"https://www.semanticscholar.org/paper/5252ed78cc59700c905a13dafafeaf713d2e5af8","title":"On the Underspecification of Situations in Open-domain Conversational Datasets","venue":"NLP4CONVAI","year":2023,"referenceCount":70,"citationCount":1,"influentialCitationCount":0,"publicationDate":2023,"authors":"Naoki Otani,J. Araki,Hyeongsik Kim,E. Hovy","id":"5252ed78cc59700c905a13dafafeaf713d2e5af8","summary":"An analysis of response generation using three datasets shows that explicitly provided situational information can improve the coherence and specificity of generated responses, but further experiments reveal that generation systems can be misled by irrelevant information.","score":7},{"url":"https://www.semanticscholar.org/paper/1658674b715e66ef3a8cf24369a1d1691580f4a9","title":"CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":97,"citationCount":0,"influentialCitationCount":0,"publicationDate":"29/11/2023","authors":"Taha İbrahim Aksu,Devamanyu Hazarika,Shikib Mehri,Seokhwan Kim,Dilek Hakkani-Tur,Yang Liu,Mahdi Namazifar","id":"1658674b715e66ef3a8cf24369a1d1691580f4a9","summary":"This work proposes a novel framework, CESAR, that unifies a large number of dialog tasks in the same format and allows programmatic induction of complex instructions without any manual effort and demonstrates the scalability of CESAR in providing rich instructions.","score":7},{"url":"https://www.semanticscholar.org/paper/493a6e7aef4ead8fafa8913ce404a870d862c08b","title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems","venue":"arXiv.org","year":2022,"referenceCount":163,"citationCount":1,"influentialCitationCount":0,"publicationDate":"19/12/2022","authors":"Sagi Shaier,L. Hunter,Katharina Kann","id":"493a6e7aef4ead8fafa8913ce404a870d862c08b","summary":"The first survey of knowledge-enhanced DSs is presented, defining three categories of systems - internal, external, and hybrid - based on the knowledge they use and proposing how to improve existing systems based on theories from linguistics and cognitive science.","score":6},{"url":"https://www.semanticscholar.org/paper/17a8b5e6fef1f69979d57021a8f30a5159e152c7","title":"Commonsense Reasoning for Conversational AI: A Survey of the State of the Art","venue":"arXiv.org","year":2023,"referenceCount":91,"citationCount":6,"influentialCitationCount":0,"publicationDate":"15/02/2023","authors":"Christopher Richardson,Larry Heck","id":"17a8b5e6fef1f69979d57021a8f30a5159e152c7","summary":"A survey of recent conversational AI research focused on commonsense reasoning, including preliminary observations of the limited commonsense capabilities of two state-of-the-art open dialogue models, BlenderBot3 and LaMDA, and its negative effect on natural interactions.","score":6},{"url":"https://www.semanticscholar.org/paper/8f926c0c3f1557a9241b7e75609082a1f207a75e","title":"InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":128,"citationCount":35,"influentialCitationCount":3,"publicationDate":"25/05/2022","authors":"Prakhar Gupta,Cathy Jiao,Yi-Ting Yeh,Shikib Mehri,M. Eskénazi,Jeffrey P. Bigham","id":"8f926c0c3f1557a9241b7e75609082a1f207a75e","summary":"This work introduces InstructDial, an instruction tuning framework for dialogue, which consists of a repository of 48 diverse dialogue tasks in a unified text-to-text format created from 59 openly available dialogue datasets, and introduces novel meta-tasks to ensure that models adhere to instructions.","score":6},{"url":"https://www.semanticscholar.org/paper/c8559021289f08eaf8cf2294e406bc1c6b506d19","title":"Recent advances in deep learning based dialogue systems: a systematic survey","venue":"Artificial Intelligence Review","year":2021,"referenceCount":480,"citationCount":151,"influentialCitationCount":6,"publicationDate":"10/05/2021","authors":"Jinjie Ni,Tom Young,Vlad Pandelea,Fuzhao Xue,V. Adiga,E. Cambria","id":"c8559021289f08eaf8cf2294e406bc1c6b506d19","summary":"This survey is the most comprehensive and up-to-date one at present for deep learning based dialogue systems, extensively covering the popular techniques.","score":5},{"url":"https://www.semanticscholar.org/paper/a6880a4c3f4b2f0a1d492d689569683ffbc03076","title":"DFM: Dialogue Foundation Model for Universal Large-Scale Dialogue-Oriented Task Learning","venue":"","year":2022,"referenceCount":100,"citationCount":2,"influentialCitationCount":1,"publicationDate":"25/05/2022","authors":"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Xinhsuai Dong,Fujiang Ge,Qingliang Miao,Jian-Guang Lou,Kai Yu","id":"a6880a4c3f4b2f0a1d492d689569683ffbc03076","summary":"Experiments show that, compared with models of the same size, DFM can achieve state-of-the-art or competitive performance on very rich cross-domain downstream dialogue tasks, demonstrating that DFM largely extends the ability of unified dialogue pre-trained model.","score":5},{"url":"https://www.semanticscholar.org/paper/9b3ff4c05be2ee57021099ab07fadfb77440be45","title":"IMAD: IMage-Augmented multi-modal Dialogue","venue":"arXiv.org","year":2023,"referenceCount":71,"citationCount":3,"influentialCitationCount":0,"publicationDate":"17/05/2023","authors":"Viktor Moskvoretskii,Anton Frolov,Denis Kuznetsov","id":"9b3ff4c05be2ee57021099ab07fadfb77440be45","summary":"This work proposes a two-stage approach to automatically construct a multi-modal dialogue dataset that can serve as a validated dataset for this task and proposes a baseline model trained on this dataset, which outperforms modeltrained on the same data without images and BlenderBot.","score":5},{"url":"https://www.semanticscholar.org/paper/84886c484a0b04029fa8352a19297fd712b2afdc","title":"UniPCM: Universal Pre-trained Conversation Model with Task-aware Automatic Prompt","venue":"arXiv.org","year":2023,"referenceCount":130,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/09/2023","authors":"Yucheng Cai,Wentao Ma,Yuchuan Wu,Shuzheng Si,Yuan Shao,Zhijian Ou,Yongbin Li","id":"84886c484a0b04029fa8352a19297fd712b2afdc","summary":"Using the high-quality prompts generated, the corpus of the pre-trained conversation model is scaled to 122 datasets from 15 dialog-related tasks, resulting in Universal Pre-trained Conversation Model (UniPCM), a powerful foundation model for various conversational tasks and different dialog systems.","score":5},{"url":"https://www.semanticscholar.org/paper/0a888711461571ae87838999c3272fd24b8e784f","title":"Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":82,"citationCount":2,"influentialCitationCount":0,"publicationDate":"16/10/2023","authors":"Weixiao Zhou,Gengyao Li,Xianfu Cheng,Xinnian Liang,Junnan Zhu,Feifei Zhai,Zhoujun Li","id":"0a888711461571ae87838999c3272fd24b8e784f","summary":"A new pre-trained model specifically designed for multi-scenario multi-domain dialogue summarization is proposed that significantly outperforms previous state-of-the-art models in full fine-tuning, zero-shot, and few-shot settings.","score":5},{"url":"https://www.semanticscholar.org/paper/5d0419f282aa8ad7c98c1f28876323645a7407d6","title":"Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":38,"citationCount":9,"influentialCitationCount":0,"publicationDate":2022,"authors":"Ling-Yu Zhu,Zhengkun Zhang,Jun Wang,Hongbin Wang,Haiying Wu,Zhenglu Yang","id":"5d0419f282aa8ad7c98c1f28876323645a7407d6","summary":"A Static-Dynamic model for Multi-Party Empathetic Dialogue Generation,SDMPED, is introduced as a baseline by exploring the static sensibility and dynamic emotion for the multi-party empathetic dialogue learning, the aspects that help SDMPED achieve the state-of-the-art performance.","score":4},{"url":"https://www.semanticscholar.org/paper/9997901cac96451686b817961c1408ac4123102c","title":"HappyBot: Generating Empathetic Dialogue Responses by Improving User Experience Look-ahead","venue":"arXiv.org","year":2019,"referenceCount":32,"citationCount":42,"influentialCitationCount":0,"publicationDate":"20/06/2019","authors":"Jamin Shin,Peng Xu,Andrea Madotto,Pascale Fung","id":"9997901cac96451686b817961c1408ac4123102c","summary":"A Sentiment Predictor is trained to estimate the user sentiment look-ahead towards the generated system responses, which is then used as the reward function for generating more empathetic responses.","score":4},{"url":"https://www.semanticscholar.org/paper/91aca4acc06348c67df00180191d02297c563d9f","title":"Empathetic Dialogue Generation with Pre-trained RoBERTa-GPT2 and External Knowledge","venue":"International Workshop on Spoken Dialogue Systems Technology","year":2021,"referenceCount":50,"citationCount":9,"influentialCitationCount":3,"publicationDate":"07/09/2021","authors":"Ye Liu,Wolfgang Maier,W. Minker,Stefan Ultes","id":"91aca4acc06348c67df00180191d02297c563d9f","summary":"To enable the empathetic ability of RoBERTa-GPT2 model, this work proposes a commonsense knowledge and emotional concepts extractor, in which the commonsensible andotional concepts of dialogue context are extracted for the GPT-2 decoder.","score":4},{"url":"https://www.semanticscholar.org/paper/5b0855b9b9361839844ae86277e8189a957d9d23","title":"MVP: Multi-task Supervised Pre-training for Natural Language Generation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":200,"citationCount":17,"influentialCitationCount":1,"publicationDate":"24/06/2022","authors":"Tianyi Tang,Junyi Li,Wayne Xin Zhao,Ji-rong Wen","id":"5b0855b9b9361839844ae86277e8189a957d9d23","summary":"This work proposes Multi-task superVised Pre-training (MVP) for natural language generation, which achieves state-of-the-art performance on $13$ out of $17$ datasets, outperforming BART by $9.3\\%$ and Flan-T5 by $5.8\\%$.","score":4},{"url":"https://www.semanticscholar.org/paper/f78fe02f681a0a9a6867b007bd39e3884de64a91","title":"SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":72,"citationCount":73,"influentialCitationCount":10,"publicationDate":"20/12/2022","authors":"Hyunwoo Kim,Jack Hessel,Liwei Jiang,Peter West,Ximing Lu,Youngjae Yu,Pei Zhou,Ronan Le Bras,Malihe Alikhani,Gunhee Kim,Maarten Sap,Yejin Choi","id":"f78fe02f681a0a9a6867b007bd39e3884de64a91","summary":"This work presents SODA: the first publicly available, million-scale high-quality social dialogue dataset, and trains COSMO: a generalizable conversation model that is significantly more natural and consistent on unseen datasets than best-performing conversation models.","score":4},{"url":"https://www.semanticscholar.org/paper/a96762ae0ac80206f33657d2941beae41c09b16b","title":"MERCY: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems","venue":"SIGDIAL Conferences","year":2023,"referenceCount":64,"citationCount":1,"influentialCitationCount":0,"publicationDate":2023,"authors":"Sarik Ghazarian,Behnam Hedayatnia,Di Jin,Sijia Liu,Violet Peng,Yang Liu,Dilek Z. Hakkani-Tür","id":"a96762ae0ac80206f33657d2941beae41c09b16b","summary":"A novel RS model called MERCY is proposed that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them and is investigated on constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time.","score":4},{"url":"https://www.semanticscholar.org/paper/062466fb189fd3d4ab2f56a05937a8ae6df7bd06","title":"A Comprehensive Assessment of Dialog Evaluation Metrics","venue":"EANCS","year":2021,"referenceCount":68,"citationCount":76,"influentialCitationCount":16,"publicationDate":"07/06/2021","authors":"Yi-Ting Yeh,M. Eskénazi,Shikib Mehri","id":"062466fb189fd3d4ab2f56a05937a8ae6df7bd06","summary":"This comprehensive assessment provides a comprehensive assessment of recently proposed dialog evaluation metrics on a number of datasets and suggests how to best assess evaluation metrics and indicates promising directions for future work.","score":4},{"url":"https://www.semanticscholar.org/paper/5cf42d26583d2b083262451e9005e6ed273badca","title":"Automatic Evaluation and Moderation of Open-domain Dialogue Systems","venue":"arXiv.org","year":2021,"referenceCount":56,"citationCount":26,"influentialCitationCount":0,"publicationDate":"03/11/2021","authors":"Chen Zhang,João Sedoc,L. F. D’Haro,Rafael E. Banchs,Alexander I. Rudnicky","id":"5cf42d26583d2b083262451e9005e6ed273badca","summary":"This paper describes the datasets and baselines provided to participants, as well as submission evaluation results for each of the two proposed subtasks, and describes the automatic evaluation mechanisms that show high correlations with human judgements across multiple dialogue evaluation aspects.","score":4},{"url":"https://www.semanticscholar.org/paper/0ba23c847d2ca087887b60ea92ce56c71f0425b2","title":"MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":48,"citationCount":14,"influentialCitationCount":2,"publicationDate":"14/12/2021","authors":"Chen Zhang,L. F. D’Haro,Thomas Friedrichs,Haizhou Li","id":"0ba23c847d2ca087887b60ea92ce56c71f0425b2","summary":"The proposed MDD-Eval framework first train a teacher evaluator with human-annotated data to acquire a rating skill to tell good dialogue responses from bad ones in a particular domain and then, adopt a self-training strategy to train a new evaluators with teacher-annotation multi-domain data, that helps the newevaluator to generalize across multiple domains.","score":4},{"url":"https://www.semanticscholar.org/paper/f1217313b3dd1d4dc5afc09edfcbccae9b5647fe","title":"Grounding in social media: An approach to building a chit-chat dialogue model","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":24,"citationCount":4,"influentialCitationCount":0,"publicationDate":"12/06/2022","authors":"Ritvik Choudhary,Daisuke Kawahara","id":"f1217313b3dd1d4dc5afc09edfcbccae9b5647fe","summary":"This method aims to improve the raw conversation ability of the system by mimicking the human response behavior through casual interactions found on social media, and queries a large set of filtered comment data from Reddit to act as additional context for the seq2seq generator.","score":4},{"url":"https://www.semanticscholar.org/paper/27a51fa45ab9512b43d697a017a52ec3b4f7fd32","title":"SelF-Eval: Self-supervised Fine-grained Dialogue Evaluation","venue":"International Conference on Computational Linguistics","year":2022,"referenceCount":49,"citationCount":3,"influentialCitationCount":0,"publicationDate":"17/08/2022","authors":"Longxuan Ma,Ziyu Zhuang,Weinan Zhang,Mingda Li,Ting Liu","id":"27a51fa45ab9512b43d697a017a52ec3b4f7fd32","summary":"A novel automatic data construction method that can automatically assign fine-grained scores for arbitrarily dialogue data and train SelF-Eval with a multi-level contrastive learning schema which helps to distinguish different score levels.","score":4},{"url":"https://www.semanticscholar.org/paper/a6f171598db5a21ece1ac38010c48df19b2b23ca","title":"FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":59,"citationCount":8,"influentialCitationCount":2,"publicationDate":"25/10/2022","authors":"Chen Zhang,L. F. D’Haro,Qiquan Zhang,Thomas Friedrichs,Haizhou Li","id":"a6f171598db5a21ece1ac38010c48df19b2b23ca","summary":"A multi-dimensional dialogue-level metric, which consists of three sub-metrics with each targeting a specific dimension, which is trained with novel self-supervised objectives and exhibit strong correlations with human judgment for their respective dimensions.","score":4},{"url":"https://www.semanticscholar.org/paper/e8059434aa997cf486e6ae83cfbf355d4829a95c","title":"PoE: A Panel of Experts for Generalized Automatic Dialogue Assessment","venue":"IEEE/ACM Transactions on Audio Speech and Language Processing","year":2022,"referenceCount":89,"citationCount":2,"influentialCitationCount":0,"publicationDate":"18/12/2022","authors":"Chen Zhang,L. F. D’Haro,Qiquan Zhang,Thomas Friedrichs,Haizhou Li","id":"e8059434aa997cf486e6ae83cfbf355d4829a95c","summary":"A Panel of Experts (PoE) network is proposed, a multitask network that consists of a shared transformer encoder and a collection of lightweight adapters that exhibits better zero-shot generalization than existing state-of-the-art ADEMs and the ability to easily adapt to new domains with few-shot transfer learning.","score":4},{"url":"https://www.semanticscholar.org/paper/b0cdedc2d44f3bf44b7dd4dd20deb75f96d5666a","title":"RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":52,"citationCount":3,"influentialCitationCount":0,"publicationDate":"15/09/2023","authors":"Zhengliang Shi,Weiwei Sun,Shuo Zhang,Zhen Zhang,Pengjie Ren,Z. Ren","id":"b0cdedc2d44f3bf44b7dd4dd20deb75f96d5666a","summary":"This work proposes the Reference-Assisted Dialogue Evaluation (RADE) approach under the multi-task learning framework, which leverages the pre-created utterance as reference other than the gold response to relief the one-to-many problem.","score":4},{"url":"https://www.semanticscholar.org/paper/59707fbd3308257628470d94e56c8165bf4e1cff","title":"FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":59,"citationCount":9,"influentialCitationCount":2,"publicationDate":"12/05/2022","authors":"Alon Albalak,Yi-Lin Tuan,Pegah Jandaghi,Connor Pryor,Luke Yoffe,Deepak Ramachandran,L. Getoor,J. Pujara,William Yang Wang","id":"59707fbd3308257628470d94e56c8165bf4e1cff","summary":"Conversational task transfer is explored by introducing FETA: a benchmark for FEw-sample TAsk transfer in open-domain dialogue and can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning.","score":4},{"url":"https://www.semanticscholar.org/paper/7e582b03b597d8865f6641c511c1a63b6255b821","title":"DialogZoo: Large-Scale Dialog-Oriented Task Learning","venue":"arXiv.org","year":2022,"referenceCount":86,"citationCount":5,"influentialCitationCount":0,"publicationDate":2022,"authors":"Zhi Chen,Jijia Bao,Lu Chen,Yuncong Liu,Da Ma,B. Chen,Mengyue Wu,Su Zhu,Jian-Guang Lou,Kai Yu","id":"7e582b03b597d8865f6641c511c1a63b6255b821","summary":"The experimental results show that the building a uniﬁed foundation model which can solve massive diverse dialogue tasks and improves the ability of dialogue generation and knowledge distillation, but also the representation ability of models.","score":4},{"url":"https://www.semanticscholar.org/paper/7576ac724204ad9f11970044fe2d12657340476f","title":"On the Compositional Generalization in Versatile Open-domain Dialogue","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":77,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Tingchen Fu,Xueliang Zhao,Lemao Liu,Rui Yan","id":"7576ac724204ad9f11970044fe2d12657340476f","summary":"This work develops a sparsely activated modular network that outperforms state-of-the-art supervised approaches on 4 datasets with only 10% training data thanks to the modular architecture and multi-task learning.","score":4},{"url":"https://www.semanticscholar.org/paper/1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a","title":"Task-specific Objectives of Pre-trained Language Models for Dialogue Adaptation","venue":"arXiv.org","year":2020,"referenceCount":47,"citationCount":23,"influentialCitationCount":1,"publicationDate":"10/09/2020","authors":"Junlong Li,Zhuosheng Zhang,Hai Zhao,Xi Zhou,Xiang Zhou","id":"1cad933afc55f1a562e27ebd4f65c5d0f5a6c26a","summary":"A Dialogue-Adaptive Pre-training Objective (DAPO) based on some important qualities for assessing dialogues which are usually ignored by general LM pre-training objectives is designed and Experimental results show that models with DAPO surpass those with general LMPre- training objectives and other strong baselines on downstream DrNLP tasks.","score":4},{"url":"https://www.semanticscholar.org/paper/281b4a7e7fb057d8266ec0610888905c46fd715d","title":"Advances in Multi-turn Dialogue Comprehension: A Survey","venue":"arXiv.org","year":2021,"referenceCount":118,"citationCount":13,"influentialCitationCount":0,"publicationDate":"04/03/2021","authors":"Zhuosheng Zhang,Hai Zhao","id":"281b4a7e7fb057d8266ec0610888905c46fd715d","summary":"The characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension are summarized and categorize dialogue-related pre-training techniques which are employed to enhance PrLMs in dialogue scenarios.","score":4},{"url":"https://www.semanticscholar.org/paper/dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2","title":"Probing Commonsense Explanation in Dialogue Response Generation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2021,"referenceCount":46,"citationCount":13,"influentialCitationCount":1,"publicationDate":"19/04/2021","authors":"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Justin Cho,J. Pujara,Xiang Ren","id":"dffedd7dcacb2fab0af708b9a6a6de8424fe2fc2","summary":"This study formalizes the problem by framing commonsense as a latent variable in the RG task and using explanations for responses as textual form of commonsense, and collecting 6k annotated explanations justifying responses from four dialogue datasets and asking humans to verify them.","score":4},{"url":"https://www.semanticscholar.org/paper/2a3dd5cf961747adcb05f4f2834ff7a22261e861","title":"Commonsense-Focused Dialogues for Response Generation: An Empirical Study","venue":"SIGDIAL Conferences","year":2021,"referenceCount":46,"citationCount":38,"influentialCitationCount":4,"publicationDate":"14/09/2021","authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"2a3dd5cf961747adcb05f4f2834ff7a22261e861","summary":"This paper auto-extract commonsensical dialogues from existing dialogue datasets by leveraging ConceptNet, a commonsense knowledge graph, and proposes an approach for automatic evaluation of commonsense that relies on features derived from ConceptNet and pre-trained language and dialog models, and shows reasonable correlation with human evaluation of responses’ commonsense quality.","score":4},{"url":"https://www.semanticscholar.org/paper/0f17d7619e5de7bf41079d65783d4fb135825377","title":"CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":34,"citationCount":28,"influentialCitationCount":3,"publicationDate":"25/03/2022","authors":"Deepanway Ghosal,Siqi Shen,Navonil Majumder,Rada Mihalcea,Soujanya Poria","id":"0f17d7619e5de7bf41079d65783d4fb135825377","summary":"This paper curates CICERO, a dataset of dyadic conversations with five types of utterance-level reasoning-based inferences, and uses it to solve relevant generative and discriminative tasks: generation of cause and subsequent event; generation of prerequisite, motivation, and listener’s emotional reaction; and selection of plausible alternatives.","score":4},{"url":"https://www.semanticscholar.org/paper/71289eaffcd5cccc04038bbce84ffe0060f2c6d2","title":"Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches, and Future Directions","venue":"ACM Computing Surveys","year":2022,"referenceCount":222,"citationCount":3,"influentialCitationCount":0,"publicationDate":"18/10/2022","authors":"Qi Jia,Siyu Ren,Yizhu Liu,Kenny Q. Zhu","id":"71289eaffcd5cccc04038bbce84ffe0060f2c6d2","summary":"This survey provides a comprehensive investigation of existing work for abstractive dialogue summarization from scenarios, approaches to evaluations, and presents a taxonomy of existing techniques in three directions, namely, injecting dialogue features, designing auxiliary training tasks, and using additional data.","score":4},{"url":"https://www.semanticscholar.org/paper/2b4ae4ecdc312f2f0b73427d009af67f2142df41","title":"CausalDialogue: Modeling Utterance-level Causality in Conversations","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":57,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/12/2022","authors":"Yi-Lin Tuan,Alon Albalak,Wenda Xu,Michael Stephen Saxon,Connor Pryor,L. Getoor,William Yang Wang","id":"2b4ae4ecdc312f2f0b73427d009af67f2142df41","summary":"This research examines user utterances as causes and generated responses as effects and proposes a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models.","score":4},{"url":"https://www.semanticscholar.org/paper/d0adbba45ad8d8d1e748c9f3901569a09d8bc227","title":"Diplomat: A Dialogue Dataset for Situated Pragmatic Reasoning","venue":"arXiv.org","year":2023,"referenceCount":93,"citationCount":1,"influentialCitationCount":0,"publicationDate":"15/06/2023","authors":"Hengli Li,Songchun Zhu,Zilong Zheng","id":"d0adbba45ad8d8d1e748c9f3901569a09d8bc227","summary":"This paper introduces a novel challenge, DiPlomat, aiming at benchmarking machines' capabilities on pragmatic reasoning and situated conversational understanding, and proposes two tasks, Pragmatic Identification and Reasoning and Conversational Question Answering.","score":4},{"url":"https://www.semanticscholar.org/paper/67f23dec7687692660d8aa1315b9dbc8e1aacf22","title":"Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems","venue":"arXiv.org","year":2023,"referenceCount":197,"citationCount":0,"influentialCitationCount":0,"publicationDate":"14/07/2023","authors":"Shivani Kumar,S. Bhatia,Milan Aggarwal,Tanmoy Chakraborty","id":"67f23dec7687692660d8aa1315b9dbc8e1aacf22","summary":"This study provides a comprehensive overview of the primary characteristics of a dialogue agent, the supporting tasks, their corresponding open-domain datasets, and the methods used to benchmark these datasets.","score":4},{"url":"https://www.semanticscholar.org/paper/13244fdc42a091f87bc08eaaac2bcfd5883e8d0c","title":"Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":42,"citationCount":6,"influentialCitationCount":0,"publicationDate":"13/10/2023","authors":"Hyungjoo Chae,Yongho Song,Kai Tzu-iunn Ong,Taeyoon Kwon,Minjin Kim,Youngjae Yu,Dongha Lee,Dongyeop Kang,Jinyoung Yeo","id":"13244fdc42a091f87bc08eaaac2bcfd5883e8d0c","summary":"A knowledge distillation framework that leverages LLMs as unreliable teachers and selectively distills consistent and helpful rationales via alignment filters is proposed and DOCTOR, a DialOgue Chain-of-ThOught Reasoner, is presented that provides reliable CoT rationales for response generation.","score":4},{"url":"https://www.semanticscholar.org/paper/f6b171486d0240fff7a464c0fbbfd84483945924","title":"DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":65,"citationCount":2,"influentialCitationCount":0,"publicationDate":"20/12/2022","authors":"Yu Li,Baolin Peng,Pengcheng He,Michel Galley,Zhou Yu,Jianfeng Gao","id":"f6b171486d0240fff7a464c0fbbfd84483945924","summary":"DIONYSUS (dynamic input optimization in pre-training for dialogue summarization), a pre-trained encoder-decoder model for summarizing dialogues in any new domain that outperforms existing methods on six datasets.","score":4},{"url":"https://www.semanticscholar.org/paper/b0b96270a9bbeb9f3ec040e70114d565fbcaaed9","title":"Learning from Dialogue after Deployment: Feed Yourself, Chatbot!","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":51,"citationCount":162,"influentialCitationCount":10,"publicationDate":"16/01/2019","authors":"Braden Hancock,Antoine Bordes,Pierre-Emmanuel Mazaré,J. Weston","id":"b0b96270a9bbeb9f3ec040e70114d565fbcaaed9","summary":"On the PersonaChat chit-chat dataset with over 131k training examples, it is found that learning from dialogue with a self-feeding chatbot significantly improves performance, regardless of the amount of traditional supervision.","score":3},{"url":"https://www.semanticscholar.org/paper/6b94dcac41325a03956402ff7862fa80936f9ddb","title":"A Survey of Natural Language Generation Techniques with a Focus on Dialogue Systems - Past, Present and Future Directions","venue":"arXiv.org","year":2019,"referenceCount":139,"citationCount":45,"influentialCitationCount":0,"publicationDate":"02/06/2019","authors":"Sashank Santhanam,Samira Shaikh","id":"6b94dcac41325a03956402ff7862fa80936f9ddb","summary":"This work provides a comprehensive review towards building open domain dialogue systems, an important application of natural language generation, and finds that, predominantly, the approaches for building dialogue systems use seq2seq or language models architecture.","score":3},{"url":"https://www.semanticscholar.org/paper/c131665638feb8c11f936989ffc6187317593b41","title":"Emotionally-Aware Chatbots: A Survey","venue":"arXiv.org","year":2019,"referenceCount":69,"citationCount":30,"influentialCitationCount":0,"publicationDate":"24/06/2019","authors":"Endang Wahyu Pamungkas","id":"c131665638feb8c11f936989ffc6187317593b41","summary":"In this paper, a systematic review of approaches in building an emotionally-aware chatbot (EAC) is provided and it is found that in the early development, EAC exploits a simple rule-based approach while now most of EAC use neural- based approach.","score":3},{"url":"https://www.semanticscholar.org/paper/b47698a589e35ec3f7a0bb30618939fbed0b9e41","title":"MoEL: Mixture of Empathetic Listeners","venue":"Conference on Empirical Methods in Natural Language Processing","year":2019,"referenceCount":64,"citationCount":150,"influentialCitationCount":43,"publicationDate":"21/08/2019","authors":"Zhaojiang Lin,Andrea Madotto,Jamin Shin,Peng Xu,Pascale Fung","id":"b47698a589e35ec3f7a0bb30618939fbed0b9e41","summary":"A novel end-to-end approach for modeling empathy in dialogue systems: Mixture of Empathetic Listeners (MoEL), which outperforms multitask training baseline in terms of empathy, relevance, and fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/2899ad28e9616779a251a78917e313b5e5011d78","title":"MIME: MIMicking Emotions for Empathetic Response Generation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":46,"citationCount":121,"influentialCitationCount":25,"publicationDate":"04/10/2020","authors":"Navonil Majumder,Pengfei Hong,Shanshan Peng,Jiankun Lu,Deepanway Ghosal,Alexander Gelbukh,Rada Mihalcea,Soujanya Poria","id":"2899ad28e9616779a251a78917e313b5e5011d78","summary":"This work argues that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content, and introduces stochasticity into the emotion mixture that yields emotionally more varied emPathetic responses than the previous work.","score":3},{"url":"https://www.semanticscholar.org/paper/eb1ac44bbc0fe07c5f31f459c7199211239e90b8","title":"Open-domain Dialogue Generation: What We Can Do, Cannot Do, And Should Do Next","venue":"NLP4CONVAI","year":2022,"referenceCount":143,"citationCount":17,"influentialCitationCount":0,"publicationDate":2022,"authors":"Katharina Kann,Abteen Ebrahimi,Joewie J. Koh,Shiran Dudy,A. Roncone","id":"eb1ac44bbc0fe07c5f31f459c7199211239e90b8","summary":"The goal of this work is to provide an overview of recent advances in the field of open-domain dialogue, to summarize issues related to ethics, bias, and fairness that the field has identified as well as typical errors of dialogue systems and to outline important future challenges.","score":3},{"url":"https://www.semanticscholar.org/paper/d1dbb7796af10b1b18d2f12f57f8d83cde443bee","title":"Protocole d’annotation multi-label pour une nouvelle approche à la génération de réponse socio-émotionnelle orientée-tâche","venue":"JEPTALNRECITAL","year":2023,"referenceCount":38,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Lorraine Vanel,Alya Yacoubi,C. Clavel","id":"d1dbb7796af10b1b18d2f12f57f8d83cde443bee","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/b73e0932cb1114741ac70ab824795ae95962c657","title":"Parallel Corpora Alignment Framework for Multilingual and Robust Automatic Dialogue Evaluation","venue":"DSTC","year":2023,"referenceCount":50,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Xinglin Wang,Jiayi Shi,Peiwen Yuan,Kan Li","id":"b73e0932cb1114741ac70ab824795ae95962c657","summary":"This paper proposes Parallel Corpora Alignment Framework (PCAF), which improves the consistency and robustness of model evaluation on parallel corpora, and improves model’s generalization ability across multiple data domains.","score":3},{"url":"https://www.semanticscholar.org/paper/0a470fbfebb5515e8af8d9a09f603df4dfce40a0","title":"A Systematic Evaluation of Large Language Models for Natural","venue":"China National Conference on Chinese Computational Linguistics","year":2023,"referenceCount":58,"citationCount":2,"influentialCitationCount":0,"publicationDate":2023,"authors":"Xuanfan Ni,Li Piji","id":"0a470fbfebb5515e8af8d9a09f603df4dfce40a0","summary":"This paper conducts a comprehensive evaluation of well-known and high-performing LLMs, namely ChatGPT, ChatGLM, T5-based models, LLaMA-basedmodels, and Pythia- based models in the context of NLG tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/11cf51c9ddf2a3debb26ca64165e6baa40143284","title":"Generating Video Game Scripts with Style","venue":"NLP4CONVAI","year":2023,"referenceCount":34,"citationCount":2,"influentialCitationCount":0,"publicationDate":2023,"authors":"Gaetan Lopez Latouche,Laurence Marcotte,Ben Swanson","id":"11cf51c9ddf2a3debb26ca64165e6baa40143284","summary":"This work proposes the Style Adaptive Semiparametric Scriptwriter (SASS) which leverages an adaptive weighted style memory to generate dialog lines in accordance with a character’s speaking patterns.","score":3},{"url":"https://www.semanticscholar.org/paper/c5a0a92fb521c7d1399cf26e63a6ffb806d1b291","title":"A Textual Dataset for Situated Proactive Response Selection","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":69,"citationCount":1,"influentialCitationCount":0,"publicationDate":2023,"authors":"Naoki Otani,J. Araki,Hyeongsik Kim,E. Hovy","id":"c5a0a92fb521c7d1399cf26e63a6ffb806d1b291","summary":"This work presents a manually-curated dataset of 1.7k English conversation examples that include situational background information plus for each conversation a set of responses, only some of which are acceptable in the situation, and introduces a task of proactive response selection based on situational information.","score":3},{"url":"https://www.semanticscholar.org/paper/21b4777948797377deedf4a9f1f58ad13f6b8b5d","title":"Overview of the Tenth Dialog System Technology Challenge: DSTC10","venue":"IEEE/ACM Transactions on Audio Speech and Language Processing","year":2024,"referenceCount":95,"citationCount":1,"influentialCitationCount":0,"publicationDate":2024,"authors":"Koichiro Yoshino,Yun-Nung (Vivian) Chen,Paul A. Crook,Satwik Kottur,Jinchao Li,Behnam Hedayatnia,Seungwhan Moon,Zhengcong Fei,Zekang Li,Jinchao Zhang,Yang Feng,Jie Zhou,Seokhwan Kim,Yang Liu,Di Jin,A. Papangelis,Karthik Gopalakrishnan,Dilek Z. Hakkani-Tür,B. Damavandi,A. Geramifard,Chiori Hori,Ankit Shah,Chen Zhang,Haizhou Li,João Sedoc,L. F. D’Haro,Rafael E. Banchs,Alexander I. Rudnicky","id":"21b4777948797377deedf4a9f1f58ad13f6b8b5d","summary":"The task definition, provided datasets, baselines, and evaluation setup for each track, and the results of the submitted systems are summarized to highlight the general trends of the state-of-the-art technologies for the tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/89e65078d37d076627818d9dba2c8ca9bf8f66bc","title":"Challenges in Building Intelligent Open-domain Dialog Systems","venue":"ACM Trans. Inf. Syst.","year":2019,"referenceCount":206,"citationCount":237,"influentialCitationCount":11,"publicationDate":"13/05/2019","authors":"Minlie Huang,Xiaoyan Zhu,Jianfeng Gao","id":"89e65078d37d076627818d9dba2c8ca9bf8f66bc","summary":"This article reviews the recent work on neural approaches that are devoted to addressing three challenges in developing intelligent open-domain dialog systems: semantics, consistency, and interactiveness.","score":3},{"url":"https://www.semanticscholar.org/paper/270b3f5201e835dd9a6a80fb8d749dba08dc88dd","title":"Generating Empathetic Responses by Looking Ahead the User’s Sentiment","venue":"IEEE International Conference on Acoustics, Speech, and Signal Processing","year":2019,"referenceCount":29,"citationCount":36,"influentialCitationCount":3,"publicationDate":"20/06/2019","authors":"Jamin Shin,Peng Xu,Andrea Madotto,Pascale Fung","id":"270b3f5201e835dd9a6a80fb8d749dba08dc88dd","summary":"This paper implements and evaluates three different possible implementations of sentiment look-ahead and empirically shows that the proposed approach can generate significantly more empathetic, relevant, and fluent responses than other competitive baselines such as multitask learning.","score":3},{"url":"https://www.semanticscholar.org/paper/6ebfbc954b9975d2f2651f380b9bdf46ae963178","title":"PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":38,"citationCount":231,"influentialCitationCount":30,"publicationDate":"17/10/2019","authors":"Siqi Bao,H. He,Fan Wang,Hua Wu","id":"6ebfbc954b9975d2f2651f380b9bdf46ae963178","summary":"This work proposes a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering, and introduces discrete latent variables to tackle the inherent one-to-many mapping problem in response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/11abce981e90585c142078b5c64b2cb8331b8794","title":"The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents","venue":"Annual Meeting of the Association for Computational Linguistics","year":2019,"referenceCount":56,"citationCount":70,"influentialCitationCount":7,"publicationDate":"09/11/2019","authors":"Kurt Shuster,Da Ju,Stephen Roller,Emily Dinan,Y-Lan Boureau,J. Weston","id":"11abce981e90585c142078b5c64b2cb8331b8794","summary":"D dodecaDialogue is introduced, a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the fine-tune and task transfer settings.","score":3},{"url":"https://www.semanticscholar.org/paper/15704cdfe55ddd375e7fec9e71cba9956a73972e","title":"EmpTransfo: A Multi-head Transformer Architecture for Creating Empathetic Dialog Systems","venue":"The Florida AI Research Society","year":2020,"referenceCount":31,"citationCount":34,"influentialCitationCount":2,"publicationDate":"05/03/2020","authors":"Rohola Zandie,M. Mahoor","id":"15704cdfe55ddd375e7fec9e71cba9956a73972e","summary":"It is shown that utilizing the history of emotions and other metadata can improve the quality of generated conversations by the dialog system, and the proposed approach outperforms other models in terms of Hit@1 and PPL (Perplexity).","score":3},{"url":"https://www.semanticscholar.org/paper/404859dc02da6c9dcb924535894dad0dc56696f2","title":"An Empirical Investigation of Pre-Trained Transformer Language Models for Open-Domain Dialogue Generation","venue":"arXiv.org","year":2020,"referenceCount":70,"citationCount":15,"influentialCitationCount":2,"publicationDate":"09/03/2020","authors":"Piji Li","id":"404859dc02da6c9dcb924535894dad0dc56696f2","summary":"An empirical investigation of pre-trained Transformer-based auto-regressive language models for the task of open-domain dialogue generation with detailed numbers of automatic evaluation metrics on relevance and diversity of the generated results for the languages models as well as the baseline approaches are reported.","score":3},{"url":"https://www.semanticscholar.org/paper/71017cc6d270d28d9edcd47550450dc05edd65f4","title":"Can You Put it All Together: Evaluating Conversational Agents’ Ability to Blend Skills","venue":"Annual Meeting of the Association for Computational Linguistics","year":2020,"referenceCount":19,"citationCount":184,"influentialCitationCount":18,"publicationDate":"17/04/2020","authors":"Eric Michael Smith,Mary Williamson,Kurt Shuster,J. Weston,Y-Lan Boureau","id":"71017cc6d270d28d9edcd47550450dc05edd65f4","summary":"This work investigates several ways to combine models trained towards isolated capabilities, ranging from simple model aggregation schemes that require minimal additional training, to various forms of multi-task training that encompass several skills at all training stages.","score":3},{"url":"https://www.semanticscholar.org/paper/18c54279a916293153db45e6db8422eaa52539cd","title":"Open-Domain Conversational Agents: Current Progress, Open Problems, and Future Directions","venue":"arXiv.org","year":2020,"referenceCount":164,"citationCount":41,"influentialCitationCount":5,"publicationDate":"22/06/2020","authors":"Stephen Roller,Y-Lan Boureau,J. Weston,Antoine Bordes,Emily Dinan,Angela Fan,David Gunning,Da Ju,Margaret Li,Spencer Poff,Pratik Ringshia,Kurt Shuster,Eric Michael Smith,Arthur Szlam,Jack Urbanek,Mary Williamson","id":"18c54279a916293153db45e6db8422eaa52539cd","summary":"The properties of continual learning, providing engaging content, and being well-behaved are discussed -- and how to measure success in providing them and their recommendations to the community are discussed.","score":3},{"url":"https://www.semanticscholar.org/paper/70af4173983eccc0beac29ed4602bf9db5568b92","title":"PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning","venue":"Findings","year":2020,"referenceCount":59,"citationCount":116,"influentialCitationCount":14,"publicationDate":"30/06/2020","authors":"Siqi Bao,H. He,Fan Wang,Hua Wu,Haifeng Wang,Wenquan Wu,Zhen Guo,Zhibin Liu,Xinchao Xu","id":"70af4173983eccc0beac29ed4602bf9db5568b92","summary":"To build a high-quality open-domain chatbot, this work introduces the effective training process of PLATO-2 via curriculum learning, achieving new state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/310ce0b1b4049206a260a711cc27cae5fad3700a","title":"Persona aware Response Generation with Emotions","venue":"IEEE International Joint Conference on Neural Network","year":2020,"referenceCount":45,"citationCount":7,"influentialCitationCount":0,"publicationDate":"01/07/2020","authors":"Mauajama Firdaus,Naveen Thangavelu,Asif Ekbal,P. Bhattacharyya","id":"310ce0b1b4049206a260a711cc27cae5fad3700a","summary":"This work proposes a persona aware attention framework employing an encoder-decoder approach in which the system can generate specific and consistent responses in accordance to the provided personality information and the conversational history.","score":3},{"url":"https://www.semanticscholar.org/paper/9fb623c516994ba4ec1365db16afced31ac23520","title":"What If Bots Feel Moods?","venue":"Annual International ACM SIGIR Conference on Research and Development in Information Retrieval","year":2020,"referenceCount":46,"citationCount":14,"influentialCitationCount":1,"publicationDate":"25/07/2020","authors":"L. Qiu,Yingwai Shiu,Pingping Lin,Ruihua Song,Yue Liu,Dongyan Zhao,Rui Yan","id":"9fb623c516994ba4ec1365db16afced31ac23520","summary":"An emotion-aware transition network is proposed to model the dynamic emotional flow and enhance context-response matching in retrieval-based dialogue systems with learnt intrinsic emotion features through a multi-task learning framework and is applied to a real IoT application.","score":3},{"url":"https://www.semanticscholar.org/paper/d8a0f9bb452bdd4408343d80336055d320cb6b1e","title":"Which Kind Is Better in Open-domain Multi-turn Dialog, Hierarchical or Non-hierarchical Models? An Empirical Study","venue":"arXiv.org","year":2020,"referenceCount":32,"citationCount":2,"influentialCitationCount":0,"publicationDate":"07/08/2020","authors":"Tian Lan,Xian-Ling Mao,Wei Wei,Heyan Huang","id":"d8a0f9bb452bdd4408343d80336055d320cb6b1e","summary":"Nearly all hierarchical models are worse than non-hierarchical models in open-domain multi-turn dialog generation, except for the HRAN model, and the word-level attention mechanism is so powerful for hierarchical models is because it can leverage context information more effectively, especially the fine-grained information.","score":3},{"url":"https://www.semanticscholar.org/paper/63913530782522e0d7ca5deceb40c08d606cafab","title":"Deploying Lifelong Open-Domain Dialogue Learning","venue":"arXiv.org","year":2020,"referenceCount":38,"citationCount":20,"influentialCitationCount":1,"publicationDate":"18/08/2020","authors":"Kurt Shuster,Jack Urbanek,Emily Dinan,Arthur Szlam,J. Weston","id":"63913530782522e0d7ca5deceb40c08d606cafab","summary":"This work builds and deploy a role-playing game, whereby human players converse with learning agents situated in an open-domain fantasy world and shows that by training models on the conversations they have with humans in the game the models progressively improve, as measured by automatic metrics and online engagement scores.","score":3},{"url":"https://www.semanticscholar.org/paper/fa544c82344a556b69316f05f2ea6f51fa202139","title":"The Adapter-Bot: All-In-One Controllable Conversational Model","venue":"AAAI Conference on Artificial Intelligence","year":2020,"referenceCount":77,"citationCount":55,"influentialCitationCount":3,"publicationDate":"28/08/2020","authors":"Andrea Madotto,Zhaojiang Lin,Yejin Bang,Pascale Fung","id":"fa544c82344a556b69316f05f2ea6f51fa202139","summary":"The Adapter-Bot is presented, a generative chat-bot that uses a fixed backbone conversational model such as DialGPT and triggers on-demand dialogue skills via different adapters that can be trained independently, thus allowing a continual integration of skills without retraining the entire model.","score":3},{"url":"https://www.semanticscholar.org/paper/7d5b2388945b5ba53512ab775d80f4659092307f","title":"Towards Empathetic Dialogue Generation over Multi-type Knowledge.","venue":"","year":2020,"referenceCount":55,"citationCount":16,"influentialCitationCount":5,"publicationDate":"21/09/2020","authors":"Qintong Li,Piji Li,Zhumin Chen,Z. Ren","id":"7d5b2388945b5ba53512ab775d80f4659092307f","summary":"This work proposes to leverage multi-type knowledge, i.e, the commonsense knowledge and emotional lexicon, to explicitly understand and express emotions in empathetic dialogue generation, and introduces a multi- type knowledge-aware context encoder to learn emotional context representations and distill emotional signals.","score":3},{"url":"https://www.semanticscholar.org/paper/66c8315b46c64e7bf375dc3b4b718d741bc697ee","title":"Empathetic Dialogue Generation via Knowledge Enhancing and Emotion Dependency Modeling","venue":"arXiv.org","year":2020,"referenceCount":49,"citationCount":12,"influentialCitationCount":1,"publicationDate":"21/09/2020","authors":"Qintong Li,Piji Li,Zhumin Chen,Z. Ren","id":"66c8315b46c64e7bf375dc3b4b718d741bc697ee","summary":"This work proposes a knowledge-enhanced framework, named Know-EDG, which outperforms state-of-the-art baselines in terms of automatic metrics and human evaluations and proposes an emotion-focused attention mechanism to exploit the emotional dependencies between dialogue context and target empathetic response.","score":3},{"url":"https://www.semanticscholar.org/paper/01caaf3a67ad31c93048a29fff90e62ad3dac167","title":"Knowledge Bridging for Empathetic Dialogue Generation","venue":"AAAI Conference on Artificial Intelligence","year":2020,"referenceCount":49,"citationCount":53,"influentialCitationCount":15,"publicationDate":"21/09/2020","authors":"Qintong Li,Pijian Li,Z. Ren,Pengjie Ren,Zhumin Chen","id":"01caaf3a67ad31c93048a29fff90e62ad3dac167","summary":"This work proposes to leverage external knowledge, including commonsense knowledge and emotional lexical knowledge, to explicitly understand and express emotions in empathetic dialogue generation to address the problems of lack of external knowledge and limited dialogue history.","score":3},{"url":"https://www.semanticscholar.org/paper/9c72b6a869cbec916d5e6b05c4ea36056c93c52c","title":"Spot the Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":41,"citationCount":31,"influentialCitationCount":3,"publicationDate":"05/10/2020","authors":"Jan Deriu,Don Tuggener,Pius von Däniken,Jon Ander Campos,Álvaro Rodrigo,Thiziri Belkacem,Aitor Soroa Etxabe,Eneko Agirre,Mark Cieliebak","id":"9c72b6a869cbec916d5e6b05c4ea36056c93c52c","summary":"A cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots, and incorporates a metric that measures which chatbot can uphold human-like behavior the longest, i.e., \\emph{Survival Analysis}.","score":3},{"url":"https://www.semanticscholar.org/paper/ef3a96d8f42e8caa1994caba2e53ca98121b4d1f","title":"Plug-and-Play Conversational Models","venue":"Findings","year":2020,"referenceCount":65,"citationCount":47,"influentialCitationCount":5,"publicationDate":"09/10/2020","authors":"Andrea Madotto,Etsuko Ishii,Zhaojiang Lin,Sumanth Dathathri,Pascale Fung","id":"ef3a96d8f42e8caa1994caba2e53ca98121b4d1f","summary":"This paper proposes and evaluates plug-and-play methods for controllable response generation, and demonstrates a high degree of control over the generated conversational responses with regard to multiple desired attributes, while being fluent.","score":3},{"url":"https://www.semanticscholar.org/paper/314358d6e9969cb89da0ad0b6aa4f406294d3ff4","title":"Generalized Conditioned Dialogue Generation Based on Pre-trained Language Model","venue":"arXiv.org","year":2020,"referenceCount":38,"citationCount":4,"influentialCitationCount":0,"publicationDate":"21/10/2020","authors":"Yan Zeng,J. Nie","id":"314358d6e9969cb89da0ad0b6aa4f406294d3ff4","summary":"This work proposes to complement the labeled dialogue data with labeled non-dialogue text data, and fine-tune BERT based on them, and utilizes BERT for both encoder and decoder via different input representations and self-attention masks in order to distinguish the source and target side.","score":3},{"url":"https://www.semanticscholar.org/paper/0f8cb4a6c794ee18d5f9177782cf07d000adffca","title":"An Evaluation Protocol for Generative Conversational Systems","venue":"arXiv.org","year":2020,"referenceCount":54,"citationCount":7,"influentialCitationCount":1,"publicationDate":"24/10/2020","authors":"Seolhwa Lee,Heuiseok Lim,João Sedoc","id":"0f8cb4a6c794ee18d5f9177782cf07d000adffca","summary":"The findings show that DialoGPT and Blender are superior systems using Bradley-Terry model and TrueSkill ranking methods and demonstrate the feasibility of the protocol for the evaluation of conversational models using head-to-head pairwise comparison.","score":3},{"url":"https://www.semanticscholar.org/paper/240f3eb516051b1e9f5baced99855e8495a1298a","title":"A Taxonomy of Empathetic Response Intents in Human Social Conversations","venue":"International Conference on Computational Linguistics","year":2020,"referenceCount":58,"citationCount":72,"influentialCitationCount":9,"publicationDate":"01/12/2020","authors":"A. Welivita,P. Pu","id":"240f3eb516051b1e9f5baced99855e8495a1298a","summary":"A large-scale taxonomy for empathetic response intents is produced and novel and important empathy patterns in human-human open-domain conversations are revealed and can serve as heuristics for hybrid approaches.","score":3},{"url":"https://www.semanticscholar.org/paper/2c1a85390a07030cbb57e583c5dfdaf8ec2829a5","title":"EmpDG: Multi-resolution Interactive Empathetic Dialogue Generation","venue":"International Conference on Computational Linguistics","year":2020,"referenceCount":52,"citationCount":34,"influentialCitationCount":7,"publicationDate":"01/12/2020","authors":"Qintong Li,Hongshen Chen,Z. Ren,Pengjie Ren,Zhaopeng Tu,Zhumin Chen","id":"2c1a85390a07030cbb57e583c5dfdaf8ec2829a5","summary":"A multi-resolution adversarial model – EmpDG is proposed, to generate more empathetic responses and an interactive adversarial learning framework which exploits the user feedback, to identify whether the generated responses evoke emotion perceptivity in dialogues.","score":3},{"url":"https://www.semanticscholar.org/paper/0e635104e5378bc226b0e07e429fcef44f959fc8","title":"Robust Dialogue Utterance Rewriting as Sequence Tagging","venue":"arXiv.org","year":2020,"referenceCount":29,"citationCount":6,"influentialCitationCount":2,"publicationDate":"29/12/2020","authors":"Jie Hao,Linfeng Song,Liwei Wang,Kun Xu,Zhaopeng Tu,Dong Yu","id":"0e635104e5378bc226b0e07e429fcef44f959fc8","summary":"A novel sequence-tagging-based model is proposed so that the search space is significantly reduced, yet the core of this task is still well covered, and the model's outputs may lack fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/6c48cedd98da74f4e1b29dc89aafd3c374e069fa","title":"Context-Controlled Topic-Aware Neural Response Generation for Open-Domain Dialog Systems","venue":"Information Processing & Management","year":2021,"referenceCount":52,"citationCount":28,"influentialCitationCount":0,"publicationDate":"01/01/2021","authors":"Yanxiang Ling,Fei Cai,Xuejun Hu,Jun Liu,Wanyu Chen,Honghui Chen","id":"6c48cedd98da74f4e1b29dc89aafd3c374e069fa","summary":"A Context-Controlled Topic-Aware neural response generation model, i.e., CCTA, which makes dialog context interact with the process of topic representing and transiting to achieve balanced improvements on response informativeness and contextual coherence and finds that topic transition modeling can work as an auxiliary learning task to boost the response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/983921bd0ccaee71df7580ce13dd0d53dba5f368","title":"Empathetic BERT2BERT Conversational Model: Learning Arabic Language Generation with Little Data","venue":"Workshop on Arabic Natural Language Processing","year":2021,"referenceCount":32,"citationCount":12,"influentialCitationCount":3,"publicationDate":"07/03/2021","authors":"Tarek Naous,Wissam Antoun,Reem A. Mahmoud,Hazem M. Hajj","id":"983921bd0ccaee71df7580ce13dd0d53dba5f368","summary":"A transformer-based encoder-decoder initialized with AraBERT parameters is proposed, validating its high capability in exhibiting empathy while generating relevant and fluent responses in open-domain settings.","score":3},{"url":"https://www.semanticscholar.org/paper/f4bef31094420c572e6c4159c45234c741d9e5bf","title":"Multi-Task Learning of Generation and Classification for Emotion-Aware Dialogue Response Generation","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":23,"citationCount":17,"influentialCitationCount":0,"publicationDate":"25/05/2021","authors":"Tatsuya Ide,Daisuke Kawahara","id":"f4bef31094420c572e6c4159c45234c741d9e5bf","summary":"This model based on BART, a pre-trained transformer encoder-decoder model, is trained to generate responses and recognize emotions simultaneously, and weight the losses for the tasks to control the update of parameters.","score":3},{"url":"https://www.semanticscholar.org/paper/87102d1054611d8cf8bc4e743516ef3a613766ac","title":"A Simple and Efficient Multi-Task Learning Approach for Conditioned Dialogue Generation","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":39,"citationCount":11,"influentialCitationCount":2,"publicationDate":"01/06/2021","authors":"Yan Zeng,J. Nie","id":"87102d1054611d8cf8bc4e743516ef3a613766ac","summary":"This work proposes a multi-task learning approach to leverage both labeled dialogue and text data, which outperforms the state-of-the-art models by leveraging the labeled texts, and it obtains larger improvement in performance comparing to the previous methods to leverage text data.","score":3},{"url":"https://www.semanticscholar.org/paper/753baa88a7f49f6605ae30f77a54dbb9e074c8b4","title":"DynaEval: Unifying Turn and Dialogue Level Evaluation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":64,"citationCount":52,"influentialCitationCount":8,"publicationDate":"02/06/2021","authors":"Chen Zhang,Yiming Chen,L. F. D’Haro,Yan Zhang,Thomas Friedrichs,Grandee Lee,Haizhou Li","id":"753baa88a7f49f6605ae30f77a54dbb9e074c8b4","summary":"DynaEval, a unified automatic evaluation framework which is not only capable of performing turn-level evaluation, but also holistically considers the quality of the entire dialogue, is proposed.","score":3},{"url":"https://www.semanticscholar.org/paper/88064de690af282dbdf222774f03ff070b9df22b","title":"Beyond Goldfish Memory: Long-Term Open-Domain Conversation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":40,"citationCount":152,"influentialCitationCount":40,"publicationDate":"15/07/2021","authors":"Jing Xu,Arthur Szlam,J. Weston","id":"88064de690af282dbdf222774f03ff070b9df22b","summary":null,"score":3},{"url":"https://www.semanticscholar.org/paper/8f31038de5cadc3171735c0410511c044d216463","title":"Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":18,"citationCount":14,"influentialCitationCount":4,"publicationDate":"19/07/2021","authors":"Nyoungwoo Lee,Suwon Shin,J. Choo,Ho‐Jin Choi,S. Myaeng","id":"8f31038de5cadc3171735c0410511c044d216463","summary":"Automatic metrics and human evaluation results show that the proposed 45k multi-modal dialogue dataset can be effectively used as training data for multi- modal dialogue systems which require an understanding of images and text in a context-aware manner.","score":3},{"url":"https://www.semanticscholar.org/paper/9f54b02d32835a6dc977a335444df707494763ec","title":"Proto: A Neural Cocktail for Generating Appealing Conversations","venue":"arXiv.org","year":2021,"referenceCount":40,"citationCount":9,"influentialCitationCount":0,"publicationDate":"06/09/2021","authors":"Sougata Saha,Souvik Das,Elizabeth Soper,Erin Pacquetet,R. Srihari","id":"9f54b02d32835a6dc977a335444df707494763ec","summary":"This paper dissect and analyze the different components and conversation strategies implemented by the socialbot, which enables it to generate colloquial, empathetic, engaging, self-rectifying, factually correct, and on-topic response, which has helped it achieve consistent scores throughout the competition.","score":3},{"url":"https://www.semanticscholar.org/paper/690edf89431f26d355fc4a991a489d9d080e1ebe","title":"Alquist 4.0: Towards Social Intelligence Using Generative Models and Dialogue Personalization","venue":"arXiv.org","year":2021,"referenceCount":34,"citationCount":14,"influentialCitationCount":1,"publicationDate":"16/09/2021","authors":"Jakub Konrád,Jan Pichl,Petro Marek,Petr Lorenc,Van Duy Ta,Ondrej Kobza,L. Hýlová,J. Sedivý","id":"690edf89431f26d355fc4a991a489d9d080e1ebe","summary":"The principles and inner workings of individual components of the open-domain dialogue system Alquist developed within the Alexa Prize Socialbot Grand Challenge 4 are presented and the experiments conducted to evaluate them are presented.","score":3},{"url":"https://www.semanticscholar.org/paper/30873c32db5a219a58be928d5692cce48be1d3a0","title":"Few-Shot Bot: Prompt-Based Learning for Dialogue Systems","venue":"arXiv.org","year":2021,"referenceCount":116,"citationCount":56,"influentialCitationCount":6,"publicationDate":"15/10/2021","authors":"Andrea Madotto,Zhaojiang Lin,Genta Indra Winata,Pascale Fung","id":"30873c32db5a219a58be928d5692cce48be1d3a0","summary":"An end-to-end chatbot named the Few-Shot Bot is created, which automatically selects the most appropriate conversational skill, queries different knowledge bases or the internet, and uses the retrieved knowledge to generate a human-like response, all using only few dialogue examples per skill.","score":3},{"url":"https://www.semanticscholar.org/paper/84363d3326105df2d297898e411be02b62e7df63","title":"Modeling Performance in Open-Domain Dialogue with PARADISE","venue":"arXiv.org","year":2021,"referenceCount":69,"citationCount":4,"influentialCitationCount":0,"publicationDate":"21/10/2021","authors":"M. Walker,Colin Harmon,James Graupera,Davan Harrison,S. Whittaker","id":"84363d3326105df2d297898e411be02b62e7df63","summary":"A PARADISE model is developed for predicting the performance of Athena, a dialogue system that has participated in thousands of conversations with real users, while competing as a finalist in the Alexa Prize.","score":3},{"url":"https://www.semanticscholar.org/paper/54e00dfd4821b0b21bb4e8392336a8c8ac062d43","title":"Conversational Agents: Goals, Technologies, Vision and Challenges","venue":"Italian National Conference on Sensors","year":2021,"referenceCount":257,"citationCount":40,"influentialCitationCount":3,"publicationDate":"01/12/2021","authors":"Merav Allouch,A. Azaria,Rina Azoulay-Schwartz","id":"54e00dfd4821b0b21bb4e8392336a8c8ac062d43","summary":"The main areas in which CAs are successful are described along with the main technologies that enable the creation of CAs and the primary tools and datasets that may be useful for the development and evaluation ofCAs of different categories are described.","score":3},{"url":"https://www.semanticscholar.org/paper/3af37400f1f9a4f4f211c4a472e18963edc2b34f","title":"ValueNet: A New Dataset for Human Value Driven Dialogue System","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":49,"citationCount":19,"influentialCitationCount":3,"publicationDate":"12/12/2021","authors":"Liang Qiu,Yizhou Zhao,Jinchao Li,Pan Lu,Baolin Peng,Jianfeng Gao,Song-Chun Zhu","id":"3af37400f1f9a4f4f211c4a472e18963edc2b34f","summary":"This work presents a new large-scale human value dataset called ValueNet, which contains human attitudes on 21,374 text scenarios and is the first one trying to incorporate a value model into emotionally intelligent dialogue systems.","score":3},{"url":"https://www.semanticscholar.org/paper/c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7","title":"Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge","venue":"AAAI Conference on Artificial Intelligence","year":2021,"referenceCount":55,"citationCount":22,"influentialCitationCount":7,"publicationDate":"16/12/2021","authors":"Yoonna Jang,J. Lim,Yuna Hur,Dongsuk Oh,Suhyune Son,Yeonsoo Lee,Donghoon Shin,Seungryong Kim,Heuiseok Lim","id":"c65c96cfc8b448fe9fd6bbfe1aaaea727515f4f7","summary":"This work introduces a call For Customized conversation (FoCus) dataset where the customized answers are built with the user's persona and Wikipedia knowledge and shows that the utterances of the data are constructed with the proper knowledge and persona through grounding quality assessment.","score":3},{"url":"https://www.semanticscholar.org/paper/e0af8f2dd390fabcdf2c373640833efc62faa530","title":"FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":54,"citationCount":3,"influentialCitationCount":0,"publicationDate":"14/02/2022","authors":"Jianqiao Zhao,Yanyang Li,Wanyu Du,Yangfeng Ji,Dong Yu,M. Lyu,Liwei Wang","id":"e0af8f2dd390fabcdf2c373640833efc62faa530","summary":"This work develops the first consensus-based dialogue evaluation framework, FlowEval, which provides a reference-free approach for dialog evaluation by finding pseudo-references and proposes segment act, an extension of dialog act from utterance level to segment level, and crowdsource a large-scale dataset for it.","score":3},{"url":"https://www.semanticscholar.org/paper/c8fba3d80a3b6add6fb386f458850d02b77f34bb","title":"Generating Relevant and Informative Questions for Open-Domain Conversations","venue":"ACM Trans. Inf. Syst.","year":2022,"referenceCount":92,"citationCount":4,"influentialCitationCount":0,"publicationDate":"14/02/2022","authors":"Yanxiang Ling,Fei Cai,Jun Liu,Honghui Chen,M. de Rijke","id":"c8fba3d80a3b6add6fb386f458850d02b77f34bb","summary":"A context-enhanced neural question generation model that leverages the conversational context to predict question content and pattern, then performs question decoding, and is the first to extend the application of QG to the multi-turn open-domain conversational scenario.","score":3},{"url":"https://www.semanticscholar.org/paper/d73d3a82da0bc93be238c286abfd06722247d298","title":"Rethinking and Refining the Distinct Metric","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":60,"citationCount":5,"influentialCitationCount":0,"publicationDate":"28/02/2022","authors":"Siyang Liu,Sahand Sabour,Yinhe Zheng,Pei Ke,Xiaoyan Zhu,Minlie Huang","id":"d73d3a82da0bc93be238c286abfd06722247d298","summary":"This work refine the calculation of distinct scores by scaling the number of distinct tokens based on their expectations, and shows that the proposed metric, Expectation-Adjusted Distinct (EAD), correlates better with human judgment in evaluating response diversity.","score":3},{"url":"https://www.semanticscholar.org/paper/1e704b99a04aad6d6d7e665616b7d4ed2513da02","title":"Probing the Robustness of Trained Metrics for Conversational Dialogue Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":19,"citationCount":5,"influentialCitationCount":0,"publicationDate":"28/02/2022","authors":"Jan Deriu,Don Tuggener,Pius von Daniken,Mark Cieliebak","id":"1e704b99a04aad6d6d7e665616b7d4ed2513da02","summary":"An adversarial method to stress-test trained metrics for the evaluation of conversational dialogue systems using Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics is introduced.","score":3},{"url":"https://www.semanticscholar.org/paper/4ebff21b83277a523d9ce84c5cc745074b1f642e","title":"MISC: A Mixed Strategy-Aware Model integrating COMET for Emotional Support Conversation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":58,"citationCount":44,"influentialCitationCount":7,"publicationDate":"25/03/2022","authors":"Quan Tu,Yanran Li,Jianwei Cui,Bin Wang,Jiaxin Wen,Rui Yan","id":"4ebff21b83277a523d9ce84c5cc745074b1f642e","summary":"A novel model is proposed, which firstly infers the user’s fine-grained emotional status, and then responds skillfully using a mixture of strategy, which reveals the benefits of fine- grained emotion understanding as well as mixed-up strategy modeling.","score":3},{"url":"https://www.semanticscholar.org/paper/aab1dead436211a7d9eb7a717ee63a5d23cf23f0","title":"Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional Characters with only a Few Utterances","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":60,"citationCount":11,"influentialCitationCount":2,"publicationDate":"22/04/2022","authors":"Seungju Han,Beomsu Kim,Jin Yong Yoo,Seokjun Seo,Sangbum Kim,Enkhbayar Erdenee,Buru Chang","id":"aab1dead436211a7d9eb7a717ee63a5d23cf23f0","summary":"A new method named Pseudo Dialog Prompting (PDP) is proposed that generates responses by leveraging the power of large-scale language models with prompts containing the target character’s utterances to better reflect the style of fictional characters.","score":3},{"url":"https://www.semanticscholar.org/paper/77ced33cba86b4d01fbfe6622c8f564c89d6a1b3","title":"A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration","venue":"arXiv.org","year":2022,"referenceCount":39,"citationCount":12,"influentialCitationCount":1,"publicationDate":"05/05/2022","authors":"Shaojie Jiang,Ruqing Zhang,Svitlana Vakulenko,M. de Rijke","id":"77ced33cba86b4d01fbfe6622c8f564c89d6a1b3","summary":"The key idea is to teach a LM to generate high probabilities for label tokens and low probabilities of negative candidates, which yields much less repetitive texts and a higher generation quality than baseline approaches, achieving the new state-of-the-art performance on text degeneration.","score":3},{"url":"https://www.semanticscholar.org/paper/086f3f9f023f0127f4be03a21189a1e90ffbb01f","title":"Empathetic Conversational Systems: A Review of Current Advances, Gaps, and Opportunities","venue":"IEEE Transactions on Affective Computing","year":2022,"referenceCount":135,"citationCount":10,"influentialCitationCount":0,"publicationDate":"09/05/2022","authors":"Aravind Sesagiri Raamkumar,Yinping Yang","id":"086f3f9f023f0127f4be03a21189a1e90ffbb01f","summary":"It is recommended that future studies should address key gaps in areas of detecting and authenticating emotions at the entity level, handling multimodal inputs, displaying more nuanced empathetic behaviors, and encompassing additional dialogue system features.","score":3},{"url":"https://www.semanticscholar.org/paper/d69ec0bbc9fc4fe898ac8cb73f629d253358bf66","title":"Stop Filtering: Multi-View Attribute-Enhanced Dialogue Learning","venue":"Knowledge-Based Systems","year":2022,"referenceCount":65,"citationCount":2,"influentialCitationCount":0,"publicationDate":"23/05/2022","authors":"Yiwei Li,Bin Sun,Shaoxiong Feng,Kan Li","id":"d69ec0bbc9fc4fe898ac8cb73f629d253358bf66","summary":"A multi-view attribute-enhanced dialogue learning framework that strengthens the attribute-related features more robustly and comprehensively and can improve the performance significantly in terms of enhancing dialogue attributes and fusing view-specific knowledge.","score":3},{"url":"https://www.semanticscholar.org/paper/d6a60f41e6e53469042259ce3c281907907c0993","title":"Building a Dialogue Corpus Annotated with Expressed and Experienced Emotions","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":26,"citationCount":3,"influentialCitationCount":0,"publicationDate":"24/05/2022","authors":"Tatsuya Ide,Daisuke Kawahara","id":"d6a60f41e6e53469042259ce3c281907907c0993","summary":"This work proposes a method to build a dialogue corpus annotated with two kinds of emotions, collecting dialogues from Twitter and annotating each utterance with the emotion that a speaker put into the utterance and the emotion a listener felt after listening to the utterances.","score":3},{"url":"https://www.semanticscholar.org/paper/36c50e6638dddc8324eef9bfa064bfcab80cbef4","title":"ProsocialDialog: A Prosocial Backbone for Conversational Agents","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":86,"citationCount":66,"influentialCitationCount":9,"publicationDate":"25/05/2022","authors":"Hyunwoo Kim,Youngjae Yu,Liwei Jiang,Ximing Lu,Daniel Khashabi,Gunhee Kim,Yejin Choi,Maarten Sap","id":"36c50e6638dddc8324eef9bfa064bfcab80cbef4","summary":"This work introduces ProsocialDialog, the first large-scale multi-turn dialogue dataset to teach conversational agents to respond to problematic content following social norms, and introduces a dialogue safety detection module, Canary, capable of generating RoTs given conversational context, and a socially-informed dialogue agent, Prost.","score":3},{"url":"https://www.semanticscholar.org/paper/cb1ecd3a14c5a65c3f887cfd3072bc05f1eea70c","title":"CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI","venue":"arXiv.org","year":2022,"referenceCount":84,"citationCount":11,"influentialCitationCount":0,"publicationDate":"29/05/2022","authors":"Yirong Chen,Weiquan Fan,Xiaofen Xing,Jianxin Pang,Minlie Huang,W. Han,Qianfeng Tie,Xiangmin Xu","id":"cb1ecd3a14c5a65c3f887cfd3072bc05f1eea70c","summary":"This work proposes CPED, a large-scale Chinese personalized and emotional dialogue dataset, which consists of multi-source knowledge related to empathy and personal characteristic, to be widely adopted by the NLP community as a new open benchmark for conversational AI research.","score":3},{"url":"https://www.semanticscholar.org/paper/e86869d44e78d4cffd1bf1b62f2f8e56a519e23c","title":"E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation","venue":"IEEE Transactions on Knowledge and Data Engineering","year":2022,"referenceCount":100,"citationCount":16,"influentialCitationCount":0,"publicationDate":"30/05/2022","authors":"Qihuang Zhong,Liang Ding,Juhua Liu,Bo Du,Dacheng Tao","id":"e86869d44e78d4cffd1bf1b62f2f8e56a519e23c","summary":"This work proposes an encoding-enhanced seq2seq pretraining strategy, namely E2S2, which improves the seq2seq models via integrating more efficient self-supervised information into the encoders via integrating more efficient self-supervised information into the encoders.","score":3},{"url":"https://www.semanticscholar.org/paper/5c474c68dea579784eb61f84c6250d3d22dfc485","title":"Towards a sentiment-aware conversational agent","venue":"International Conference on Intelligent Virtual Agents","year":2022,"referenceCount":40,"citationCount":2,"influentialCitationCount":0,"publicationDate":"24/07/2022","authors":"Isabel Dias,Ricardo Rei,Patrícia Pereira,Luísa Coheur","id":"5c474c68dea579784eb61f84c6250d3d22dfc485","summary":"Results show that explicitly guiding the text generation model with a pre-defined set of sentiment sentences leads to clear improvements, regarding the expressed sentiment and the quality of the generated text.","score":3},{"url":"https://www.semanticscholar.org/paper/1c25b49fb6a2789597320a9e3591a6e51f1ed6ed","title":"Neural Generation Meets Real People: Building a Social, Informative Open-Domain Dialogue Agent","venue":"SIGDIAL Conferences","year":2022,"referenceCount":81,"citationCount":5,"influentialCitationCount":0,"publicationDate":"25/07/2022","authors":"Ethan A. Chi,Ashwin Paranjape,A. See,Caleb Chiam,Kathleen Kenealy,Swee Kiat Lim,Amelia Hardy,Chetanya Rastogi,Hao Li,Alexander Iyabor,Yutong He,Hari Sowrirajan,Peng Qi,Kaushik Ram Sadagopan,Nguyet Minh Phu,Dilara Soylu,Jillian Tang,A. Narayan,Giovanni Campagna,Christopher D. Manning","id":"1c25b49fb6a2789597320a9e3591a6e51f1ed6ed","summary":"Aiming to be both informative and conversational, the Chirpy Cardinal bot chats with users in an authentic, emotionally intelligent way by integrating controlled neural generation with scaffolded, hand-written dialogue, producing an engaging and socially fluent experience.","score":3},{"url":"https://www.semanticscholar.org/paper/9a1e0b8cc7a94dbe3929bb350bd04f5017a88515","title":"Building the Intent Landscape of Real-World Conversational Corpora with Extractive Question-Answering Transformers","venue":"arXiv.org","year":2022,"referenceCount":46,"citationCount":0,"influentialCitationCount":0,"publicationDate":"26/08/2022","authors":"Jean-Philippe Corbeil,Mia Taige Li,H. Ghavidel","id":"9a1e0b8cc7a94dbe3929bb350bd04f5017a88515","summary":"This work proposes an unsupervised pipeline that extracts the intents and the taxonomy of intents from real-world dialogues and demonstrates the generalization ability of an ELECTRA large model tuned on the SQuAD2 dataset to understand dialogues.","score":3},{"url":"https://www.semanticscholar.org/paper/cd6652fe413d57d05b44e0f3aa036c54f0eef464","title":"Towards Boosting the Open-Domain Chatbot with Human Feedback","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":43,"citationCount":6,"influentialCitationCount":1,"publicationDate":"30/08/2022","authors":"Hua Lu,Siqi Bao,H. He,Fan Wang,Hua Wu,Haifeng Wang","id":"cd6652fe413d57d05b44e0f3aa036c54f0eef464","summary":"A novel and efficient framework Diamante is proposed to boost the open-domain chatbot, where two kinds of human feedback are collected and leveraged and the implicit preference in the data collection process and the generation-evaluation joint training is introduced.","score":3},{"url":"https://www.semanticscholar.org/paper/051808bd0abd0350b6d642cf4f0cb63533b3f06d","title":"Prediction, selection, and generation: a knowledge-driven conversation system","venue":"Neural computing & applications (Print)","year":2022,"referenceCount":51,"citationCount":0,"influentialCitationCount":0,"publicationDate":"18/09/2022","authors":"Cheng Luo,Dayiheng Liu,Chanjuan Li,Li Lu,Jiancheng Lv","id":"051808bd0abd0350b6d642cf4f0cb63533b3f06d","summary":"This paper proposes a knowledge-driven conversation system that outperforms a strong baseline and achieves state-of-the-art results, and proposes the Bert2Transformer model as the dialogue generator, which can generate rich and fluent utterances based on contextual and relevant knowledge.","score":3},{"url":"https://www.semanticscholar.org/paper/52788fec0b67236d110eaa2d6ce637febb9ef4aa","title":"An Explainable Artificial Intelligence Approach for Detecting Empathy in Textual Communication","venue":"Applied Sciences","year":2022,"referenceCount":107,"citationCount":5,"influentialCitationCount":0,"publicationDate":"20/09/2022","authors":"Edwin Carlos Montiel-Vázquez,J. R. Ramírez Uresti,O. Loyola-González","id":"52788fec0b67236d110eaa2d6ce637febb9ef4aa","summary":"It is shown that an explicative pattern-based approach (PBC4cip) is, to date, the best approach for detecting empathy in texts by measuring performance in both nominal and ordinal metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/fa65e9eecf98dbd0a6a67fbd3fcc035de0badd6c","title":"MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":70,"citationCount":17,"influentialCitationCount":7,"publicationDate":"10/11/2022","authors":"Jiazhan Feng,Qingfeng Sun,Can Xu,Pu Zhao,Yaming Yang,Chongyang Tao,Dongyan Zhao,Qingwei Lin","id":"fa65e9eecf98dbd0a6a67fbd3fcc035de0badd6c","summary":"This paper introduces the MMDialog dataset and proposes and normalize two response prediction tasks based on retrieval and generative scenarios, and proposes a novel evaluation metric MM-Relevance to measure the multi-modal responses.","score":3},{"url":"https://www.semanticscholar.org/paper/59a8057b8c2d0f72b09e46b9c4d43b4971eef930","title":"A response generator with response-aware encoder for generating specific and relevant responses","venue":"Soft Computing - A Fusion of Foundations, Methodologies and Applications","year":2022,"referenceCount":51,"citationCount":0,"influentialCitationCount":0,"publicationDate":"28/11/2022","authors":"So-Eon Kim,Hyun-Je Song,Seong-Bae Park","id":"59a8057b8c2d0f72b09e46b9c4d43b4971eef930","summary":"The proposed model is the first attempt to use a golden response directly for generating a query representation, whereas previous studies used the responses for its implicit and indirect reflection.","score":3},{"url":"https://www.semanticscholar.org/paper/89924944fe899fc26e8dfa447900ca849f47b76a","title":"DialogCC: Large-Scale Multi-Modal Dialogue Dataset","venue":"arXiv.org","year":2022,"referenceCount":64,"citationCount":4,"influentialCitationCount":1,"publicationDate":"08/12/2022","authors":"Young-Jun Lee,ByungSoo Ko,Han-Gyu Kim,Ho-Jin Choi","id":"89924944fe899fc26e8dfa447900ca849f47b76a","summary":"It is demonstrated that training a multi-modal dialogue model with the proposed DialogCC dataset can improve generalization performance and existing models trained with the dataset achieve state-of-the-art performance on image and text retrieval tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/cb4cfa57f14f8120827b34107a36b4aa20b0c9a4","title":"Open-Domain Response Generation in Low-Resource Settings using Self-Supervised Pre-Training of Warm-Started Transformers","venue":"ACM Trans. Asian Low Resour. Lang. Inf. Process.","year":2023,"referenceCount":41,"citationCount":3,"influentialCitationCount":0,"publicationDate":"05/01/2023","authors":"Tarek Naous,Zahraa Bassyouni,Bassel Mousi,Hazem M. Hajj,Wassim El Hajj,K. Shaban","id":"cb4cfa57f14f8120827b34107a36b4aa20b0c9a4","summary":"A framework for training open-domain response generation models in low-resource settings that is capable of generating fluent responses in multiple dialects with an average human-evaluated fluency score above 4 and fine-tuned on a very small labeled dataset for open- domain response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/12d13eb67b05a74d49fda150d62deb0fc4462dc2","title":"Improving Open-Domain Dialogue Evaluation with a Causal Inference Model","venue":"arXiv.org","year":2023,"referenceCount":57,"citationCount":9,"influentialCitationCount":0,"publicationDate":"31/01/2023","authors":"Cat P. Le,Luke Dai,Michael Johnston,Yang Liu,M. Walker,R. Ghanadan","id":"12d13eb67b05a74d49fda150d62deb0fc4462dc2","summary":"This work explores the creation of automated methods for predicting both expert and user ratings of open-domain dialogues and shows that the proposed CF-LSTM is a sequential model over turn-level features which predicts ratings using multiple regressors depending on hypotheses derived from the turn- level features.","score":3},{"url":"https://www.semanticscholar.org/paper/5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691","title":"PLACES: Prompting Language Models for Social Conversation Synthesis","venue":"Findings","year":2023,"referenceCount":64,"citationCount":30,"influentialCitationCount":0,"publicationDate":"07/02/2023","authors":"Maximillian Chen,A. Papangelis,Chenyang Tao,Seokhwan Kim,Andrew Rosenbaum,Yang Liu,Zhou Yu,Dilek Z. Hakkani-Tür","id":"5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691","summary":"This work uses a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting, and demonstrates that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi- party tasks.","score":3},{"url":"https://www.semanticscholar.org/paper/36c8d3ef11c1ebe311489c27dffca56d19369c38","title":"Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue Response Generation Models by Causal Discovery","venue":"Transactions of the Association for Computational Linguistics","year":2023,"referenceCount":64,"citationCount":0,"influentialCitationCount":0,"publicationDate":"02/03/2023","authors":"Tao Feng,Lizhen Qu,Gholamreza Haffari","id":"36c8d3ef11c1ebe311489c27dffca56d19369c38","summary":"Inspired by causal discovery algorithms, a novel model-agnostic method for training and inference using a conditional independence classifier is proposed that significantly outperforms the competitive baselines in terms of relevance, informativeness, and fluency.","score":3},{"url":"https://www.semanticscholar.org/paper/c12473c442f59613f5640b76acea389c1d4f518a","title":"Weakly Supervised Turn-level Engagingness Evaluator for Dialogues","venue":"Conference on Human Information Interaction and Retrieval","year":2023,"referenceCount":40,"citationCount":1,"influentialCitationCount":1,"publicationDate":"19/03/2023","authors":"Shaojie Jiang,S. Vakulenko,M. de Rijke","id":"c12473c442f59613f5640b76acea389c1d4f518a","summary":"This work pioneer an alternative approach, Weakly Supervised Engagingness Evaluator (WeSEE), which uses the remaining depth for each turn as a heuristic weak label for engagingness, thus serving as a good learning proxy for this metric.","score":3},{"url":"https://www.semanticscholar.org/paper/86dcd6268324b65960f0ac6287dabf155647c5f7","title":"Heterogeneous-Branch Collaborative Learning for Dialogue Generation","venue":"AAAI Conference on Artificial Intelligence","year":2023,"referenceCount":58,"citationCount":1,"influentialCitationCount":0,"publicationDate":"21/03/2023","authors":"Yiwei Li,Shaoxiong Feng,Bin Sun,Kan Li","id":"86dcd6268324b65960f0ac6287dabf155647c5f7","summary":"This work considers the dialogue attributes in the training of network branches and proposes a dual group-based knowledge distillation method, consisting of positive distillation and negative distillation, to further diversify the features of different branches in a steadily and interpretable way.","score":3},{"url":"https://www.semanticscholar.org/paper/22c872c4e2761089cbb7688f258e00c4e6c7a39a","title":"When Crowd Meets Persona: Creating a Large-Scale Open-Domain Persona Dialogue Corpus","venue":"arXiv.org","year":2023,"referenceCount":33,"citationCount":1,"influentialCitationCount":0,"publicationDate":"01/04/2023","authors":"Won Ik Cho,Yoon Kyung Lee,Seoyeon Bae,Jihwan Kim,S. Park,Moosung Kim,S. Hahn,N. Kim","id":"22c872c4e2761089cbb7688f258e00c4e6c7a39a","summary":"This study tackles issues when creating a large-scale open-domain persona dialogue corpus, where persona implies that the conversation is performed by several actors with a fixed persona and user-side workers from an unspecified crowd.","score":3},{"url":"https://www.semanticscholar.org/paper/34305fa411aefdc309f590d0da85fc22731dc7de","title":"Triggering Empathy out of Malicious Intent: The Role of Empathy in Social Engineering Attacks","venue":"EMPATHICH","year":2023,"referenceCount":47,"citationCount":0,"influentialCitationCount":0,"publicationDate":"23/04/2023","authors":"Verena Distler,Yasmeen Abdrabou,Felix Dietz,Florian Alt","id":"34305fa411aefdc309f590d0da85fc22731dc7de","summary":"This paper focuses on the malicious ways in which empathy can be instrumentalized in social engineering, and explores potential solutions (including the automated detection of empathy-triggering communication, or of empathetic communication on the part of a potential victim).","score":3},{"url":"https://www.semanticscholar.org/paper/5ef881b8f06bec87452032a59983c83e9e02ea86","title":"A Critical Analysis of EmpatheticDialogues as a Corpus for Empathetic Engagement","venue":"EMPATHICH","year":2023,"referenceCount":35,"citationCount":0,"influentialCitationCount":0,"publicationDate":"23/04/2023","authors":"Alok Debnath,Owen Conlan","id":"5ef881b8f06bec87452032a59983c83e9e02ea86","summary":"This analysis aims to analyze the content and relevance of one of the most popular contemporary training corpora for empathetic conversational agents: EmpatheticDialogues, including a detailed qualitative breakdown of the corpus including the corpus creation methodology, and provides a quantitative comparison to other contemporary small-talk corpora.","score":3},{"url":"https://www.semanticscholar.org/paper/a89c30ceca55783a1b2ff843eb6a4793e4a54b66","title":"Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting","venue":"arXiv.org","year":2023,"referenceCount":94,"citationCount":1,"influentialCitationCount":0,"publicationDate":"24/05/2023","authors":"Akhila Yerukola,Xuhui Zhou,Maarten Sap","id":"a89c30ceca55783a1b2ff843eb6a4793e4a54b66","summary":"A new composite contextual evaluation metric is introduced that combines similarity to the original sentence with contextual cohesiveness and highlights the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.","score":3},{"url":"https://www.semanticscholar.org/paper/d0f108b8f5fcfb81e4354b498f3f8491740ece7e","title":"COMET-M: Reasoning about Multiple Events in Complex Sentences","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":52,"citationCount":1,"influentialCitationCount":0,"publicationDate":"24/05/2023","authors":"Sahithya Ravi,R. Ng,Vered Shwartz","id":"d0f108b8f5fcfb81e4354b498f3f8491740ece7e","summary":"ComET-M (Multi-Event), an event-centric commonsense model capable of generating commonsense inferences for a target event within a complex sentence, is proposed and holds promise for downstream tasks involving natural text such as coreference resolution, dialogue, and story understanding.","score":3},{"url":"https://www.semanticscholar.org/paper/4bd35d344c635b05f97f4d749741d196ff541bf3","title":"A Primer on Seq2Seq Models for Generative Chatbots","venue":"ACM Computing Surveys","year":2023,"referenceCount":198,"citationCount":2,"influentialCitationCount":0,"publicationDate":"09/06/2023","authors":"Vincenzo Scotti,L. Sbattella,Roberto Tedesco","id":"4bd35d344c635b05f97f4d749741d196ff541bf3","summary":"Recent trends in the development of open-domain data-driven generative chatbots are examined, focusing on the Seq2Seq architectures, which allow to directly output the next turn in a conversation but also allow to control the style or content of the response.","score":3},{"url":"https://www.semanticscholar.org/paper/9799c17fd287bb9e8d231fe032c6dbf9c0c9d675","title":"Overview of Robust and Multilingual Automatic Evaluation Metrics\n\nfor Open-Domain Dialogue Systems at DSTC 11 Track 4","venue":"DSTC","year":2023,"referenceCount":71,"citationCount":3,"influentialCitationCount":0,"publicationDate":"22/06/2023","authors":"Mario Rodr'iguez-Cantelar,Chen Zhang,Chengguang Tang,Ke Shi,Sarik Ghazarian,João Sedoc,L. F. D’Haro,Alexander I. Rudnicky","id":"9799c17fd287bb9e8d231fe032c6dbf9c0c9d675","summary":"The datasets and baselines provided to participants are described and the submission and result details of the two proposed subtasks are discussed, which promote robust and multilingual automatic evaluation metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/74fedee9d809ec766a2089a89435fa7dd1346693","title":"How About Kind of Generating Hedges using End-to-End Neural Models?","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":75,"citationCount":1,"influentialCitationCount":0,"publicationDate":"26/06/2023","authors":"Alafate Abulimiti,C. Clavel,Justine Cassell","id":"74fedee9d809ec766a2089a89435fa7dd1346693","summary":"This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier.","score":3},{"url":"https://www.semanticscholar.org/paper/21bf712e642fda8a1a1f0e15ea910e080f1b674e","title":"I Enjoy Writing and Playing, Do You?: A Personalized and Emotion Grounded Dialogue Agent Using Generative Adversarial Network","venue":"IEEE Transactions on Affective Computing","year":2023,"referenceCount":103,"citationCount":5,"influentialCitationCount":0,"publicationDate":"01/07/2023","authors":"Mauajama Firdaus,Naveen Thangavelu,Asif Ekbal,P. Bhattacharyya","id":"21bf712e642fda8a1a1f0e15ea910e080f1b674e","summary":"This work designs a generative adversarial framework, named EP-GAN (Empathy and Persona aware Generative Adversarial Network), to generate responses that are sensitive to the emotion of the user and corresponds to the persona in dialogues.","score":3},{"url":"https://www.semanticscholar.org/paper/84a36e19f9394f22b34f79756fa9628a795e02ea","title":"LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset","venue":"arXiv.org","year":2023,"referenceCount":62,"citationCount":18,"influentialCitationCount":3,"publicationDate":"21/09/2023","authors":"Lianmin Zheng,Wei-Lin Chiang,Ying Sheng,Tianle Li,Siyuan Zhuang,Zhanghao Wu,Yonghao Zhuang,Zhuohan Li,Zi Lin,Eric P. Xing,Joseph E. Gonzalez,I. Stoica,Haotong Zhang","id":"84a36e19f9394f22b34f79756fa9628a795e02ea","summary":"This paper introduces LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs, and demonstrates its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that performs similarly to Vicuna, and creating challenging benchmark questions.","score":3},{"url":"https://www.semanticscholar.org/paper/d2af7f63861ad683b061b508316624615bff162d","title":"Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":33,"citationCount":0,"influentialCitationCount":0,"publicationDate":"20/10/2023","authors":"Jihyoung Jang,Minseong Boo,Hyounghun Kim","id":"d2af7f63861ad683b061b508316624615bff162d","summary":"A new 1M multi-session dialogue dataset, called Conversation Chronicles, is introduced and a dialogue model, called ReBot, which consists of chronological summarization and dialogue generation modules using only around 630M parameters is proposed, which demonstrates long-term context understanding with a high human engagement score.","score":3},{"url":"https://www.semanticscholar.org/paper/6ecb6f2c4544e3c7f8dfd33a8e2f14735653b6ef","title":"Improving Dialog Safety using Socially Aware Contrastive Learning","venue":"arXiv.org","year":2024,"referenceCount":45,"citationCount":0,"influentialCitationCount":0,"publicationDate":"01/02/2024","authors":"Souvik Das,R. Srihari","id":"6ecb6f2c4544e3c7f8dfd33a8e2f14735653b6ef","summary":"This work studies prosociality in both adversarial and casual dialog contexts and audit the response quality of general-purpose language models in terms of propensity to produce unsafe content, and proposes a dual-step fine-tuning process to address these issues using a socially aware n-pair contrastive loss.","score":3},{"url":"https://www.semanticscholar.org/paper/ec66bec9594e9359dfee2a874cbdd8349986bfad","title":"Dior-CVAE: Diffusion Priors in Variational Dialog Generation","venue":"arXiv.org","year":2023,"referenceCount":77,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Tianyu Yang,Thy Thy Tran,Iryna Gurevych","id":"ec66bec9594e9359dfee2a874cbdd8349986bfad","summary":"Dior-CVAE, a hierarchical CVAE model with an informative prior produced by a diffusion model, which derives a series of layer-wise latent variables using attention mechanism and infusing them into decoder layers accordingly to alleviate posterior collapse.","score":3},{"url":"https://www.semanticscholar.org/paper/75f8188332d47d55054e3fda3c3ab2e60f0deec7","title":"Dial-M: A Masking-based Framework for Dialogue Evaluation","venue":"SIGDIAL Conferences","year":2023,"referenceCount":47,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Suvodip Dey,M. Desarkar","id":"75f8188332d47d55054e3fda3c3ab2e60f0deec7","summary":"Dial-M, a Masking-based reference-free framework for Dialogue evaluation, the main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions, thereby making the evaluation framework simple and easily extensible for multiple datasets.","score":3},{"url":"https://www.semanticscholar.org/paper/c6d38e105562ae0a5d9b21fb4333212f36a3e041","title":"A Survey of Evaluation Metrics Used for NLG Systems","venue":"ACM Computing Surveys","year":2020,"referenceCount":206,"citationCount":144,"influentialCitationCount":9,"publicationDate":"27/08/2020","authors":"Ananya B. Sai,Akash Kumar Mohankumar,Mitesh M. Khapra","id":"c6d38e105562ae0a5d9b21fb4333212f36a3e041","summary":"This survey of automatic evaluation metrics for evaluating Natural Language Generation (NLG) systems highlights the challenges, proposes a coherent taxonomy for organising existing evaluation metrics, and briefly describes different existing metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/a7a00e14c60fd13bf08dc435e9b0fdd96d050b99","title":"Generating Negative Samples by Manipulating Golden Responses for Unsupervised Learning of a Response Evaluation Model","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":28,"citationCount":6,"influentialCitationCount":0,"publicationDate":"01/06/2021","authors":"chaeHun Park,Eugene Jang,Wonsuk Yang,Jong C. Park","id":"a7a00e14c60fd13bf08dc435e9b0fdd96d050b99","summary":"It is found that using the negative samples generated by the unsupervised learning of a golden response to create a new negative response that is designed to be inappropriate within the context while maintaining high similarity with the original golden response can increase the model's correlation with human evaluations.","score":3},{"url":"https://www.semanticscholar.org/paper/c8419114a8972e4945052e9699b69dfa858ab17c","title":"Towards Quantifiable Dialogue Coherence Evaluation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":31,"citationCount":14,"influentialCitationCount":3,"publicationDate":"01/06/2021","authors":"Zheng Ye,Liucun Lu,Lishan Huang,Liang Lin,Xiaodan Liang","id":"c8419114a8972e4945052e9699b69dfa858ab17c","summary":"Experimental results show that the model trained by QuantiDCE presents stronger correlations with human judgements than the other state-of-the-art metrics.","score":3},{"url":"https://www.semanticscholar.org/paper/d08a6a41e2b16928a1dc93b259bffbe37dae021d","title":"Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation","venue":"Findings","year":2021,"referenceCount":96,"citationCount":16,"influentialCitationCount":3,"publicationDate":"10/06/2021","authors":"Prakhar Gupta,Yulia Tsvetkov,Jeffrey P. Bigham","id":"d08a6a41e2b16928a1dc93b259bffbe37dae021d","summary":"This work proposes mask-and-fill and keyword-guided approaches that generate negative examples for training more robust dialogue systems and proposes approaches for automatically creating adversarial negative training data to help ranking and evaluation models learn features beyond content similarity.","score":3},{"url":"https://www.semanticscholar.org/paper/32f87b51e3ba42894821716b8145bde41fc65983","title":"Semantic Diversity in Dialogue with Natural Language Inference","venue":"North American Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":36,"citationCount":12,"influentialCitationCount":0,"publicationDate":"03/05/2022","authors":"Katherine Stasaski,Marti A. Hearst","id":"32f87b51e3ba42894821716b8145bde41fc65983","summary":"It is shown that the contradiction relation is more useful than the neutral relation for measuring this diversity and that incorporating the NLI model’s confidence achieves state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/b0e7055fcbb33e0cf1a93a27b483db66a57ffd5b","title":"A Systematic Evaluation of Response Selection for Open Domain Dialogue","venue":"SIGDIAL Conferences","year":2022,"referenceCount":43,"citationCount":7,"influentialCitationCount":1,"publicationDate":"08/08/2022","authors":"Behnam Hedayatnia,Di Jin,Yang Liu,Dilek Z. Hakkani-Tür","id":"b0e7055fcbb33e0cf1a93a27b483db66a57ffd5b","summary":"This work curated a dataset where responses from multiple response generators produced for the same dialog context are manually annotated as appropriate (positive) and inappropriate (negative) and argues that such training data better matches the actual use case examples, enabling the models to learn to rank responses effectively.","score":3},{"url":"https://www.semanticscholar.org/paper/4f480bae3196dbbc27ab383bce33478ea963f9b3","title":"LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models","venue":"NLP4CONVAI","year":2023,"referenceCount":41,"citationCount":27,"influentialCitationCount":0,"publicationDate":"23/05/2023","authors":"Yen-Ting Lin,Yun-Nung (Vivian) Chen","id":"4f480bae3196dbbc27ab383bce33478ea963f9b3","summary":"LLM-Eval is proposed, a single prompt-based evaluation method that leverages a unified evaluation schema to cover multiple dimensions of conversation quality in a single model call and offers a versatile and robust solution for evaluating open-domain conversation systems.","score":3},{"url":"https://www.semanticscholar.org/paper/1f132aedd064314a02569cc05f2b9369d35dc4f3","title":"Dior-CVAE: Pre-trained Language Models and Diffusion Priors for Variational Dialog Generation","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":79,"citationCount":0,"influentialCitationCount":0,"publicationDate":"24/05/2023","authors":"Tianyu Yang,Thy Thy Tran,Iryna Gurevych","id":"1f132aedd064314a02569cc05f2b9369d35dc4f3","summary":"This work employs a diffusion model to increase the complexity of the prior distribution and its compatibility with the distributions produced by a PLM, and proposes memory dropout to the cross-attention mechanism, which actively encourages the use of latent variables for response generation.","score":3},{"url":"https://www.semanticscholar.org/paper/dd0c6a687c493ffdcba529282ebc6a9ef7335883","title":"Evaluating Open-Domain Dialogues in Latent Space with Next Sentence Prediction and Mutual Information","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":39,"citationCount":0,"influentialCitationCount":0,"publicationDate":"26/05/2023","authors":"Kun Zhao,Bohao Yang,Chenghua Lin,Wenge Rong,Aline Villavicencio,Xiaohui Cui","id":"dd0c6a687c493ffdcba529282ebc6a9ef7335883","summary":"A novel learning-based automatic evaluation metric (CMN) is proposed, which can robustly evaluate open-domain dialogues by augmenting Conditional Variational Autoencoders with a Next Sentence Prediction (NSP) objective and employing Mutual Information to model the semantic similarity of text in the latent space.","score":3},{"url":"https://www.semanticscholar.org/paper/94adf8b8ccfaae8c55b2dee041fa6415470f5a77","title":"DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":44,"citationCount":1,"influentialCitationCount":0,"publicationDate":"29/06/2023","authors":"Ang Lv,Jinpeng Li,Yuhan Chen,Xing Gao,Ji Zhang,Rui Yan","id":"94adf8b8ccfaae8c55b2dee041fa6415470f5a77","summary":"This paper proposes DialoGue Path Sampling (DialoGPS) method in continuous semantic space, the first many-to-many augmentation method for multi-turn dialogues, and maps a dialogue to the extended Brownian Bridge, a special Gaussian process.","score":3},{"url":"https://www.semanticscholar.org/paper/b64b2d28e00e1bdf35393856707cbd133058abab","title":"xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":74,"citationCount":0,"influentialCitationCount":0,"publicationDate":"13/10/2023","authors":"Chen Zhang,L. F. D’Haro,Chengguang Tang,Ke Shi,Guohua Tang,Haizhou Li","id":"b64b2d28e00e1bdf35393856707cbd133058abab","summary":null,"score":3},{"url":"https://www.semanticscholar.org/paper/4236663e6416423fca02d5b058302adcb78f51f3","title":"COSMIC: COmmonSense knowledge for eMotion Identification in Conversations","venue":"Findings","year":2020,"referenceCount":46,"citationCount":200,"influentialCitationCount":50,"publicationDate":"06/10/2020","authors":"Deepanway Ghosal,Navonil Majumder,Alexander Gelbukh,Rada Mihalcea,Soujanya Poria","id":"4236663e6416423fca02d5b058302adcb78f51f3","summary":"This paper proposes COSMIC, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation.","score":3},{"url":"https://www.semanticscholar.org/paper/5b41b3c31edb20f7b08ebb8fa49b9d0887f01a3c","title":"Enhancing Cognitive Models of Emotions with Representation Learning","venue":"Workshop on Cognitive Modeling and Computational Linguistics","year":2021,"referenceCount":25,"citationCount":3,"influentialCitationCount":0,"publicationDate":"20/04/2021","authors":"Yuting Guo,Jinho D. Choi","id":"5b41b3c31edb20f7b08ebb8fa49b9d0887f01a3c","summary":"A novel deep learning-based framework to generate embedding representations of fine-grained emotions that can be used to computationally describe psychological models of emotions that enables to interpret dynamically learned representations optimized for an emotion classification task.","score":3},{"url":"https://www.semanticscholar.org/paper/45645b392ce5cd914007b5ae2c572c0cd591e835","title":"Emotion Recognition in Conversation using Probabilistic Soft Logic","venue":"arXiv.org","year":2022,"referenceCount":41,"citationCount":0,"influentialCitationCount":0,"publicationDate":"14/07/2022","authors":"Eriq Augustine,Pegah Jandaghi,Alon Albalak,Connor Pryor,Charles Dickens,William Wang,L. Getoor","id":"45645b392ce5cd914007b5ae2c572c0cd591e835","summary":"This work explores an approach to ERC that exploits the use of neural embeddings along with complex structures in dialogues, and implements it in a framework called Probabilistic Soft Logic (PSL), a declarative templating language that uses first-order like logical rules that when combined with data, define a particular class of graphical model.","score":3},{"url":"https://www.semanticscholar.org/paper/3562571fdfed2bfc7b6061c8721c9a5183240e67","title":"Emotion Prediction in Conversation Based on Relationship Extraction","venue":"IEEE International Conference on Cyborg and Bionic Systems","year":2023,"referenceCount":25,"citationCount":0,"influentialCitationCount":0,"publicationDate":"24/03/2023","authors":"Yingjian Liu,Xiaoping Wang,Lei Shanglin","id":"3562571fdfed2bfc7b6061c8721c9a5183240e67","summary":"A simple and effective framework for emotion prediction in conversation based on relationship extraction (DiaRP), consisting of two curricula: Dialogue Relationship Capture (DRC) and Next Emotion Prediction (NEP), which observe a significant performance improvement over a wide range of existing ERC models and achieve new state-of-the-art results.","score":3},{"url":"https://www.semanticscholar.org/paper/616597b6c8cc3d24339d9f16bb4b195624046abe","title":"Is ChatGPT Equipped with Emotional Dialogue Capabilities?","venue":"arXiv.org","year":2023,"referenceCount":47,"citationCount":25,"influentialCitationCount":2,"publicationDate":"19/04/2023","authors":"Weixiang Zhao,Yanyan Zhao,Xin Lu,Shilong Wang,Yanpeng Tong,Bing Qin","id":"616597b6c8cc3d24339d9f16bb4b195624046abe","summary":"While ChatGPT's performance on emotional dialogue understanding may still lag behind that of supervised models, it exhibits promising results in generating emotional responses, and suggests potential avenues for future research directions.","score":3},{"url":"https://www.semanticscholar.org/paper/9247189e531ebcb19b4eb92401665b4ed8c3a2c9","title":"EmoTwiCS: a corpus for modelling emotion trajectories in Dutch customer service dialogues on Twitter","venue":"Language Resources and Evaluation","year":2023,"referenceCount":95,"citationCount":3,"influentialCitationCount":0,"publicationDate":"10/10/2023","authors":"Sofie Labat,Thomas Demeester,V'eronique Hoste","id":"9247189e531ebcb19b4eb92401665b4ed8c3a2c9","summary":"EmoTwiCS, a corpus of 9489 Dutch customer service dialogues on Twitter that are annotated for emotion trajectories, is introduced and some suggestions on the different types of predictive modelling tasks and open research questions to which EmoTwiCS can be applied are given.","score":3},{"url":"https://www.semanticscholar.org/paper/f82988b15284b93fac4b8c6f5f6aef022931ba2a","title":"Hypergraph Neural Network for Emotion Recognition in Conversations","venue":"ACM Transactions on Asian and Low-Resource Language Information Processing","year":2024,"referenceCount":36,"citationCount":0,"influentialCitationCount":0,"publicationDate":"08/02/2024","authors":"Cheng Zheng,Haojie Xu,Xiao Sun","id":"f82988b15284b93fac4b8c6f5f6aef022931ba2a","summary":"The proposed hypergraph neural network, namely HNN-ERC, combines the recurrent neural network with the conventional hypergraph neural network to strengthen connections between utterances and make each utterance receive information from other utterances better.","score":3},{"url":"https://www.semanticscholar.org/paper/d4e502d22216440bf84fdff7a4fcef436873352e","title":"A Multi-Task Learning Approach for Summarization of Dialogues","venue":"","year":null,"referenceCount":50,"citationCount":4,"influentialCitationCount":1,"publicationDate":null,"authors":"Saprativa Bhattacharjee,Kartik Shinde,Tirthankar Ghosal,Asif Ekbal","id":"d4e502d22216440bf84fdff7a4fcef436873352e","summary":"This work describes a multi-task learning based approach for summarization of real-life dialogues through the auxiliary tasks of extractive summarization, novelty detection and language modeling and reports the results of automatic evaluation of the generated summaries in terms of ROUGE and BERTScore.","score":3},{"url":"https://www.semanticscholar.org/paper/2cc805b3b4a0a6a619a44bb7dd6d91d15f117016","title":"Think Before You Speak: Learning to Generate Implicit Knowledge for Response Generation by Self-Talk","venue":"NLP4CONVAI","year":2021,"referenceCount":17,"citationCount":6,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Behnam Hedayatnia,Karthik Gopalakrishnan,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"2cc805b3b4a0a6a619a44bb7dd6d91d15f117016","summary":"Experimental results show that compared with models that directly generate responses given a dialogue history, self-talk models produce better-quality responses according to human evaluation on grammaticality, coherence, and engagingness and models that are trained to identify when to self- talk further improves the response quality.","score":3},{"url":"https://www.semanticscholar.org/paper/dfcdf6c4e1d43097d911e0da304b2540f857cfb8","title":"DialogSum Challenge: Summarizing Real-Life Scenario Dialogues","venue":"International Conference on Natural Language Generation","year":2021,"referenceCount":22,"citationCount":17,"influentialCitationCount":4,"publicationDate":2021,"authors":"Yulong Chen,Yang Liu,Yue Zhang","id":"dfcdf6c4e1d43097d911e0da304b2540f857cfb8","summary":"This work carefully annotates a large-scale dialogue summarization dataset based on multiple public dialogue corpus, opening the door to all kinds of summarization models.","score":3},{"url":"https://www.semanticscholar.org/paper/0934d7cac5a86b02fc49852334051bde540b34bd","title":"DialogSum: A Real-Life Scenario Dialogue Summarization Dataset","venue":"Findings","year":2021,"referenceCount":37,"citationCount":127,"influentialCitationCount":32,"publicationDate":2021,"authors":"Yulong Chen,Yang Liu,Liang Chen,Yue Zhang","id":"0934d7cac5a86b02fc49852334051bde540b34bd","summary":"Experimental results show unique challenges in dialogue summarization, such as spoken terms, special discourse structures, coreferences and ellipsis, pragmatics and social common sense, which require specific representation learning technologies to better deal with.","score":3},{"url":"https://www.semanticscholar.org/paper/ce74df5126faad7d74f578f1e1953278611e235d","title":"Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation","venue":"arXiv.org","year":2021,"referenceCount":56,"citationCount":9,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"ce74df5126faad7d74f578f1e1953278611e235d","summary":"Compared with end-to-end RG models, self-talk models that externalize the knowledge grounding process by explicitly generating implicit knowledge also produce responses that are more informative, speciﬁc, and follow common sense.","score":3},{"url":"https://www.semanticscholar.org/paper/a210df43018c682f6f57120cdb66b93a42c26699","title":"Probing Causal Common Sense in Dialogue Response Generation","venue":"arXiv.org","year":2021,"referenceCount":46,"citationCount":4,"influentialCitationCount":1,"publicationDate":2021,"authors":"Pei Zhou,Pegah Jandaghi,Bill Yuchen Lin,Hyundong Justin Cho,J. Pujara,Xiang Ren","id":"a210df43018c682f6f57120cdb66b93a42c26699","summary":"The study if response generation models can emulate human reasoning process and use common sense to help produce better-quality responses finds that RG models have a hard time determining the logical validity of explanations but can identify grammatical naturalness of the explanation easily.","score":3},{"url":"https://www.semanticscholar.org/paper/8b6a633c33f20933d1d42eb9ba5b5470be1a3fa8","title":"TCS_WITM_2022 @ DialogSum : Topic oriented Summarization using Transformer based Encoder Decoder Model","venue":"","year":2022,"referenceCount":18,"citationCount":2,"influentialCitationCount":1,"publicationDate":2022,"authors":"Vipul Chauhan,Prasenjeet Roy,Lipika Dey,Tushar Goel","id":"8b6a633c33f20933d1d42eb9ba5b5470be1a3fa8","summary":"This paper's approach to the DialogSum challenge, which was proposed as a shared task aimed to summarize dialogues from real-life scenarios, is presented and it is found that since conversations usually veer around a topic, using topics along with the dialoagues, helps to generate more human-like summaries.","score":3},{"url":"https://www.semanticscholar.org/paper/0f43e829f2f9ce34d1d16865b03d843809639fb1","title":"Exploring Dialog Act Recognition in Open Domain Conversational Agents","venue":"International Conference on Data Warehousing and Knowledge Discovery","year":2023,"referenceCount":46,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Maliha Sultana,Osmar R Zaiane","id":"0f43e829f2f9ce34d1d16865b03d843809639fb1","summary":"This work proposes a dialog act (DA) classifier for two of the authors' open domain dialog systems and shows that the proposed model not only outperforms the baseline SVM classifier by achieving state-of-the-art accuracy but also generalizes extremely well on previously unseen data.","score":3},{"url":"https://www.semanticscholar.org/paper/8089bfe8aa59151147b78d9c9968026119cd5420","title":"Dialogue-adaptive language model pre-training from quality estimation☆","venue":"Neurocomputing","year":2020,"referenceCount":54,"citationCount":4,"influentialCitationCount":0,"publicationDate":"10/09/2020","authors":"Junlong Li,Zhuosheng Zhang,Hai Zhao","id":"8089bfe8aa59151147b78d9c9968026119cd5420","summary":"Experimental results on widely used open-domain response selection and quality estimation benchmarks show that DAPO significantly improves the baseline models and achieves state-of-the-art performance on the MuTual leaderboard, verifying the effectiveness of estimating quality evaluation factors into pre-training.","score":3},{"url":"https://www.semanticscholar.org/paper/614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac","title":"A Survey on Response Selection for Retrieval-based Dialogues","venue":"International Joint Conference on Artificial Intelligence","year":2021,"referenceCount":63,"citationCount":18,"influentialCitationCount":0,"publicationDate":"01/08/2021","authors":"Chongyang Tao,Jiazhan Feng,Rui Yan,Wei Wu,Daxin Jiang","id":"614cfe0d9edb0ad9caa5a446fbbde95af5afe9ac","summary":"A comprehensive survey of recent advances in response selection for retrieval-based dialogues and summarizes some recent advances on the research of response selection, including incorporation with extra knowledge and exploration on more effective model learning.","score":3},{"url":"https://www.semanticscholar.org/paper/81b58944372ea10436ff7252b115e21e893d11c6","title":"Enhanced Speaker-Aware Multi-Party Multi-Turn Dialogue Comprehension","venue":"IEEE/ACM Transactions on Audio Speech and Language Processing","year":2021,"referenceCount":99,"citationCount":12,"influentialCitationCount":2,"publicationDate":"09/09/2021","authors":"Xinbei Ma,Zhuosheng Zhang,Hai Zhao","id":"81b58944372ea10436ff7252b115e21e893d11c6","summary":"The Enhanced Speaker-Aware method (ESA) helps achieve state-of-the-art performance on the Molweni dataset, as well as significant improvements on the FriendsQA dataset, and analysis shows that the method makes steady improvements on stronger backbones.","score":3},{"url":"https://www.semanticscholar.org/paper/2820c2f6147ca8dbc19181fa712b2662dd0c3ae0","title":"Guiding Topic Flows in the Generative Chatbot by Enhancing the ConceptNet with the Conversation Corpora","venue":"arXiv.org","year":2021,"referenceCount":43,"citationCount":0,"influentialCitationCount":0,"publicationDate":"12/09/2021","authors":"Pengda Si,Yao Qiu,Jinchao Zhang,Yujiu Yang","id":"2820c2f6147ca8dbc19181fa712b2662dd0c3ae0","summary":"This work proposes the method to supply more concept relations extracted from the conversational corpora and reconstruct an enhanced concept graph for the chatbot construction and presents a novel, powerful, and fast graph encoding architecture named the Edge-Transformer to replace the traditional GNN architecture.","score":3},{"url":"https://www.semanticscholar.org/paper/5038cfdca6201cf328106fe5193bc430548a1772","title":"Think Before You Speak: Explicitly Generating Implicit Commonsense Knowledge for Response Generation","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":67,"citationCount":24,"influentialCitationCount":2,"publicationDate":"16/10/2021","authors":"Pei Zhou,Karthik Gopalakrishnan,Behnam Hedayatnia,Seokhwan Kim,J. Pujara,Xiang Ren,Yang Liu,Dilek Z. Hakkani-Tür","id":"5038cfdca6201cf328106fe5193bc430548a1772","summary":"Think-Before-Speaking is presented, a generative approach to first externalize implicit commonsense knowledge (think) and use this knowledge to generate responses (speak), arguing that externalizing implicit knowledge allows more efficient learning, produces more informative responses, and enables more explainable models.","score":3},{"url":"https://www.semanticscholar.org/paper/2ae757afd718d5219cdee3a6c4cee0d226378efd","title":"Representation Learning for Conversational Data using Discourse Mutual Information Maximization","venue":"North American Chapter of the Association for Computational Linguistics","year":2021,"referenceCount":53,"citationCount":3,"influentialCitationCount":0,"publicationDate":"04/12/2021","authors":"Bishal Santra,Sumegh Roychowdhury,Aishik Mandal,Vasu Gurram,Atharva Naik,Manish Gupta,Pawan Goyal","id":"2ae757afd718d5219cdee3a6c4cee0d226378efd","summary":"This work proposes a structure-aware Mutual Information based loss-function DMI (Discourse Mutual Information) for training dialog-representation models, that additionally captures the inherent uncertainty in response prediction.","score":3},{"url":"https://www.semanticscholar.org/paper/3c9ba25baca64151af4e9d50c7947de28eb2a599","title":"Survey of Hallucination in Natural Language Generation","venue":"ACM Computing Surveys","year":2022,"referenceCount":252,"citationCount":867,"influentialCitationCount":46,"publicationDate":"08/02/2022","authors":"Ziwei Ji,Nayeon Lee,Rita Frieske,Tiezheng Yu,D. Su,Yan Xu,Etsuko Ishii,Yejin Bang,Wenliang Dai,Andrea Madotto,Pascale Fung","id":"3c9ba25baca64151af4e9d50c7947de28eb2a599","summary":"A broad overview of the research progress and challenges in the hallucination problem in NLG is provided, including task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation.","score":3},{"url":"https://www.semanticscholar.org/paper/d179082956ab75d08311ddc1bbb20783031d15b1","title":"Leveraging speaker-aware structure and factual knowledge for faithful dialogue summarization","venue":"Knowledge-Based Systems","year":2022,"referenceCount":75,"citationCount":2,"influentialCitationCount":0,"publicationDate":"01/03/2022","authors":"Lulu Zhao,Weiran Xu,Chunyun Zhang,Jun Guo","id":"d179082956ab75d08311ddc1bbb20783031d15b1","summary":"","score":3},{"url":"https://www.semanticscholar.org/paper/3c05f71157c713fe45704bdd130f01620b7ab771","title":"Towards Robust Online Dialogue Response Generation","venue":"arXiv.org","year":2022,"referenceCount":56,"citationCount":1,"influentialCitationCount":0,"publicationDate":"07/03/2022","authors":"Leyang Cui,Fandong Meng,Yanjun Liu,Jie Zhou,Yue Zhang","id":"3c05f71157c713fe45704bdd130f01620b7ab771","summary":"This paper proposes a hierarchical sampling-based method consisting of both utterance-level sampling and semi-utterance- level sampling, to alleviate the discrepancy between training and real-world testing, which implicitly increases the dialogue coherence.","score":3},{"url":"https://www.semanticscholar.org/paper/d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3","title":"Multiview Contextual Commonsense Inference: A New Dataset and Task","venue":"arXiv.org","year":2022,"referenceCount":25,"citationCount":4,"influentialCitationCount":1,"publicationDate":"06/10/2022","authors":"Siqi Shen,Deepanway Ghosal,Navonil Majumder,Henry Lim,Rada Mihalcea,Soujanya Poria","id":"d0ba95d3c7766038ea47fda8a13377cf3ee1c8e3","summary":"This work creates CICEROv2, a dataset consisting of 8,351 instances from 2,379 dialogues, containing multiple human-written answers for each contextual commonsense inference question, representing a type of explanation on cause, subsequent event, motivation, and emotional reaction.","score":3},{"url":"https://www.semanticscholar.org/paper/d1feb79f63ea52839f4a784fbd7d60bb73dd98dd","title":"ComFact: A Benchmark for Linking Contextual Commonsense Knowledge","venue":"Conference on Empirical Methods in Natural Language Processing","year":2022,"referenceCount":71,"citationCount":10,"influentialCitationCount":3,"publicationDate":"23/10/2022","authors":"Silin Gao,Jena D. Hwang,Saya Kanno,Hiromi Wakaki,Yuki Mitsufuji,Antoine Bosselut","id":"d1feb79f63ea52839f4a784fbd7d60bb73dd98dd","summary":"This work proposes the new task of commonsense fact linking, where models are given contexts and trained to identify situationally-relevant commonsense knowledge from KGs, and shows that heuristic fact linking approaches are imprecise knowledge extractors.","score":3},{"url":"https://www.semanticscholar.org/paper/19a0777498ec3ef1e11e8349df3eb336cc19698d","title":"Syndicom: Improving Conversational Commonsense with Error-Injection and Natural Language Feedback","venue":"SIGDIAL Conferences","year":2023,"referenceCount":30,"citationCount":1,"influentialCitationCount":0,"publicationDate":"18/09/2023","authors":"Christopher Richardson,Anirudh S. Sundar,Larry Heck","id":"19a0777498ec3ef1e11e8349df3eb336cc19698d","summary":"This work introduces Syndicom - a method for improving commonsense in dialogue response generation by training a model to predict natural language feedback for invalid responses and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue.","score":3},{"url":"https://www.semanticscholar.org/paper/99f7bd216214b22c22974142fd558ce554f518b8","title":"Contrastive Learning for Inference in Dialogue","venue":"Conference on Empirical Methods in Natural Language Processing","year":2023,"referenceCount":80,"citationCount":0,"influentialCitationCount":0,"publicationDate":"19/10/2023","authors":"Etsuko Ishii,Yan Xu,Bryan Wilie,Ziwei Ji,Holy Lovenia,Willy Chung,Pascale Fung","id":"99f7bd216214b22c22974142fd558ce554f518b8","summary":"This paper analyzes the behavior of the models based on the task difficulty defined by the semantic information gap -- which distinguishes inductive and deductive reasoning (Johnson-Laird, 1988, 1993); and investigates a contrastive learning approach by feeding negative samples.","score":3},{"url":"https://www.semanticscholar.org/paper/6abededed5b4eb1bdeba0fa53db5ae37526882ef","title":"Goal Awareness for Conversational AI: Proactivity, Non-collaborativity, and Beyond","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":109,"citationCount":6,"influentialCitationCount":0,"publicationDate":2023,"authors":"Yang Deng,Wenqiang Lei,Minlie Huang,Tat-seng Chua","id":"6abededed5b4eb1bdeba0fa53db5ae37526882ef","summary":"This tutorial will introduce the recent advances on the design of agent’s awareness of goals in a wide range of conversational systems and suggest ways to empower the system to handle more complicated conversation tasks that involve strategical and motivational interactions.","score":3},{"url":"https://www.semanticscholar.org/paper/a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88","title":"Social Influence Dialogue Systems: A Survey of Datasets and Models For Social Influence Tasks","venue":"Conference of the European Chapter of the Association for Computational Linguistics","year":2022,"referenceCount":99,"citationCount":5,"influentialCitationCount":0,"publicationDate":"11/10/2022","authors":"Kushal Chawla,Weiyan Shi,Jingwen Zhang,Gale M. Lucas,Zhou Yu,J. Gratch","id":"a1275e92f4830e5bbd53bc1b1fa44a9a2f024f88","summary":"This work formally define and introduce the category of social influence dialogue systems that influence users’ cognitive and emotional responses, leading to changes in thoughts, opinions, and behaviors through natural conversations.","score":3},{"url":"https://www.semanticscholar.org/paper/ada86fad82097fc3c76000b3af2862fc21678919","title":"ConvoSense: Overcoming Monotonous Commonsense Inferences for Conversational AI","venue":"arXiv.org","year":2024,"referenceCount":44,"citationCount":0,"influentialCitationCount":0,"publicationDate":"27/01/2024","authors":"Sarah E. Finch,Jinho D. Choi","id":"ada86fad82097fc3c76000b3af2862fc21678919","summary":"This work compiles a new synthetic dataset for commonsense reasoning in dialogue contexts using GPT, ConvoSense, that boasts greater contextual novelty, offers a higher volume of inferences per example, and substantially enriches the detail conveyed by the inferences.","score":2},{"url":"https://www.semanticscholar.org/paper/b0df9c1a785618c1cfa9090cbca4c6110be092fe","title":"Emotion-Aware and Human-Like Autonomous Agents","venue":"","year":2019,"referenceCount":227,"citationCount":1,"influentialCitationCount":0,"publicationDate":"20/12/2019","authors":"Nabiha Asghar","id":"b0df9c1a785618c1cfa9090cbca4c6110be092fe","summary":"This thesis addresses two challenges: replicating the human ability to correctly perceive and adopt emotions, and communicate effectively through language, and devise an active learning technique that elicits user feedback during a conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/d08463bd665589d04619f04dbde84183ffcf2e63","title":"Towards a Human-like Open-Domain Chatbot","venue":"arXiv.org","year":2020,"referenceCount":87,"citationCount":777,"influentialCitationCount":97,"publicationDate":"27/01/2020","authors":"Daniel De Freitas,Minh-Thang Luong,David R. So,Jamie Hall,Noah Fiedel,Romal Thoppilan,Zi Yang,Apoorv Kulshreshtha,Gaurav Nemade,Yifeng Lu,Quoc V. Le","id":"d08463bd665589d04619f04dbde84183ffcf2e63","summary":"Meena, a multi-turn open-domain chatbot trained end-to-end on data mined and filtered from public domain social media conversations, is presented and a human evaluation metric called Sensibleness and Specificity Average (SSA) is proposed, which captures key elements of a human-like multi- turn conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/343eef7387dbc7d0ffa463cfe1cfab237f82aa66","title":"Gunrock 2.0: A User Adaptive Social Conversational System","venue":"arXiv.org","year":2020,"referenceCount":44,"citationCount":20,"influentialCitationCount":0,"publicationDate":"17/11/2020","authors":"Kai-Hui Liang,Author Chau,Yu Li,Xueyuan Lu,Dian Yu,Mingyang Zhou,Ishan Jain,Sam Davidson,Josh Arnold,Minh Le Nguyen,Zhou Yu","id":"343eef7387dbc7d0ffa463cfe1cfab237f82aa66","summary":"Gunrock 2.0 is built on top of Gunrock with an emphasis on user adaptation and combines various neural natural language understanding modules, including named entity detection, linking, and dialog act prediction, to improve user understanding.","score":2},{"url":"https://www.semanticscholar.org/paper/77b101d2c0f3d2842edb4acdbca0c4e859cda4d5","title":"A survey on empathetic dialogue systems","venue":"Information Fusion","year":2020,"referenceCount":152,"citationCount":148,"influentialCitationCount":1,"publicationDate":"01/12/2020","authors":"Yukun Ma,Khanh Linh Nguyen,Frank Xing,E. Cambria","id":"77b101d2c0f3d2842edb4acdbca0c4e859cda4d5","summary":"This review article focuses on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge, and identifies three key features that underpin such systems: emotion-awareness, personality-awareness and knowledge-accessibility.","score":2},{"url":"https://www.semanticscholar.org/paper/8ac5f84cd417b04dd178e963d7aa03f3be27d74b","title":"Dialogue System Augmented with Commonsense Knowledge","venue":"Vilnius University Open Series","year":2022,"referenceCount":31,"citationCount":0,"influentialCitationCount":0,"publicationDate":"13/05/2022","authors":"I. Lasy,Virginijus Marcinkevičius","id":"8ac5f84cd417b04dd178e963d7aa03f3be27d74b","summary":"This work proposes usage of structured knowledge base ConceptNet for knowledge-grounded dialogue generation and novel knowledge extraction algorithm is proposed which is then used to incorporate knowledge into existing dialogue datasets.","score":2},{"url":"https://www.semanticscholar.org/paper/4f6f14315ed322fb8eae5aa04b3e48f5f34324bf","title":"Can Large Language Models Be Good Companions? An LLM-Based Eyewear System with Conversational Common Ground","venue":"arXiv.org","year":2023,"referenceCount":71,"citationCount":0,"influentialCitationCount":0,"publicationDate":"30/11/2023","authors":"Zhenyu Xu,Hailin Xu,Zhouyang Lu,Yingying Zhao,Rui Zhu,Yujiang Wang,Mingzhi Dong,Yuhu Chang,Qin Lv,Robert P. Dick,Fan Yang,T. Lu,Ning Gu,L. Shang","id":"4f6f14315ed322fb8eae5aa04b3e48f5f34324bf","summary":"This work proposes to build a common-ground-aware dialogue system from an LLM-based module, named OS-1, which can significantly improve user satisfaction and potentially lead to downstream tasks such as personal emotional support and assistance.","score":2},{"url":"https://www.semanticscholar.org/paper/c0e36c42bb7c70d64e4fe3b736ae1944210accdc","title":"Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement","venue":"arXiv.org","year":2024,"referenceCount":29,"citationCount":0,"influentialCitationCount":0,"publicationDate":"25/01/2024","authors":"Hana Kim,Kai Tzu-iunn Ong,Seoyeon Kim,Dongha Lee,Jinyoung Yeo","id":"c0e36c42bb7c70d64e4fe3b736ae1944210accdc","summary":"A novel framework that leverages commonsense-based persona expansion to address issues in long-term conversation by transforming contradictory personas into sentences that contain rich speaker information, by refining them based on their contextual backgrounds with designed strategies.","score":2},{"url":"https://www.semanticscholar.org/paper/658a912984d6a4899d1369ca674b06c7aafd45d0","title":"DIRECT: Toward Dialogue-Based Reading Comprehension Tutoring","venue":"IEEE Access","year":2023,"referenceCount":44,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Jin-Xia Huang,Yohan Lee,Oh-Woog Kwon","id":"658a912984d6a4899d1369ca674b06c7aafd45d0","summary":"A dialogue-based intelligent tutoring system (ITS) that imitates human expert tutors that asks questions, assesses student answers, provides hints, and even chats to encourage student engagement is developed.","score":2},{"url":"https://www.semanticscholar.org/paper/fac8d660e9c0cef1da5d35aea35c572ed776e887","title":"Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion Dialogues via Reinforcement Learning and Human Demonstration","venue":"Conference on Empirical Methods in Natural Language Processing","year":2020,"referenceCount":55,"citationCount":18,"influentialCitationCount":2,"publicationDate":"31/12/2020","authors":"Weiyan Shi,Yu Li,Saurav Sahay,Zhou Yu","id":"fac8d660e9c0cef1da5d35aea35c572ed776e887","summary":"This model outperforms previous state-of-the-art dialogue models on both automatic metrics and human evaluation results on a donation persuasion task, and generates more diverse, consistent and persuasive conversations according to the user feedback.","score":2},{"url":"https://www.semanticscholar.org/paper/23bb7ac9d1164b0b429e59eb012584c1c1c64e73","title":"Structural Characterization for Dialogue Disentanglement","venue":"Annual Meeting of the Association for Computational Linguistics","year":2021,"referenceCount":66,"citationCount":14,"influentialCitationCount":3,"publicationDate":"15/10/2021","authors":"Xinbei Ma,Zhuosheng Zhang,Hai Zhao","id":"23bb7ac9d1164b0b429e59eb012584c1c1c64e73","summary":"This work specially takes structure factors into account and design a novel model for dialogue disentangling that achieves new state-of-the-art on the Ubuntu IRC benchmark dataset and contributes to dialogue-related comprehension.","score":2},{"url":"https://www.semanticscholar.org/paper/b0291bee1d532e8dc082753329d2579549100479","title":"Eliciting Transferability in Multi-task Learning with Task-level Mixture-of-Experts","venue":"arXiv.org","year":2022,"referenceCount":45,"citationCount":4,"influentialCitationCount":0,"publicationDate":2022,"authors":"Qinyuan Ye,Juan Zha,Xiang Ren","id":"b0291bee1d532e8dc082753329d2579549100479","summary":"It is shown that the learned routing decisions and experts partially rediscover human categorization of NLP tasks – certain experts are strongly associated with extractive tasks, some with classiﬁcation tasks, and some with tasks requiring world knowledge.","score":2},{"url":"https://www.semanticscholar.org/paper/08f7aeca8f94bedbeb425bef1f0b3fcd9361f785","title":"SafetyKit: First Aid for Measuring Safety in Open-domain Conversational Systems","venue":"Annual Meeting of the Association for Computational Linguistics","year":2022,"referenceCount":136,"citationCount":40,"influentialCitationCount":1,"publicationDate":2022,"authors":"Emily Dinan,Gavin Abercrombie,A. Bergman,Shannon L. Spruit,Dirk Hovy,Y-Lan Boureau,Verena Rieser","id":"08f7aeca8f94bedbeb425bef1f0b3fcd9361f785","summary":"This position paper surveys the problem of safety for end-to-end conversational AI, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects, and empirically assess the extent to which current tools can measure these effects and current systems display them.","score":2},{"url":"https://www.semanticscholar.org/paper/25eba922c7076e1a8a0a86fd0eed2bfcdbe0bbc3","title":"AugESC: Large-scale Data Augmentation for Emotional Support Conversation with Pre-trained Language Models","venue":"arXiv.org","year":2022,"referenceCount":27,"citationCount":17,"influentialCitationCount":2,"publicationDate":2022,"authors":"Chujie Zheng,Sahand Sabour,Jiaxin Wen,Minlie Huang","id":"25eba922c7076e1a8a0a86fd0eed2bfcdbe0bbc3","summary":"This paper proposes exploiting large-scale pre-trained language models for data augmentation, and demonstrates with interactive evaluation that A UG ESC can further enhance dialog models tuned on ESConv to handle various conversation topics and to provide signiﬁcantly more effective emotional support.","score":2},{"url":"https://www.semanticscholar.org/paper/5fa273f7db53ef98d3789b26a8f2dcf3b71fe005","title":"Empirical study on BlenderBot 2.0 Errors Analysis in terms of Model, Data and User-Centric Approach","venue":"arXiv.org","year":2022,"referenceCount":28,"citationCount":4,"influentialCitationCount":0,"publicationDate":2022,"authors":"Jungseob Lee,Midan Shim,Suhyune Son,Yujin Kim,Chanjun Park,Heuiseok Lim","id":"5fa273f7db53ef98d3789b26a8f2dcf3b71fe005","summary":"This work examined BlenderBot 2.0’s limitations and errors from three perspectives: model, data, and user, and highlights the unclear guidelines provided to workers during the crowdsourcing process and lack of a process for re-ﬁning hate speech in the collected data and verifying the accuracy of internet-based information.","score":2},{"url":"https://www.semanticscholar.org/paper/5e251503c1ce484cc50accac7b0ad695f32c1a91","title":"Primary Program Committees","venue":"","year":2022,"referenceCount":66,"citationCount":0,"influentialCitationCount":0,"publicationDate":2022,"authors":"Young-Jun Lee,Chae-Gyun Lim,Yunsu Choi,Ji-Hui Lm,Ho-Jin Choi","id":"5e251503c1ce484cc50accac7b0ad695f32c1a91","summary":"It is presented that the FoCus model could not correctly blend the knowledge according to the input dialogue and that the dataset design is unsuitable for the multiturn conversation.","score":2},{"url":"https://www.semanticscholar.org/paper/925d25c93021c8bdb408d5c2c279fa125f3520db","title":"PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue","venue":"arXiv.org","year":2023,"referenceCount":31,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Min Sik Oh,Joosung Lee,Jiwei Li,Guoyin Wang","id":"925d25c93021c8bdb408d5c2c279fa125f3520db","summary":"A novel grounding retrieval method is developed that utilizes all contexts of dialogue simultaneously while also requiring limited training via zero-shot inference due to compatibility with neural Q & A retrieval models and the hard-negative behavior of combining Persona and Dialogue is analyzed.","score":2},{"url":"https://www.semanticscholar.org/paper/194de0615fecd9a9cc8cde2524a0e2522a0ce6fb","title":"Portabilité linguistique des modèles de langage pré-appris appliqués à la tâche de dialogue humain-machine en français","venue":"JEPTALNRECITAL","year":2023,"referenceCount":20,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Ahmed Njifenjou,Virgile Sucal,Bassam Jabaian,Fabrice Lefèvre","id":"194de0615fecd9a9cc8cde2524a0e2522a0ce6fb","summary":"","score":2},{"url":"https://www.semanticscholar.org/paper/66490616f9992c473347cb05cd05a46e6d897da2","title":"Human-Centered Metrics for Dialog System Evaluation","venue":"arXiv.org","year":2023,"referenceCount":72,"citationCount":4,"influentialCitationCount":0,"publicationDate":2023,"authors":"Salvatore Giorgi,Shreya Havaldar,Farhan Ahmed,Zuhaib Akhtar,Shalaka Vaidya,Gary Pan,L. Ungar,H. A. Schwartz,João Sedoc","id":"66490616f9992c473347cb05cd05a46e6d897da2","summary":"The proposed human metrics offer novel information, are uncorrelated with automatic metrics, and lead to increased accuracy beyond existing automatic metrics for predicting crowd-sourced dialog judgements, which make it a valuable tool for evaluating and improving dialog systems.","score":2},{"url":"https://www.semanticscholar.org/paper/bd4c0aac616b40d981d046f87e8f1650bd9c290b","title":"Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution","venue":"SIGDIAL Conferences","year":2023,"referenceCount":38,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Ayaka Ueyama,Yoshinobu Kano","id":"bd4c0aac616b40d981d046f87e8f1650bd9c290b","summary":"This work proposes Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history.","score":2},{"url":"https://www.semanticscholar.org/paper/20218ba137b62c6257335aaf77ef420a5c2c9e51","title":"Evaluation Metrics for NLG and TTS in Task-Oriented Dialog PhD. Thesis Proposal","venue":"","year":2023,"referenceCount":92,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"PhD. Thesis Proposal Ondˇrej Pl´atek","id":"20218ba137b62c6257335aaf77ef420a5c2c9e51","summary":"This thesis proposal explores the evaluation of Task-oriented Dialogue (ToD) systems and Text-to-Speech Synthesis (TTS) using automatic metrics and proposes a series of experiments aimed at resolving the identified limitations and enhancing the evaluation process for D2T and ToD NLG.","score":2},{"url":"https://www.semanticscholar.org/paper/10a1df67be1401752d65f0c7fdf80a3bfa686a67","title":"A Synthetic Data Generation Framework for Grounded Dialogues","venue":"Annual Meeting of the Association for Computational Linguistics","year":2023,"referenceCount":41,"citationCount":3,"influentialCitationCount":0,"publicationDate":2023,"authors":"Jianzhu Bao,Rui Wang,Yasheng Wang,Aixin Sun,Yitong Li,Fei Mi,Rui-Lan Xu","id":"10a1df67be1401752d65f0c7fdf80a3bfa686a67","summary":"This paper presents a synthetic data generation framework (SynDG) for grounded dialogues, and designs a two-level filtering strategy to ensure coherence of both the dialogue flow and the synthetic dialogue.","score":2},{"url":"https://www.semanticscholar.org/paper/e0d3a34ea616d181eedae9e56126e86daefdd2c8","title":"Enhancing Dialogue Generation with Conversational Concept Flows","venue":"Findings","year":2023,"referenceCount":50,"citationCount":3,"influentialCitationCount":0,"publicationDate":2023,"authors":"Siheng Li,Wangjie Jiang,Pengda Si,Cheng Yang,Qiu Yao,Jinchao Zhang,Jie Zhou,Yujiu Yang","id":"e0d3a34ea616d181eedae9e56126e86daefdd2c8","summary":"This work extracts abundant concepts and relations from natural conversations and builds a new conversation-aware knowledge graph and designs a novel relation-aware graph encoder to capture the concept flows guided by the knowledge graph.","score":2},{"url":"https://www.semanticscholar.org/paper/5da8ef8573a1504804314f612c97bf7ab6a563df","title":"Empathy Identification Systems are not Accurately Accounting for Context","venue":"Conference of the European Chapter of the Association for Computational Linguistics","year":2023,"referenceCount":40,"citationCount":0,"influentialCitationCount":0,"publicationDate":2023,"authors":"Andrew Lee,Jonathan K. Kummerfeld,Lawrence An,Rada Mihalcea","id":"5da8ef8573a1504804314f612c97bf7ab6a563df","summary":"A simple model that checks if an input utterance is similar to a small set of empathetic examples is considered, which indicates that current systems rely on the surface form of the response, rather than whether it is suitable in context.","score":2},{"url":"https://www.semanticscholar.org/paper/f2d257625e8029f6f4998deb6279f97e07e2893c","title":"MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations","venue":"Annual Meeting of the Association for Computational Linguistics","year":2018,"referenceCount":35,"citationCount":629,"influentialCitationCount":150,"publicationDate":"05/10/2018","authors":"Soujanya Poria,Devamanyu Hazarika,Navonil Majumder,Gautam Naik,E. Cambria,Rada Mihalcea","id":"f2d257625e8029f6f4998deb6279f97e07e2893c","summary":"The Multimodal EmotionLines Dataset (MELD), an extension and enhancement of Emotion lines, contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends and shows the importance of contextual and multimodal information for emotion recognition in conversations.","score":2},{"url":"https://www.semanticscholar.org/paper/592d500e44f99e39f35d5d96f8787b94f51aa914","title":"Approximating Interactive Human Evaluation with Self-Play for Open-Domain Dialog Systems","venue":"Neural Information Processing Systems","year":2019,"referenceCount":44,"citationCount":79,"influentialCitationCount":7,"publicationDate":"01/06/2019","authors":"Asma Ghandeharioun,J. Shen,Natasha Jaques,Craig Ferguson,Noah J. Jones,Àgata Lapedriza,Rosalind W. Picard","id":"592d500e44f99e39f35d5d96f8787b94f51aa914","summary":"It is shown that this metric is capable of capturing the human-rated quality of a dialog model better than any automated metric known to-date, achieving a significant Pearson correlation (r>.7, p<.05).","score":2},{"url":"https://www.semanticscholar.org/paper/9fc0ddd6811cf682500d12585da78385b01a1e6b","title":"CAiRE: An End-to-End Empathetic Chatbot","venue":"AAAI Conference on Artificial Intelligence","year":2019,"referenceCount":31,"citationCount":102,"influentialCitationCount":12,"publicationDate":"28/07/2019","authors":"Zhaojiang Lin,Peng Xu,Genta Indra Winata,Zihan Liu,Pascale Fung","id":"9fc0ddd6811cf682500d12585da78385b01a1e6b","summary":"This system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection.","score":2},{"url":"https://www.semanticscholar.org/paper/11ed7f038bd7efd1491f3957959e1e30bc120c38","title":"CAiRE: An Empathetic Neural Chatbot.","venue":"","year":2019,"referenceCount":30,"citationCount":20,"influentialCitationCount":1,"publicationDate":"28/07/2019","authors":"Zhaojiang Lin,Peng Xu,Genta Indra Winata,Farhad Bin Siddique,Zihan Liu,Jamin Shin,Pascale Fung","id":"11ed7f038bd7efd1491f3957959e1e30bc120c38","summary":"This system adapts TransferTransfo (Wolf et al., 2019) learning approach that fine-tunes a large-scale pre-trained language model with multi-task objectives: response language modeling, response prediction and dialogue emotion detection.","score":2},{"url":"https://www.semanticscholar.org/paper/e324d92c005ccdec0ce04dfb9941dd99ded21920","title":"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction","venue":"arXiv.org","year":2019,"referenceCount":180,"citationCount":5,"influentialCitationCount":0,"publicationDate":"08/09/2019","authors":"Bin Guo,Hao Wang,Yasan Ding,Shaoyang Hao,Yueqi Sun,Zhiwen Yu","id":"e324d92c005ccdec0ce04dfb9941dd99ded21920","summary":"This work aims to give a comprehensive review of the new research trends of c-TextGen, and gives a brief literature review of text generation technology, based on which it formalizes the concept model of c.TextGen.","score":2}]}